{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metropolis-Hastings Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we implement the Metropolis-Hasting algorithm to sample from two probability distributions. The first distribution is the a mixture of two normal distributions in 2D and the second distribution is a banana-shaped distribution in 2D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mixtures of two normal distributions in 2D\n",
    "### Probability density function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability density function (PDF) of the mixture of two normal distributions in 2D used in this tutorial\n",
    "is given by:\n",
    "\n",
    "$$\n",
    "p(x) = \\alpha \\cdot \\phi(x \\mid \\mu_1, \\sigma_1) + (1 - \\alpha) \\cdot \\phi(x \\mid \\mu_2, \\sigma_2)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\phi(x \\mid \\mu, \\sigma)$ is the PDF of the 2d normal distribution with mean $\\mu$ and standard deviation $\\sigma$. Here we assume that the standard deviation is the same in both dimensions and there is no correlation between the dimensions.\n",
    "- $\\alpha$ is the weight of the first normal distribution.\n",
    "  \n",
    "$\\phi(x \\mid \\mu, \\sigma)$ is given by:\n",
    "\n",
    "$$\n",
    "\\phi(x \\mid \\mu, \\sigma) = \\frac{1}{2\\pi\\sigma^2} \\exp\\left(-\\frac{1}{2\\sigma^2} (x - \\mu)^T(x - \\mu)\\right)\n",
    "$$\n",
    "\n",
    "In this tutorial, we use the following parameters:\n",
    "- $\\alpha = 0.5$\n",
    "- $\\mu_1 = [0, 0]$\n",
    "- $\\mu_2 = [5, -4]$\n",
    "- $\\sigma_1 = 1$\n",
    "- $\\sigma_2 = 1.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import vmap, jit\n",
    "import jax.random as jr\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prob_mixture_of_normal(\n",
    "    x, alpha=0.5, mu1=jnp.array([0, 0]), mu2=jnp.array([5, -4]), sigma1=1, sigma2=1.5\n",
    "):\n",
    "    \"\"\" \"\n",
    "    Compute the log probability of a point x under the Gaussian Mixture Model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : jnp.array\n",
    "        A 2D point\n",
    "    alpha : float\n",
    "        The weight of the first Gaussian component\n",
    "    mu1 : jnp.array\n",
    "        The mean of the first Gaussian component\n",
    "    mu2 : jnp.array\n",
    "        The mean of the second Gaussian component\n",
    "    sigma1 : float\n",
    "        The standard deviation of the first Gaussian component for both dimensions, the covariance matrix is diagonal\n",
    "    sigma2 : float\n",
    "        The standard deviation of the second Gaussian component for both dimensions, the covariance matrix is diagonal\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the probability of x under the first Gaussian component\n",
    "    prob1 = jnp.exp(-0.5 * (jnp.linalg.norm(x - mu1) ** 2) / (sigma1**2)) / (\n",
    "        2 * jnp.pi * sigma1**2\n",
    "    )\n",
    "\n",
    "    # Compute the probability of x under the second Gaussian component\n",
    "    prob2 = jnp.exp(-0.5 * (jnp.linalg.norm(x - mu2) ** 2) / (sigma2**2)) / (\n",
    "        2 * jnp.pi * sigma2**2\n",
    "    )\n",
    "\n",
    "    # Compute the probability of x under the Gaussian Mixture Model\n",
    "    prob = alpha * prob1 + (1 - alpha) * prob2\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the PDF of the mixture of two normal distributions to visualize the distribution. The distribution has two modes, one at the origin and the other at $(5, -4)$. The two modes are separated by a region of low probability density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## plot contour of the probability\n",
    "x1 = jnp.linspace(-2, 8, 100)\n",
    "x2 = jnp.linspace(-8, 2, 100)\n",
    "\n",
    "X1, X2 = jnp.meshgrid(x1, x2)\n",
    "X = jnp.stack([X1, X2], axis=-1)\n",
    "\n",
    "prob = vmap(vmap(compute_prob_mixture_of_normal))(X)\n",
    "plt.contourf(X1, X2, prob, 20)\n",
    "plt.colorbar()\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.title(\"Probability contour of the Gaussian Mixture Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample using Metropolis-Hastings algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genrate_proposal_mixture_of_normal(key, x):\n",
    "    \"\"\"Propose a new point x' given the current point x\"\"\"\n",
    "\n",
    "    return x + jr.normal(key, (2,))\n",
    "\n",
    "\n",
    "@jit\n",
    "def one_step_mixture_of_normal(key, x):\n",
    "    \"\"\"Perform one step of the Metropolis-Hastings algorithm\"\"\"\n",
    "\n",
    "    ## Generate a proposal\n",
    "    subkey, key = jr.split(key)\n",
    "    x_proposal = genrate_proposal_mixture_of_normal(subkey, x)\n",
    "\n",
    "    ## Compute the acceptance probability\n",
    "    p_x = compute_prob_mixture_of_normal(x)\n",
    "    p_x_proposal = compute_prob_mixture_of_normal(x_proposal)\n",
    "    accept_prob = jnp.min(jnp.array([1, p_x_proposal / p_x]))\n",
    "\n",
    "    ## Accept or reject the proposal\n",
    "    u = jr.uniform(key)\n",
    "    x_new = jnp.where(u < accept_prob, x_proposal, x)\n",
    "\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Metropolis-Hastings algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## generate a random initial point\n",
    "key = jr.PRNGKey(0)\n",
    "subkey1, subkey2, key = jr.split(key, 3)\n",
    "x_init = jnp.concatenate(\n",
    "    [\n",
    "        jr.uniform(subkey1, (1,), minval=-2, maxval=8),\n",
    "        jr.uniform(subkey2, (1,), minval=-8, maxval=2),\n",
    "    ]\n",
    ")\n",
    "print(f\"Initial point: {x_init}\")\n",
    "\n",
    "## generate samples\n",
    "num_samples = 3000\n",
    "samples = [x_init]\n",
    "for i in tqdm(range(num_samples)):\n",
    "    key, subkey = jr.split(key)\n",
    "    x_init = one_step_mixture_of_normal(subkey, x_init)\n",
    "    samples.append(x_init)\n",
    "\n",
    "samples = jnp.stack(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt.plot(samples[:, 0], samples[:, 1], \".\", alpha=0.5)\n",
    "plt.xlim(-2, 8)\n",
    "plt.ylim(-8, 2)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.title(\"Samples from the Gaussian Mixture Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.clf()\n",
    "plt.plot(samples[:, 0], label=\"x1\", alpha=0.5)\n",
    "plt.plot(samples[:, 1], label=\"x2\", alpha=0.5)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.title(\"Trace plot of the samples\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Banana-shaped distribution\n",
    "### Probability density function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability density function (PDF) of the banana-shaped distribution is given by:\n",
    "\n",
    "$$\n",
    "p(x_1, x_2) = \\frac{1}{2\\pi\\sigma_1\\sigma_2} \\exp\\left(-\\frac{1}{2} \\frac{x_1^2}{\\sigma_1^2} \\right) + \\exp\\left(-\\frac{1}{2}\\frac{(x_2 - a x_1^2)^2}{\\sigma_2^2}\\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\sigma_1 $ and $ \\sigma_2 $ are the standard deviations.\n",
    "- $ a $ is a parameter that controls the curvature of the banana shape.\n",
    "\n",
    "In this tutorial, we use the following parameters:\n",
    "- $ a = 0.25 $\n",
    "- $ \\sigma_1 = 2 $\n",
    "- $ \\sigma_2 = 0.5 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function to compute the PDF of the banana-shaped distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prob_banana_dist(x, a = 0.25, sigma1 = 2, sigma2 = 0.5):\n",
    "    x1, x2 = x[0], x[1]\n",
    "    prob = jnp.exp(-0.5 * x1**2 / sigma1**2 - 0.5 * (x2 - a * x1**2)**2 / sigma2**2)\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the PDF of the banana-shaped distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "x1 = jnp.linspace(-5, 5, 100)\n",
    "x2 = jnp.linspace(-2, 8, 100)\n",
    "\n",
    "X1, X2 = jnp.meshgrid(x1, x2)\n",
    "X = jnp.stack([X1, X2], axis=-1)\n",
    "\n",
    "prob = vmap(vmap(compute_prob_banana_dist))(X)\n",
    "plt.contourf(X1, X2, prob, 20)\n",
    "plt.colorbar()\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.title(\"Log probability contour of the target distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample using Metropolis-Hastings algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_proposal_banana(key, x):\n",
    "    return x + jr.normal(key, (2,)) * jnp.array([0.5, 0.5])\n",
    "\n",
    "@jit\n",
    "def one_step_banana(key, x):\n",
    "    subkey, key = jr.split(key)\n",
    "    x_proposal = generate_proposal_banana(subkey, x)\n",
    "    p_x = compute_prob_banana_dist(x)\n",
    "    p_x_proposal = compute_prob_banana_dist(x_proposal)\n",
    "\n",
    "    accept_prob = jnp.min(jnp.array([1, p_x_proposal / p_x]))   \n",
    "    \n",
    "    u = jr.uniform(key)\n",
    "    x_new = jnp.where(u < accept_prob, x_proposal, x)\n",
    "\n",
    "    return x_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Metropolis-Hastings algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## generate a random initial point\n",
    "subkey1, subkey2, key = jr.split(key, 3)\n",
    "\n",
    "x_init = jnp.concatenate(\n",
    "    [\n",
    "        jr.uniform(subkey1, (1,), minval=-5, maxval=5),\n",
    "        jr.uniform(subkey2, (1,), minval=-2, maxval=8),\n",
    "    ]\n",
    ")\n",
    "print(f\"Initial point: {x_init}\")\n",
    "\n",
    "## generate samples\n",
    "num_samples = 3000\n",
    "samples = [x_init]\n",
    "for i in tqdm(range(num_samples)):\n",
    "    key, subkey = jr.split(key)\n",
    "    x_init = one_step_banana(subkey, x_init)\n",
    "    samples.append(x_init)\n",
    "samples = jnp.stack(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt.plot(samples[:, 0], samples[:, 1], \".\", alpha=0.5)\n",
    "plt.xlim(-5, 5)\n",
    "plt.ylim(-2, 8)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.title(\"Samples from the banana distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt.plot(samples[:, 0], label=\"x1\", alpha=0.5)\n",
    "plt.plot(samples[:, 1], label=\"x2\", alpha=0.5)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.title(\"Trace plot of the samples\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
