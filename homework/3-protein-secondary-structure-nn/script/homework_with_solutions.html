
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Predict protein secondary structure with deep neural networks &#8212; Chem 193</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../_static/documentation_options.js?v=e645c8fa"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'homework/3-protein-secondary-structure-nn/script/homework_with_solutions';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Chem 193</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../schedule.html">Schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../syllabus.html">Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../lecture.html">Lecture Slides</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../tutorial/index.html">Tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/python-basics.html">Python Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/numpy-jax.html">Numpy &amp; JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/linear-regression.html">Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/hpc.html">High Performance Computing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/jax-nn.html">Neural networks with JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/sample-from-probability-distributions.html">Sample from probability distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/metropolis-hastings-algorithm.html">Metropolis-Hastings Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorial/molecular-simulations-with-openmm.html">Molecular dynamics simulations with OpenMM</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../index.html">Homeworks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../0-linear-algebra.html">Linear Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1-python-basics/main.html">Processing protein MSA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../2-protein-secondary-structure/script/main.html">Predicting protein secondary structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="main.html">Predicting protein secondary structure with neural networks</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/DingGroup/Chem-193" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/homework/3-protein-secondary-structure-nn/script/homework_with_solutions.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Predict protein secondary structure with deep neural networks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Input-and-output-of-the-neural-network-model">Input and output of the neural network model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Process-the-training-data">Process the training data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#The-neural-network-model">The neural network model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Training-the-model">Training the model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Train-the-model-using-stochastic-gradient-descent-(SGD)-with-the-Adam-optimizer">Train the model using stochastic gradient descent (SGD) with the Adam optimizer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Plot-the-loss-and-accuracy-curves-during-training">Plot the loss and accuracy curves during training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Save-the-model-with-the-highest-validation-accuracy">Save the model with the highest validation accuracy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Make-predictions-on-the-test-data">Make predictions on the test data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Submission-instructions">Submission instructions</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Predict-protein-secondary-structure-with-deep-neural-networks">
<h1>Predict protein secondary structure with deep neural networks<a class="headerlink" href="#Predict-protein-secondary-structure-with-deep-neural-networks" title="Link to this heading">#</a></h1>
<p><strong>Author</strong>: YOUR_NAME</p>
<p><strong>Due date</strong>: March 30, 2025, 11:59 PM</p>
<p>This assignment is similar to the <a class="reference external" href="https://dinglab.io/chem193/homework/2-protein-secondary-structure/script/main.html#">previous one</a> but uses deep neural networks instead of simple linear models. It also uses larger datasets. The training and test datasets are provided in the text files <a class="reference external" href="https://tufts.box.com/s/y4t82o03hhf92zw6dik0x9r7v09qdyhs">train.txt</a> and <a class="reference external" href="https://tufts.box.com/s/v4ypbippcsnifjlkd7vrp478bb7ue92l">test.txt</a>, respectively. The format of the datasets is the same as in
the previous assignment. The task is to train a deep neural network model using the training dataset and predict the secondary structure of the proteins using their sequences in the test dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">equinox</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">eqx</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">optax</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sys</span><span class="w"> </span><span class="kn">import</span> <span class="n">exit</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.random</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jr</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
</pre></div>
</div>
</div>
<section id="Input-and-output-of-the-neural-network-model">
<h2>Input and output of the neural network model<a class="headerlink" href="#Input-and-output-of-the-neural-network-model" title="Link to this heading">#</a></h2>
<p>Similary to the previous assignment, the model will predict the secondary structure of a protein using the sliding window approach. It predicts the secondary structure of a residue based on a window of residues centered at that residue. In the previous assignment, the window size was 15. In this assignment, the window size is a hyperparameter that you can choose. The default value is 31, but you can change it to any odd number.</p>
<p>Assume that the window size is <code class="docutils literal notranslate"><span class="pre">k</span></code>. The input to the neural network model is a 1d array of <code class="docutils literal notranslate"><span class="pre">k</span></code> integers, each representing the index of that residue in the amino acid alphabet, <code class="docutils literal notranslate"><span class="pre">ACDEFGHIKLMNPQRSTVWY*</span></code>. For example, if <code class="docutils literal notranslate"><span class="pre">k</span> <span class="pre">=</span> <span class="pre">5</span></code>, the sequence <code class="docutils literal notranslate"><span class="pre">ACACG</span></code> will be represented as <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">0,</span> <span class="pre">1,</span> <span class="pre">5]</span></code>. The output of the model is a 1d array of 3 floats, each representing the logorihtm of the probability of the corresponding secondary structure, <code class="docutils literal notranslate"><span class="pre">helix</span></code>, <code class="docutils literal notranslate"><span class="pre">strand</span></code>, and <code class="docutils literal notranslate"><span class="pre">other</span></code>. For example, the
output <code class="docutils literal notranslate"><span class="pre">[-1.0986123,</span> <span class="pre">-1.0986123,</span> <span class="pre">-1.0986123]</span></code> represents the probabilities <code class="docutils literal notranslate"><span class="pre">[0.333,</span> <span class="pre">0.333,</span> <span class="pre">0.333]</span></code> for the secondary structures <code class="docutils literal notranslate"><span class="pre">helix</span></code>, <code class="docutils literal notranslate"><span class="pre">strand</span></code>, and <code class="docutils literal notranslate"><span class="pre">other</span></code>, respectively.</p>
<section id="Process-the-training-data">
<h3>Process the training data<a class="headerlink" href="#Process-the-training-data" title="Link to this heading">#</a></h3>
<p>Given the design of the model, the data in <code class="docutils literal notranslate"><span class="pre">train.txt</span></code> are not directly suitable for training. The data need to be processed to create the input and output pairs for the model. For each sequence in the training data, we extract all windows of size <code class="docutils literal notranslate"><span class="pre">k</span></code> and convert both the amino acid sequence and the secondary structure to the integer representation. The following two code cells show how it is done.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## you need to change `path_to_train` to the path of the train.txt file</span>
<span class="n">path_to_train</span> <span class="o">=</span> <span class="s2">&quot;../data/train.txt&quot;</span>

<span class="c1">## read data from train.txt</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1">## train_seq is a dictionary with the following structure:</span>
<span class="c1">## train_seq[protein_name] = (sequence, secondary_structure),</span>
<span class="c1">## where protein_name is the name of the protein, sequence is the amino acid sequence of the protein, and secondary_structure is the secondary structure of the protein as given in the train.txt file</span>


<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path_to_train</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;&gt;&quot;</span><span class="p">):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]</span>
            <span class="n">train_data</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">train_data</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>


<span class="c1">## here we split the data into training and validation data</span>
<span class="c1">## we use 80% of the data for training and 20% for validation</span>

<span class="n">names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">train_data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">names_validation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)</span><span class="o">*</span><span class="mf">0.2</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">valid_data</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">train_data</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names_validation</span><span class="p">}</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names_validation</span><span class="p">:</span>
    <span class="n">train_data</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of training samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of validation samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Number of training samples: 34331
Number of validation samples: 8582
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_windows_per_seq</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="n">secondary_structure</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">31</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Get windows for a single sequence</span>

<span class="sd">    Args:</span>
<span class="sd">        seq (str): amino acid sequence</span>
<span class="sd">        secondary_structure (str): secondary structure</span>
<span class="sd">        window_size (int): window size</span>

<span class="sd">    Returns:</span>
<span class="sd">        xs (np.array): input windows</span>
<span class="sd">        ys (np.array): output windows</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">## amino acid order</span>
    <span class="n">amino_acids</span> <span class="o">=</span> <span class="s2">&quot;ACDEFGHIKLMNPQRSTVWY*&quot;</span>

    <span class="n">seq</span> <span class="o">=</span> <span class="p">[</span><span class="n">amino_acids</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">window_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">):</span>
        <span class="n">seq</span> <span class="o">=</span> <span class="p">[</span><span class="n">amino_acids</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">)]</span> <span class="o">+</span> <span class="n">seq</span> <span class="o">+</span> <span class="p">[</span><span class="n">amino_acids</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">)]</span>

    <span class="n">windows</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">window_size</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span> <span class="o">-</span> <span class="n">window_size</span><span class="o">//</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">seq</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="n">window_size</span><span class="o">//</span><span class="mi">2</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">window_size</span><span class="o">//</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">secondary_structure</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="n">window_size</span><span class="o">//</span><span class="mi">2</span><span class="p">])</span>

        <span class="n">windows</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

    <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">windows</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">windows</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_windows</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">31</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Get windows for a dataset&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        data (dict): dataset</span>
<span class="sd">        window_size (int): window size</span>

<span class="sd">    Returns:</span>
<span class="sd">        xs (np.array): input windows</span>
<span class="sd">        ys (np.array): output windows</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">xs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
        <span class="n">seq</span><span class="p">,</span> <span class="n">ss</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">get_windows_per_seq</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="n">ss</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="n">window_size</span><span class="p">)</span>
        <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## the default window size is 31 amino acids (15 on each side of the central amino acid)</span>
<span class="c1">## you can change the window size by changing the value of the window_size variable</span>
<span class="n">window_size</span> <span class="o">=</span> <span class="mi">31</span>

<span class="c1">## get windows for training and validation data</span>
<span class="n">train_xs</span><span class="p">,</span> <span class="n">train_ys</span> <span class="o">=</span> <span class="n">get_windows</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">window_size</span><span class="p">)</span>
<span class="n">valid_xs</span><span class="p">,</span> <span class="n">valid_ys</span> <span class="o">=</span> <span class="n">get_windows</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">window_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 34331/34331 [00:51&lt;00:00, 663.31it/s]
100%|██████████| 8582/8582 [00:11&lt;00:00, 722.15it/s]
</pre></div></div>
</div>
</section>
</section>
<section id="The-neural-network-model">
<h2>The neural network model<a class="headerlink" href="#The-neural-network-model" title="Link to this heading">#</a></h2>
<p>You need to implement a deep neural network model using the <code class="docutils literal notranslate"><span class="pre">equinox</span></code> library. The input and output of the model are described above.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">############################################################################################################  write your code for the following NeuralNetwork class (50 points)</span>
<span class="c1">####################################################################################################</span>
<span class="k">class</span><span class="w"> </span><span class="nc">NeuralNetwork</span><span class="p">(</span><span class="n">eqx</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">emb</span><span class="p">:</span> <span class="n">eqx</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span>
    <span class="n">emb_layer</span><span class="p">:</span> <span class="nb">list</span>
    <span class="n">res_layer_1</span><span class="p">:</span> <span class="nb">list</span>
    <span class="n">res_layer_2</span><span class="p">:</span> <span class="nb">list</span>
    <span class="n">res_layer_3</span><span class="p">:</span> <span class="nb">list</span>
    <span class="n">output_layer</span><span class="p">:</span> <span class="nb">list</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="n">subkey</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">eqx</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="mi">21</span><span class="p">,</span> <span class="n">embedding_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">subkey</span><span class="p">)</span>
        <span class="n">emb_size</span> <span class="o">=</span> <span class="mi">16</span><span class="o">*</span><span class="n">window_size</span>
        <span class="n">res_size</span> <span class="o">=</span> <span class="mi">32</span>

        <span class="n">subkey</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb_layer</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">eqx</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">emb_size</span><span class="p">,</span> <span class="n">res_size</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">subkey</span><span class="p">),</span>
            <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="p">]</span>

        <span class="n">subkey1</span><span class="p">,</span> <span class="n">subkey2</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">res_layer_1</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">eqx</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">res_size</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">subkey1</span><span class="p">),</span>
            <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
            <span class="n">eqx</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">res_size</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">subkey2</span><span class="p">),</span>
            <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="p">]</span>

        <span class="n">subkey1</span><span class="p">,</span> <span class="n">subkey2</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">res_layer_2</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">eqx</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">res_size</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">subkey1</span><span class="p">),</span>
            <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
            <span class="n">eqx</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">res_size</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">subkey2</span><span class="p">),</span>
            <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="p">]</span>

        <span class="n">subkey1</span><span class="p">,</span> <span class="n">subkey2</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">res_layer_3</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">eqx</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">res_size</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">subkey1</span><span class="p">),</span>
            <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
            <span class="n">eqx</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">res_size</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">subkey2</span><span class="p">),</span>
            <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="p">]</span>

        <span class="n">subkey1</span><span class="p">,</span> <span class="n">subkey2</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">eqx</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">res_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">subkey1</span><span class="p">),</span>
            <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">,</span>
        <span class="p">]</span>


    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Forward pass</span>

<span class="sd">        Args:</span>
<span class="sd">            x (jnp.array): 1D array of integers representing amino acids in a window</span>

<span class="sd">        Returns:</span>
<span class="sd">            logp (jnp.array): 1D array of 3 floats representing log-probabilities of secondary structure classes</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_layer</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x_ini</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">res_layer_1</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x_ini</span>

        <span class="n">x_ini</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">res_layer_2</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x_ini</span>

        <span class="n">x_ini</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">res_layer_3</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x_ini</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>
<br/></pre></div>
</div>
</div>
</section>
<section id="Training-the-model">
<h2>Training the model<a class="headerlink" href="#Training-the-model" title="Link to this heading">#</a></h2>
<p>To train the model, you need to finish the implementation of the <code class="docutils literal notranslate"><span class="pre">loss_fn</span></code> function. The function takes the model, a batch of input and output pairs, and returns the loss. The loss should be the same as the loss function used in the previous assignment. To monitor the training process, you also need to implement the three functions: <code class="docutils literal notranslate"><span class="pre">make_predictions</span></code>, and <code class="docutils literal notranslate"><span class="pre">compute_accuracy</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Note that you could comment the @eqx.filter_jit decorator during the development of the loss function so that the error messages are more informative. Once the loss function is working, you can uncomment the decorator to speed up the training process. The same applies to the make_predictions function</span>

<span class="nd">@eqx</span><span class="o">.</span><span class="n">filter_jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">loss_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Loss function for a batch of windows</span>

<span class="sd">    Args:</span>
<span class="sd">        model (NeuralNetwork): neural network model</span>
<span class="sd">        xs (jnp.array): 2D array of integers representing amino acids in windows. Shape:(batch_size, window_size)</span>
<span class="sd">        ys (jnp.array): 1D array of integers representing secondary structure classes. Shape: (batch_size,)</span>

<span class="sd">    Returns:</span>
<span class="sd">        loss (jnp.array): the average loss over the batch</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">##############################################################################################</span>
    <span class="c1">#### write your code loss function (15 points)</span>
    <span class="c1">###############################################################################################</span>
    <span class="n">log_prob</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">model</span><span class="p">)(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_prob</span> <span class="o">*</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">loss</span>



<span class="nd">@eqx</span><span class="o">.</span><span class="n">filter_jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">make_predictions</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">xs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Make predictions for a batch of windows&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        model (NeuralNetwork): neural network model</span>
<span class="sd">        xs (jnp.array): 2D array of integers representing amino acids in windows. Shape:(batch_size, window_size)</span>

<span class="sd">    Returns:</span>
<span class="sd">        predictions (jnp.array): 1D array of integers representing predicted secondary structure classes. Shape: (batch_size,)</span>

<span class="sd">    &quot;&quot;&quot;</span>


    <span class="c1">################################################</span>
    <span class="c1">#### write your code loss function (15 points)</span>
    <span class="c1">################################################</span>


    <span class="n">log_prob</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">model</span><span class="p">)(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">log_prob</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">predictions</span>


<span class="k">def</span><span class="w"> </span><span class="nf">compute_average_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="o">*</span><span class="mi">16</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Compute average loss for a dataset of windows by batching</span>

<span class="sd">    Args:</span>
<span class="sd">        model (NeuralNetwork): neural network model</span>
<span class="sd">        xs (jnp.array): 2D array of integers representing amino acids in windows. Shape:(num_samples, window_size)</span>
<span class="sd">        ys (jnp.array): 1D array of integers representing secondary structure classes. Shape: (num_samples,)</span>
<span class="sd">        batch_size (int): batch size</span>

<span class="sd">    Returns:</span>
<span class="sd">        loss (float): average loss over the dataset</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">idx_batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
        <span class="n">start_idx</span> <span class="o">=</span> <span class="n">idx_batch</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="n">end_idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">batch_size</span>
        <span class="n">batch_xs</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
        <span class="n">batch_ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch_xs</span><span class="p">,</span> <span class="n">batch_ys</span><span class="p">)</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">batch_xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>


<span class="k">def</span><span class="w"> </span><span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="o">*</span><span class="mi">16</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Compute accuracy for a dataset of windows by batching&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        model (NeuralNetwork): neural network model</span>
<span class="sd">        xs (jnp.array): 2D array of integers representing amino acids in windows. Shape:(num_samples, window_size)</span>
<span class="sd">        ys (jnp.array): 1D array of integers representing secondary structure classes. Shape: (num_samples,)</span>
<span class="sd">        batch_size (int): batch size</span>

<span class="sd">    Returns:</span>
<span class="sd">        accuracy (float): accuracy over the dataset</span>
<span class="sd">    &quot;&quot;&quot;</span>


    <span class="c1">#####################################################</span>
    <span class="c1">####  write your code loss function (10 points)  ####</span>
    <span class="c1">#####################################################</span>


    <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">idx_batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
        <span class="n">start_idx</span> <span class="o">=</span> <span class="n">idx_batch</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="n">end_idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">batch_size</span>
        <span class="n">batch_xs</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
        <span class="n">batch_ys</span> <span class="o">=</span> <span class="n">ys</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">make_predictions</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch_xs</span><span class="p">)</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">batch_ys</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_ys</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
<br/><br/><br/></pre></div>
</div>
</div>
<section id="Train-the-model-using-stochastic-gradient-descent-(SGD)-with-the-Adam-optimizer">
<h3>Train the model using stochastic gradient descent (SGD) with the Adam optimizer<a class="headerlink" href="#Train-the-model-using-stochastic-gradient-descent-(SGD)-with-the-Adam-optimizer" title="Link to this heading">#</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## initialize the model</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNetwork</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>


<span class="c1">## initialize the optimizer</span>
<span class="c1">## the learning rate is set to 0.001</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">adamw</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">opt_state</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">eqx</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">eqx</span><span class="o">.</span><span class="n">is_array</span><span class="p">))</span>

<span class="c1">## training loop</span>
<span class="c1">## Note that you could comment the @eqx.filter_jit decorator during the development so that the error messages are more informative. Once you are done, you can uncomment the decorator to speed up the training process</span>
<span class="nd">@eqx</span><span class="o">.</span><span class="n">filter_jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">make_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch_xs</span><span class="p">,</span> <span class="n">batch_ys</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Make a single optimization step using a batch of windows</span>

<span class="sd">    Args:</span>
<span class="sd">        model (NeuralNetwork): neural network model</span>
<span class="sd">        batch_xs (jnp.array): 2D array of integers representing amino acids in windows. Shape:(batch_size, window_size)</span>
<span class="sd">        batch_ys (jnp.array): 1D array of integers representing secondary structure classes. Shape: (batch_size,)</span>
<span class="sd">        opt_state (optax.OptState): optimizer state</span>

<span class="sd">    Returns:</span>
<span class="sd">        model (NeuralNetwork): updated neural network model</span>
<span class="sd">        opt_state (optax.OptState): updated optimizer state</span>
<span class="sd">        loss_value (float): loss value for the batch</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">loss_value</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">eqx</span><span class="o">.</span><span class="n">filter_value_and_grad</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">)(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch_xs</span><span class="p">,</span> <span class="n">batch_ys</span><span class="p">)</span>
    <span class="n">updates</span><span class="p">,</span> <span class="n">opt_state</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="n">grads</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">,</span> <span class="n">eqx</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">eqx</span><span class="o">.</span><span class="n">is_array</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">eqx</span><span class="o">.</span><span class="n">apply_updates</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">,</span> <span class="n">loss_value</span>
</pre></div>
</div>
</div>
<p>The following code cell shows how to train the model using the Adam optimizer. We monitor the training process by computing the loss and accuracy on the training and validation datasets after each epoch.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## set the number of epochs and batch size</span>
<span class="c1">## you can change both as needed</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">16</span>

<span class="n">train_loss_record</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valid_loss_record</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_accuracy_record</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valid_accuracy_record</span> <span class="o">=</span> <span class="p">[]</span>


<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_xs</span><span class="p">))</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
    <span class="n">train_xs</span> <span class="o">=</span> <span class="n">train_xs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="n">train_ys</span> <span class="o">=</span> <span class="n">train_ys</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_xs</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>
    <span class="k">for</span> <span class="n">idx_batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
        <span class="n">start_idx</span> <span class="o">=</span> <span class="n">idx_batch</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="n">end_idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">batch_size</span>
        <span class="n">batch_xs</span> <span class="o">=</span> <span class="n">train_xs</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
        <span class="n">batch_ys</span> <span class="o">=</span> <span class="n">train_ys</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>

        <span class="n">model</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">,</span> <span class="n">loss_value</span> <span class="o">=</span> <span class="n">make_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch_xs</span><span class="p">,</span> <span class="n">batch_ys</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">idx_batch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="s2">5&gt;d</span><span class="si">}</span><span class="s2">, batch </span><span class="si">{</span><span class="n">idx_batch</span><span class="si">:</span><span class="s2">5&gt;d</span><span class="si">}</span><span class="s2">, train_loss </span><span class="si">{</span><span class="n">loss_value</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">compute_average_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_xs</span><span class="p">,</span> <span class="n">train_ys</span><span class="p">)</span>
    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_xs</span><span class="p">,</span> <span class="n">train_ys</span><span class="p">)</span>

    <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">compute_average_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_xs</span><span class="p">,</span> <span class="n">valid_ys</span><span class="p">)</span>
    <span class="n">valid_accuracy</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_xs</span><span class="p">,</span> <span class="n">valid_ys</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="s2">&gt;5d</span><span class="si">}</span><span class="s2">, train_loss </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">, valid_loss </span><span class="si">{</span><span class="n">valid_loss</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">, train_accuracy </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s2">7.2%</span><span class="si">}</span><span class="s2">, valid_accuracy </span><span class="si">{</span><span class="n">valid_accuracy</span><span class="si">:</span><span class="s2">7.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">train_loss_record</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
    <span class="n">valid_loss_record</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_loss</span><span class="p">)</span>
    <span class="n">train_accuracy_record</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
    <span class="n">valid_accuracy_record</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_accuracy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
epoch 0, batch 0, train_loss 1.090
epoch 0, batch 10, train_loss 1.006
epoch 0, batch 20, train_loss 0.951
epoch 0, batch 30, train_loss 0.926
epoch 0, batch 40, train_loss 0.902
epoch 0, batch 50, train_loss 0.890
epoch 0, batch 60, train_loss 0.868
epoch 0, batch 70, train_loss 0.865
epoch 0, batch 80, train_loss 0.854
epoch 0, batch 90, train_loss 0.852
epoch 0, batch 100, train_loss 0.849
epoch 0, batch 110, train_loss 0.842
epoch 0, batch 120, train_loss 0.836
epoch 0, batch 130, train_loss 0.841
epoch 0, batch 140, train_loss 0.831
epoch 0, batch 150, train_loss 0.825
epoch 0, batch 160, train_loss 0.817
epoch 0, batch 170, train_loss 0.813
epoch 0, batch 180, train_loss 0.805
epoch 0, batch 190, train_loss 0.804
epoch 0, batch 200, train_loss 0.809
epoch 0, batch 210, train_loss 0.797
epoch 0, batch 220, train_loss 0.789
epoch 0, batch 230, train_loss 0.786
epoch 0, batch 240, train_loss 0.776
epoch 0, batch 250, train_loss 0.773
epoch 0, batch 260, train_loss 0.774
epoch 0, batch 270, train_loss 0.773
epoch 0, batch 280, train_loss 0.765
epoch 0, batch 290, train_loss 0.765
epoch 0, batch 300, train_loss 0.775
epoch 0, batch 310, train_loss 0.763
epoch 0, batch 320, train_loss 0.770
epoch 0, batch 330, train_loss 0.762
epoch 0, batch 340, train_loss 0.764
epoch 0, batch 350, train_loss 0.767
epoch 0, batch 360, train_loss 0.757
epoch 0, batch 370, train_loss 0.764
epoch 0, batch 380, train_loss 0.757
epoch 0, batch 390, train_loss 0.755
epoch 0, batch 400, train_loss 0.746
epoch 0, batch 410, train_loss 0.757
epoch 0, batch 420, train_loss 0.755
epoch 0, batch 430, train_loss 0.757
epoch 0, batch 440, train_loss 0.750
epoch 0, batch 450, train_loss 0.757
epoch 0, batch 460, train_loss 0.748
epoch 0, batch 470, train_loss 0.755
epoch 0, batch 480, train_loss 0.755
epoch 0, batch 490, train_loss 0.753
epoch 0, batch 500, train_loss 0.754
epoch 0, batch 510, train_loss 0.747
epoch 0, batch 520, train_loss 0.740
epoch 0, batch 530, train_loss 0.748
epoch 0, batch 540, train_loss 0.743
epoch 0, batch 550, train_loss 0.750
epoch 0, batch 560, train_loss 0.742
epoch 0, batch 570, train_loss 0.741
epoch 0, batch 580, train_loss 0.752
epoch 0, batch 590, train_loss 0.747
epoch 0, batch 600, train_loss 0.748
epoch 0, batch 610, train_loss 0.739
epoch 0, batch 620, train_loss 0.737
epoch 0, batch 630, train_loss 0.745
epoch 0, batch 640, train_loss 0.743
epoch 0, batch 650, train_loss 0.743
epoch 0, batch 660, train_loss 0.742
epoch 0, batch 670, train_loss 0.738
epoch 0, batch 680, train_loss 0.738
epoch 0, batch 690, train_loss 0.742
epoch 0, batch 700, train_loss 0.746
epoch 0, batch 710, train_loss 0.753
epoch 0, batch 720, train_loss 0.747
epoch 0, batch 730, train_loss 0.733
epoch 0, batch 740, train_loss 0.733
epoch 0, batch 750, train_loss 0.739
epoch 0, batch 760, train_loss 0.733
epoch 0, batch 770, train_loss 0.734
epoch 0, batch 780, train_loss 0.739
epoch 0, batch 790, train_loss 0.734
epoch 0, batch 800, train_loss 0.734
epoch 0, batch 810, train_loss 0.741
epoch 0, batch 820, train_loss 0.731
epoch 0, batch 830, train_loss 0.733
epoch 0, batch 840, train_loss 0.724
epoch 0, batch 850, train_loss 0.745
epoch 0, batch 860, train_loss 0.733
epoch 0, batch 870, train_loss 0.747
epoch 0, batch 880, train_loss 0.720
epoch 0, batch 890, train_loss 0.736
epoch 0, batch 900, train_loss 0.743
epoch 0, batch 910, train_loss 0.736
epoch 0, batch 920, train_loss 0.730
epoch 0, batch 930, train_loss 0.737
epoch 0, batch 940, train_loss 0.735
epoch 0, batch 950, train_loss 0.740
epoch 0, batch 960, train_loss 0.738
epoch 0, batch 970, train_loss 0.732
epoch 0, batch 980, train_loss 0.730
epoch 0, batch 990, train_loss 0.729
epoch 0, batch 1000, train_loss 0.729
epoch 0, batch 1010, train_loss 0.734
epoch 0, batch 1020, train_loss 0.727
epoch 0, batch 1030, train_loss 0.736
epoch 0, batch 1040, train_loss 0.728
epoch 0, batch 1050, train_loss 0.730
epoch 0, batch 1060, train_loss 0.726
epoch 0, batch 1070, train_loss 0.732
epoch 0, batch 1080, train_loss 0.739
epoch 0, batch 1090, train_loss 0.736
epoch 0, batch 1100, train_loss 0.731
epoch 0, batch 1110, train_loss 0.728
epoch 0, batch 1120, train_loss 0.735
epoch 0, batch 1130, train_loss 0.741
epoch 0, batch 1140, train_loss 0.740
epoch 0, batch 1150, train_loss 0.731
epoch 0, batch 1160, train_loss 0.734
epoch 0, batch 1170, train_loss 0.728
epoch 0, batch 1180, train_loss 0.729
epoch 0, batch 1190, train_loss 0.731
epoch     0, train_loss 0.730, valid_loss 0.740, train_accuracy  68.26%, valid_accuracy  67.72%
epoch 1, batch 0, train_loss 0.737
epoch 1, batch 10, train_loss 0.730
epoch 1, batch 20, train_loss 0.738
epoch 1, batch 30, train_loss 0.729
epoch 1, batch 40, train_loss 0.720
epoch 1, batch 50, train_loss 0.737
epoch 1, batch 60, train_loss 0.727
epoch 1, batch 70, train_loss 0.731
epoch 1, batch 80, train_loss 0.729
epoch 1, batch 90, train_loss 0.730
epoch 1, batch 100, train_loss 0.723
epoch 1, batch 110, train_loss 0.724
epoch 1, batch 120, train_loss 0.731
epoch 1, batch 130, train_loss 0.721
epoch 1, batch 140, train_loss 0.727
epoch 1, batch 150, train_loss 0.727
epoch 1, batch 160, train_loss 0.729
epoch 1, batch 170, train_loss 0.715
epoch 1, batch 180, train_loss 0.720
epoch 1, batch 190, train_loss 0.732
epoch 1, batch 200, train_loss 0.733
epoch 1, batch 210, train_loss 0.720
epoch 1, batch 220, train_loss 0.732
epoch 1, batch 230, train_loss 0.717
epoch 1, batch 240, train_loss 0.736
epoch 1, batch 250, train_loss 0.727
epoch 1, batch 260, train_loss 0.726
epoch 1, batch 270, train_loss 0.715
epoch 1, batch 280, train_loss 0.718
epoch 1, batch 290, train_loss 0.721
epoch 1, batch 300, train_loss 0.731
epoch 1, batch 310, train_loss 0.730
epoch 1, batch 320, train_loss 0.734
epoch 1, batch 330, train_loss 0.730
epoch 1, batch 340, train_loss 0.727
epoch 1, batch 350, train_loss 0.739
epoch 1, batch 360, train_loss 0.728
epoch 1, batch 370, train_loss 0.718
epoch 1, batch 380, train_loss 0.728
epoch 1, batch 390, train_loss 0.717
epoch 1, batch 400, train_loss 0.732
epoch 1, batch 410, train_loss 0.715
epoch 1, batch 420, train_loss 0.724
epoch 1, batch 430, train_loss 0.719
epoch 1, batch 440, train_loss 0.720
epoch 1, batch 450, train_loss 0.720
epoch 1, batch 460, train_loss 0.731
epoch 1, batch 470, train_loss 0.732
epoch 1, batch 480, train_loss 0.725
epoch 1, batch 490, train_loss 0.727
epoch 1, batch 500, train_loss 0.726
epoch 1, batch 510, train_loss 0.723
epoch 1, batch 520, train_loss 0.717
epoch 1, batch 530, train_loss 0.719
epoch 1, batch 540, train_loss 0.738
epoch 1, batch 550, train_loss 0.721
epoch 1, batch 560, train_loss 0.717
epoch 1, batch 570, train_loss 0.720
epoch 1, batch 580, train_loss 0.737
epoch 1, batch 590, train_loss 0.721
epoch 1, batch 600, train_loss 0.718
epoch 1, batch 610, train_loss 0.721
epoch 1, batch 620, train_loss 0.730
epoch 1, batch 630, train_loss 0.725
epoch 1, batch 640, train_loss 0.726
epoch 1, batch 650, train_loss 0.720
epoch 1, batch 660, train_loss 0.725
epoch 1, batch 670, train_loss 0.716
epoch 1, batch 680, train_loss 0.726
epoch 1, batch 690, train_loss 0.724
epoch 1, batch 700, train_loss 0.733
epoch 1, batch 710, train_loss 0.722
epoch 1, batch 720, train_loss 0.718
epoch 1, batch 730, train_loss 0.729
epoch 1, batch 740, train_loss 0.719
epoch 1, batch 750, train_loss 0.724
epoch 1, batch 760, train_loss 0.724
epoch 1, batch 770, train_loss 0.729
epoch 1, batch 780, train_loss 0.726
epoch 1, batch 790, train_loss 0.721
epoch 1, batch 800, train_loss 0.713
epoch 1, batch 810, train_loss 0.727
epoch 1, batch 820, train_loss 0.720
epoch 1, batch 830, train_loss 0.729
epoch 1, batch 840, train_loss 0.731
epoch 1, batch 850, train_loss 0.726
epoch 1, batch 860, train_loss 0.715
epoch 1, batch 870, train_loss 0.729
epoch 1, batch 880, train_loss 0.722
epoch 1, batch 890, train_loss 0.721
epoch 1, batch 900, train_loss 0.725
epoch 1, batch 910, train_loss 0.723
epoch 1, batch 920, train_loss 0.717
epoch 1, batch 930, train_loss 0.731
epoch 1, batch 940, train_loss 0.727
epoch 1, batch 950, train_loss 0.721
epoch 1, batch 960, train_loss 0.715
epoch 1, batch 970, train_loss 0.720
epoch 1, batch 980, train_loss 0.723
epoch 1, batch 990, train_loss 0.722
epoch 1, batch 1000, train_loss 0.716
epoch 1, batch 1010, train_loss 0.726
epoch 1, batch 1020, train_loss 0.720
epoch 1, batch 1030, train_loss 0.723
epoch 1, batch 1040, train_loss 0.728
epoch 1, batch 1050, train_loss 0.725
epoch 1, batch 1060, train_loss 0.720
epoch 1, batch 1070, train_loss 0.715
epoch 1, batch 1080, train_loss 0.709
epoch 1, batch 1090, train_loss 0.714
epoch 1, batch 1100, train_loss 0.724
epoch 1, batch 1110, train_loss 0.713
epoch 1, batch 1120, train_loss 0.718
epoch 1, batch 1130, train_loss 0.726
epoch 1, batch 1140, train_loss 0.718
epoch 1, batch 1150, train_loss 0.723
epoch 1, batch 1160, train_loss 0.712
epoch 1, batch 1170, train_loss 0.719
epoch 1, batch 1180, train_loss 0.725
epoch 1, batch 1190, train_loss 0.714
epoch     1, train_loss 0.718, valid_loss 0.731, train_accuracy  68.86%, valid_accuracy  68.22%
epoch 2, batch 0, train_loss 0.723
epoch 2, batch 10, train_loss 0.720
epoch 2, batch 20, train_loss 0.708
epoch 2, batch 30, train_loss 0.720
epoch 2, batch 40, train_loss 0.724
epoch 2, batch 50, train_loss 0.713
epoch 2, batch 60, train_loss 0.711
epoch 2, batch 70, train_loss 0.709
epoch 2, batch 80, train_loss 0.720
epoch 2, batch 90, train_loss 0.723
epoch 2, batch 100, train_loss 0.721
epoch 2, batch 110, train_loss 0.717
epoch 2, batch 120, train_loss 0.713
epoch 2, batch 130, train_loss 0.719
epoch 2, batch 140, train_loss 0.705
epoch 2, batch 150, train_loss 0.713
epoch 2, batch 160, train_loss 0.710
epoch 2, batch 170, train_loss 0.728
epoch 2, batch 180, train_loss 0.719
epoch 2, batch 190, train_loss 0.724
epoch 2, batch 200, train_loss 0.712
epoch 2, batch 210, train_loss 0.720
epoch 2, batch 220, train_loss 0.717
epoch 2, batch 230, train_loss 0.722
epoch 2, batch 240, train_loss 0.723
epoch 2, batch 250, train_loss 0.720
epoch 2, batch 260, train_loss 0.724
epoch 2, batch 270, train_loss 0.718
epoch 2, batch 280, train_loss 0.714
epoch 2, batch 290, train_loss 0.709
epoch 2, batch 300, train_loss 0.719
epoch 2, batch 310, train_loss 0.725
epoch 2, batch 320, train_loss 0.725
epoch 2, batch 330, train_loss 0.724
epoch 2, batch 340, train_loss 0.713
epoch 2, batch 350, train_loss 0.719
epoch 2, batch 360, train_loss 0.721
epoch 2, batch 370, train_loss 0.723
epoch 2, batch 380, train_loss 0.709
epoch 2, batch 390, train_loss 0.713
epoch 2, batch 400, train_loss 0.712
epoch 2, batch 410, train_loss 0.716
epoch 2, batch 420, train_loss 0.711
epoch 2, batch 430, train_loss 0.722
epoch 2, batch 440, train_loss 0.730
epoch 2, batch 450, train_loss 0.719
epoch 2, batch 460, train_loss 0.717
epoch 2, batch 470, train_loss 0.722
epoch 2, batch 480, train_loss 0.720
epoch 2, batch 490, train_loss 0.718
epoch 2, batch 500, train_loss 0.727
epoch 2, batch 510, train_loss 0.716
epoch 2, batch 520, train_loss 0.719
epoch 2, batch 530, train_loss 0.713
epoch 2, batch 540, train_loss 0.710
epoch 2, batch 550, train_loss 0.718
epoch 2, batch 560, train_loss 0.724
epoch 2, batch 570, train_loss 0.718
epoch 2, batch 580, train_loss 0.724
epoch 2, batch 590, train_loss 0.716
epoch 2, batch 600, train_loss 0.729
epoch 2, batch 610, train_loss 0.710
epoch 2, batch 620, train_loss 0.719
epoch 2, batch 630, train_loss 0.715
epoch 2, batch 640, train_loss 0.715
epoch 2, batch 650, train_loss 0.717
epoch 2, batch 660, train_loss 0.716
epoch 2, batch 670, train_loss 0.717
epoch 2, batch 680, train_loss 0.708
epoch 2, batch 690, train_loss 0.716
epoch 2, batch 700, train_loss 0.710
epoch 2, batch 710, train_loss 0.724
epoch 2, batch 720, train_loss 0.727
epoch 2, batch 730, train_loss 0.722
epoch 2, batch 740, train_loss 0.720
epoch 2, batch 750, train_loss 0.719
epoch 2, batch 760, train_loss 0.704
epoch 2, batch 770, train_loss 0.713
epoch 2, batch 780, train_loss 0.724
epoch 2, batch 790, train_loss 0.724
epoch 2, batch 800, train_loss 0.712
epoch 2, batch 810, train_loss 0.708
epoch 2, batch 820, train_loss 0.721
epoch 2, batch 830, train_loss 0.732
epoch 2, batch 840, train_loss 0.718
epoch 2, batch 850, train_loss 0.715
epoch 2, batch 860, train_loss 0.719
epoch 2, batch 870, train_loss 0.715
epoch 2, batch 880, train_loss 0.719
epoch 2, batch 890, train_loss 0.716
epoch 2, batch 900, train_loss 0.721
epoch 2, batch 910, train_loss 0.720
epoch 2, batch 920, train_loss 0.711
epoch 2, batch 930, train_loss 0.715
epoch 2, batch 940, train_loss 0.718
epoch 2, batch 950, train_loss 0.720
epoch 2, batch 960, train_loss 0.719
epoch 2, batch 970, train_loss 0.714
epoch 2, batch 980, train_loss 0.719
epoch 2, batch 990, train_loss 0.718
epoch 2, batch 1000, train_loss 0.704
epoch 2, batch 1010, train_loss 0.726
epoch 2, batch 1020, train_loss 0.715
epoch 2, batch 1030, train_loss 0.714
epoch 2, batch 1040, train_loss 0.723
epoch 2, batch 1050, train_loss 0.718
epoch 2, batch 1060, train_loss 0.719
epoch 2, batch 1070, train_loss 0.712
epoch 2, batch 1080, train_loss 0.709
epoch 2, batch 1090, train_loss 0.716
epoch 2, batch 1100, train_loss 0.714
epoch 2, batch 1110, train_loss 0.714
epoch 2, batch 1120, train_loss 0.718
epoch 2, batch 1130, train_loss 0.712
epoch 2, batch 1140, train_loss 0.714
epoch 2, batch 1150, train_loss 0.718
epoch 2, batch 1160, train_loss 0.718
epoch 2, batch 1170, train_loss 0.712
epoch 2, batch 1180, train_loss 0.707
epoch 2, batch 1190, train_loss 0.713
epoch     2, train_loss 0.713, valid_loss 0.727, train_accuracy  69.11%, valid_accuracy  68.36%
epoch 3, batch 0, train_loss 0.710
epoch 3, batch 10, train_loss 0.713
epoch 3, batch 20, train_loss 0.706
epoch 3, batch 30, train_loss 0.717
epoch 3, batch 40, train_loss 0.715
epoch 3, batch 50, train_loss 0.711
epoch 3, batch 60, train_loss 0.703
epoch 3, batch 70, train_loss 0.717
epoch 3, batch 80, train_loss 0.708
epoch 3, batch 90, train_loss 0.714
epoch 3, batch 100, train_loss 0.711
epoch 3, batch 110, train_loss 0.705
epoch 3, batch 120, train_loss 0.719
epoch 3, batch 130, train_loss 0.708
epoch 3, batch 140, train_loss 0.711
epoch 3, batch 150, train_loss 0.715
epoch 3, batch 160, train_loss 0.730
epoch 3, batch 170, train_loss 0.719
epoch 3, batch 180, train_loss 0.726
epoch 3, batch 190, train_loss 0.714
epoch 3, batch 200, train_loss 0.713
epoch 3, batch 210, train_loss 0.717
epoch 3, batch 220, train_loss 0.717
epoch 3, batch 230, train_loss 0.720
epoch 3, batch 240, train_loss 0.716
epoch 3, batch 250, train_loss 0.703
epoch 3, batch 260, train_loss 0.714
epoch 3, batch 270, train_loss 0.715
epoch 3, batch 280, train_loss 0.717
epoch 3, batch 290, train_loss 0.712
epoch 3, batch 300, train_loss 0.723
epoch 3, batch 310, train_loss 0.717
epoch 3, batch 320, train_loss 0.722
epoch 3, batch 330, train_loss 0.715
epoch 3, batch 340, train_loss 0.719
epoch 3, batch 350, train_loss 0.705
epoch 3, batch 360, train_loss 0.707
epoch 3, batch 370, train_loss 0.720
epoch 3, batch 380, train_loss 0.711
epoch 3, batch 390, train_loss 0.712
epoch 3, batch 400, train_loss 0.711
epoch 3, batch 410, train_loss 0.716
epoch 3, batch 420, train_loss 0.716
epoch 3, batch 430, train_loss 0.712
epoch 3, batch 440, train_loss 0.713
epoch 3, batch 450, train_loss 0.714
epoch 3, batch 460, train_loss 0.712
epoch 3, batch 470, train_loss 0.706
epoch 3, batch 480, train_loss 0.714
epoch 3, batch 490, train_loss 0.714
epoch 3, batch 500, train_loss 0.708
epoch 3, batch 510, train_loss 0.718
epoch 3, batch 520, train_loss 0.724
epoch 3, batch 530, train_loss 0.709
epoch 3, batch 540, train_loss 0.711
epoch 3, batch 550, train_loss 0.704
epoch 3, batch 560, train_loss 0.711
epoch 3, batch 570, train_loss 0.705
epoch 3, batch 580, train_loss 0.712
epoch 3, batch 590, train_loss 0.716
epoch 3, batch 600, train_loss 0.706
epoch 3, batch 610, train_loss 0.718
epoch 3, batch 620, train_loss 0.713
epoch 3, batch 630, train_loss 0.706
epoch 3, batch 640, train_loss 0.715
epoch 3, batch 650, train_loss 0.700
epoch 3, batch 660, train_loss 0.700
epoch 3, batch 670, train_loss 0.721
epoch 3, batch 680, train_loss 0.717
epoch 3, batch 690, train_loss 0.715
epoch 3, batch 700, train_loss 0.717
epoch 3, batch 710, train_loss 0.717
epoch 3, batch 720, train_loss 0.703
epoch 3, batch 730, train_loss 0.705
epoch 3, batch 740, train_loss 0.714
epoch 3, batch 750, train_loss 0.715
epoch 3, batch 760, train_loss 0.708
epoch 3, batch 770, train_loss 0.713
epoch 3, batch 780, train_loss 0.709
epoch 3, batch 790, train_loss 0.704
epoch 3, batch 800, train_loss 0.714
epoch 3, batch 810, train_loss 0.706
epoch 3, batch 820, train_loss 0.715
epoch 3, batch 830, train_loss 0.717
epoch 3, batch 840, train_loss 0.720
epoch 3, batch 850, train_loss 0.716
epoch 3, batch 860, train_loss 0.720
epoch 3, batch 870, train_loss 0.704
epoch 3, batch 880, train_loss 0.718
epoch 3, batch 890, train_loss 0.709
epoch 3, batch 900, train_loss 0.712
epoch 3, batch 910, train_loss 0.712
epoch 3, batch 920, train_loss 0.714
epoch 3, batch 930, train_loss 0.721
epoch 3, batch 940, train_loss 0.710
epoch 3, batch 950, train_loss 0.720
epoch 3, batch 960, train_loss 0.705
epoch 3, batch 970, train_loss 0.709
epoch 3, batch 980, train_loss 0.712
epoch 3, batch 990, train_loss 0.709
epoch 3, batch 1000, train_loss 0.709
epoch 3, batch 1010, train_loss 0.707
epoch 3, batch 1020, train_loss 0.709
epoch 3, batch 1030, train_loss 0.721
epoch 3, batch 1040, train_loss 0.720
epoch 3, batch 1050, train_loss 0.713
epoch 3, batch 1060, train_loss 0.711
epoch 3, batch 1070, train_loss 0.712
epoch 3, batch 1080, train_loss 0.708
epoch 3, batch 1090, train_loss 0.702
epoch 3, batch 1100, train_loss 0.720
epoch 3, batch 1110, train_loss 0.712
epoch 3, batch 1120, train_loss 0.707
epoch 3, batch 1130, train_loss 0.713
epoch 3, batch 1140, train_loss 0.711
epoch 3, batch 1150, train_loss 0.710
epoch 3, batch 1160, train_loss 0.721
epoch 3, batch 1170, train_loss 0.713
epoch 3, batch 1180, train_loss 0.714
epoch 3, batch 1190, train_loss 0.711
epoch     3, train_loss 0.711, valid_loss 0.726, train_accuracy  69.25%, valid_accuracy  68.40%
epoch 4, batch 0, train_loss 0.714
epoch 4, batch 10, train_loss 0.707
epoch 4, batch 20, train_loss 0.713
epoch 4, batch 30, train_loss 0.701
epoch 4, batch 40, train_loss 0.708
epoch 4, batch 50, train_loss 0.713
epoch 4, batch 60, train_loss 0.717
epoch 4, batch 70, train_loss 0.711
epoch 4, batch 80, train_loss 0.715
epoch 4, batch 90, train_loss 0.714
epoch 4, batch 100, train_loss 0.714
epoch 4, batch 110, train_loss 0.709
epoch 4, batch 120, train_loss 0.704
epoch 4, batch 130, train_loss 0.718
epoch 4, batch 140, train_loss 0.715
epoch 4, batch 150, train_loss 0.706
epoch 4, batch 160, train_loss 0.713
epoch 4, batch 170, train_loss 0.721
epoch 4, batch 180, train_loss 0.713
epoch 4, batch 190, train_loss 0.724
epoch 4, batch 200, train_loss 0.718
epoch 4, batch 210, train_loss 0.713
epoch 4, batch 220, train_loss 0.710
epoch 4, batch 230, train_loss 0.715
epoch 4, batch 240, train_loss 0.700
epoch 4, batch 250, train_loss 0.713
epoch 4, batch 260, train_loss 0.706
epoch 4, batch 270, train_loss 0.715
epoch 4, batch 280, train_loss 0.693
epoch 4, batch 290, train_loss 0.714
epoch 4, batch 300, train_loss 0.726
epoch 4, batch 310, train_loss 0.709
epoch 4, batch 320, train_loss 0.709
epoch 4, batch 330, train_loss 0.701
epoch 4, batch 340, train_loss 0.708
epoch 4, batch 350, train_loss 0.712
epoch 4, batch 360, train_loss 0.706
epoch 4, batch 370, train_loss 0.709
epoch 4, batch 380, train_loss 0.711
epoch 4, batch 390, train_loss 0.707
epoch 4, batch 400, train_loss 0.714
epoch 4, batch 410, train_loss 0.711
epoch 4, batch 420, train_loss 0.714
epoch 4, batch 430, train_loss 0.716
epoch 4, batch 440, train_loss 0.705
epoch 4, batch 450, train_loss 0.711
epoch 4, batch 460, train_loss 0.721
epoch 4, batch 470, train_loss 0.703
epoch 4, batch 480, train_loss 0.715
epoch 4, batch 490, train_loss 0.710
epoch 4, batch 500, train_loss 0.709
epoch 4, batch 510, train_loss 0.712
epoch 4, batch 520, train_loss 0.722
epoch 4, batch 530, train_loss 0.707
epoch 4, batch 540, train_loss 0.704
epoch 4, batch 550, train_loss 0.703
epoch 4, batch 560, train_loss 0.715
epoch 4, batch 570, train_loss 0.709
epoch 4, batch 580, train_loss 0.718
epoch 4, batch 590, train_loss 0.711
epoch 4, batch 600, train_loss 0.708
epoch 4, batch 610, train_loss 0.716
epoch 4, batch 620, train_loss 0.708
epoch 4, batch 630, train_loss 0.710
epoch 4, batch 640, train_loss 0.709
epoch 4, batch 650, train_loss 0.713
epoch 4, batch 660, train_loss 0.707
epoch 4, batch 670, train_loss 0.715
epoch 4, batch 680, train_loss 0.706
epoch 4, batch 690, train_loss 0.708
epoch 4, batch 700, train_loss 0.711
epoch 4, batch 710, train_loss 0.704
epoch 4, batch 720, train_loss 0.704
epoch 4, batch 730, train_loss 0.706
epoch 4, batch 740, train_loss 0.700
epoch 4, batch 750, train_loss 0.707
epoch 4, batch 760, train_loss 0.709
epoch 4, batch 770, train_loss 0.710
epoch 4, batch 780, train_loss 0.712
epoch 4, batch 790, train_loss 0.707
epoch 4, batch 800, train_loss 0.697
epoch 4, batch 810, train_loss 0.702
epoch 4, batch 820, train_loss 0.702
epoch 4, batch 830, train_loss 0.709
epoch 4, batch 840, train_loss 0.718
epoch 4, batch 850, train_loss 0.712
epoch 4, batch 860, train_loss 0.704
epoch 4, batch 870, train_loss 0.712
epoch 4, batch 880, train_loss 0.713
epoch 4, batch 890, train_loss 0.711
epoch 4, batch 900, train_loss 0.705
epoch 4, batch 910, train_loss 0.709
epoch 4, batch 920, train_loss 0.715
epoch 4, batch 930, train_loss 0.714
epoch 4, batch 940, train_loss 0.713
epoch 4, batch 950, train_loss 0.711
epoch 4, batch 960, train_loss 0.713
epoch 4, batch 970, train_loss 0.713
epoch 4, batch 980, train_loss 0.712
epoch 4, batch 990, train_loss 0.707
epoch 4, batch 1000, train_loss 0.714
epoch 4, batch 1010, train_loss 0.706
epoch 4, batch 1020, train_loss 0.714
epoch 4, batch 1030, train_loss 0.701
epoch 4, batch 1040, train_loss 0.707
epoch 4, batch 1050, train_loss 0.719
epoch 4, batch 1060, train_loss 0.712
epoch 4, batch 1070, train_loss 0.708
epoch 4, batch 1080, train_loss 0.712
epoch 4, batch 1090, train_loss 0.701
epoch 4, batch 1100, train_loss 0.700
epoch 4, batch 1110, train_loss 0.711
epoch 4, batch 1120, train_loss 0.700
epoch 4, batch 1130, train_loss 0.706
epoch 4, batch 1140, train_loss 0.709
epoch 4, batch 1150, train_loss 0.713
epoch 4, batch 1160, train_loss 0.716
epoch 4, batch 1170, train_loss 0.700
epoch 4, batch 1180, train_loss 0.708
epoch 4, batch 1190, train_loss 0.697
epoch     4, train_loss 0.708, valid_loss 0.725, train_accuracy  69.38%, valid_accuracy  68.50%
epoch 5, batch 0, train_loss 0.711
epoch 5, batch 10, train_loss 0.699
epoch 5, batch 20, train_loss 0.704
epoch 5, batch 30, train_loss 0.706
epoch 5, batch 40, train_loss 0.713
epoch 5, batch 50, train_loss 0.716
epoch 5, batch 60, train_loss 0.712
epoch 5, batch 70, train_loss 0.720
epoch 5, batch 80, train_loss 0.705
epoch 5, batch 90, train_loss 0.715
epoch 5, batch 100, train_loss 0.706
epoch 5, batch 110, train_loss 0.709
epoch 5, batch 120, train_loss 0.709
epoch 5, batch 130, train_loss 0.715
epoch 5, batch 140, train_loss 0.705
epoch 5, batch 150, train_loss 0.711
epoch 5, batch 160, train_loss 0.709
epoch 5, batch 170, train_loss 0.716
epoch 5, batch 180, train_loss 0.702
epoch 5, batch 190, train_loss 0.708
epoch 5, batch 200, train_loss 0.712
epoch 5, batch 210, train_loss 0.698
epoch 5, batch 220, train_loss 0.708
epoch 5, batch 230, train_loss 0.713
epoch 5, batch 240, train_loss 0.716
epoch 5, batch 250, train_loss 0.725
epoch 5, batch 260, train_loss 0.710
epoch 5, batch 270, train_loss 0.716
epoch 5, batch 280, train_loss 0.700
epoch 5, batch 290, train_loss 0.705
epoch 5, batch 300, train_loss 0.712
epoch 5, batch 310, train_loss 0.706
epoch 5, batch 320, train_loss 0.715
epoch 5, batch 330, train_loss 0.710
epoch 5, batch 340, train_loss 0.705
epoch 5, batch 350, train_loss 0.708
epoch 5, batch 360, train_loss 0.724
epoch 5, batch 370, train_loss 0.710
epoch 5, batch 380, train_loss 0.705
epoch 5, batch 390, train_loss 0.703
epoch 5, batch 400, train_loss 0.710
epoch 5, batch 410, train_loss 0.705
epoch 5, batch 420, train_loss 0.706
epoch 5, batch 430, train_loss 0.709
epoch 5, batch 440, train_loss 0.715
epoch 5, batch 450, train_loss 0.710
epoch 5, batch 460, train_loss 0.715
epoch 5, batch 470, train_loss 0.709
epoch 5, batch 480, train_loss 0.709
epoch 5, batch 490, train_loss 0.725
epoch 5, batch 500, train_loss 0.714
epoch 5, batch 510, train_loss 0.704
epoch 5, batch 520, train_loss 0.704
epoch 5, batch 530, train_loss 0.705
epoch 5, batch 540, train_loss 0.702
epoch 5, batch 550, train_loss 0.713
epoch 5, batch 560, train_loss 0.708
epoch 5, batch 570, train_loss 0.707
epoch 5, batch 580, train_loss 0.705
epoch 5, batch 590, train_loss 0.708
epoch 5, batch 600, train_loss 0.697
epoch 5, batch 610, train_loss 0.703
epoch 5, batch 620, train_loss 0.712
epoch 5, batch 630, train_loss 0.698
epoch 5, batch 640, train_loss 0.713
epoch 5, batch 650, train_loss 0.705
epoch 5, batch 660, train_loss 0.706
epoch 5, batch 670, train_loss 0.707
epoch 5, batch 680, train_loss 0.704
epoch 5, batch 690, train_loss 0.707
epoch 5, batch 700, train_loss 0.706
epoch 5, batch 710, train_loss 0.710
epoch 5, batch 720, train_loss 0.706
epoch 5, batch 730, train_loss 0.705
epoch 5, batch 740, train_loss 0.697
epoch 5, batch 750, train_loss 0.703
epoch 5, batch 760, train_loss 0.714
epoch 5, batch 770, train_loss 0.698
epoch 5, batch 780, train_loss 0.709
epoch 5, batch 790, train_loss 0.719
epoch 5, batch 800, train_loss 0.706
epoch 5, batch 810, train_loss 0.706
epoch 5, batch 820, train_loss 0.703
epoch 5, batch 830, train_loss 0.709
epoch 5, batch 840, train_loss 0.700
epoch 5, batch 850, train_loss 0.707
epoch 5, batch 860, train_loss 0.711
epoch 5, batch 870, train_loss 0.717
epoch 5, batch 880, train_loss 0.704
epoch 5, batch 890, train_loss 0.709
epoch 5, batch 900, train_loss 0.706
epoch 5, batch 910, train_loss 0.709
epoch 5, batch 920, train_loss 0.701
epoch 5, batch 930, train_loss 0.710
epoch 5, batch 940, train_loss 0.707
epoch 5, batch 950, train_loss 0.709
epoch 5, batch 960, train_loss 0.700
epoch 5, batch 970, train_loss 0.715
epoch 5, batch 980, train_loss 0.702
epoch 5, batch 990, train_loss 0.712
epoch 5, batch 1000, train_loss 0.710
epoch 5, batch 1010, train_loss 0.711
epoch 5, batch 1020, train_loss 0.716
epoch 5, batch 1030, train_loss 0.703
epoch 5, batch 1040, train_loss 0.703
epoch 5, batch 1050, train_loss 0.702
epoch 5, batch 1060, train_loss 0.704
epoch 5, batch 1070, train_loss 0.705
epoch 5, batch 1080, train_loss 0.699
epoch 5, batch 1090, train_loss 0.708
epoch 5, batch 1100, train_loss 0.720
epoch 5, batch 1110, train_loss 0.716
epoch 5, batch 1120, train_loss 0.704
epoch 5, batch 1130, train_loss 0.704
epoch 5, batch 1140, train_loss 0.717
epoch 5, batch 1150, train_loss 0.696
epoch 5, batch 1160, train_loss 0.708
epoch 5, batch 1170, train_loss 0.703
epoch 5, batch 1180, train_loss 0.706
epoch 5, batch 1190, train_loss 0.709
epoch     5, train_loss 0.706, valid_loss 0.724, train_accuracy  69.46%, valid_accuracy  68.54%
epoch 6, batch 0, train_loss 0.710
epoch 6, batch 10, train_loss 0.708
epoch 6, batch 20, train_loss 0.709
epoch 6, batch 30, train_loss 0.695
epoch 6, batch 40, train_loss 0.700
epoch 6, batch 50, train_loss 0.703
epoch 6, batch 60, train_loss 0.696
epoch 6, batch 70, train_loss 0.717
epoch 6, batch 80, train_loss 0.710
epoch 6, batch 90, train_loss 0.702
epoch 6, batch 100, train_loss 0.722
epoch 6, batch 110, train_loss 0.699
epoch 6, batch 120, train_loss 0.716
epoch 6, batch 130, train_loss 0.704
epoch 6, batch 140, train_loss 0.704
epoch 6, batch 150, train_loss 0.706
epoch 6, batch 160, train_loss 0.701
epoch 6, batch 170, train_loss 0.703
epoch 6, batch 180, train_loss 0.709
epoch 6, batch 190, train_loss 0.707
epoch 6, batch 200, train_loss 0.702
epoch 6, batch 210, train_loss 0.714
epoch 6, batch 220, train_loss 0.705
epoch 6, batch 230, train_loss 0.692
epoch 6, batch 240, train_loss 0.712
epoch 6, batch 250, train_loss 0.708
epoch 6, batch 260, train_loss 0.710
epoch 6, batch 270, train_loss 0.710
epoch 6, batch 280, train_loss 0.700
epoch 6, batch 290, train_loss 0.706
epoch 6, batch 300, train_loss 0.706
epoch 6, batch 310, train_loss 0.708
epoch 6, batch 320, train_loss 0.702
epoch 6, batch 330, train_loss 0.704
epoch 6, batch 340, train_loss 0.712
epoch 6, batch 350, train_loss 0.708
epoch 6, batch 360, train_loss 0.708
epoch 6, batch 370, train_loss 0.707
epoch 6, batch 380, train_loss 0.708
epoch 6, batch 390, train_loss 0.712
epoch 6, batch 400, train_loss 0.705
epoch 6, batch 410, train_loss 0.710
epoch 6, batch 420, train_loss 0.712
epoch 6, batch 430, train_loss 0.705
epoch 6, batch 440, train_loss 0.700
epoch 6, batch 450, train_loss 0.708
epoch 6, batch 460, train_loss 0.716
epoch 6, batch 470, train_loss 0.704
epoch 6, batch 480, train_loss 0.709
epoch 6, batch 490, train_loss 0.711
epoch 6, batch 500, train_loss 0.709
epoch 6, batch 510, train_loss 0.696
epoch 6, batch 520, train_loss 0.705
epoch 6, batch 530, train_loss 0.713
epoch 6, batch 540, train_loss 0.704
epoch 6, batch 550, train_loss 0.701
epoch 6, batch 560, train_loss 0.695
epoch 6, batch 570, train_loss 0.702
epoch 6, batch 580, train_loss 0.697
epoch 6, batch 590, train_loss 0.705
epoch 6, batch 600, train_loss 0.705
epoch 6, batch 610, train_loss 0.701
epoch 6, batch 620, train_loss 0.712
epoch 6, batch 630, train_loss 0.702
epoch 6, batch 640, train_loss 0.717
epoch 6, batch 650, train_loss 0.700
epoch 6, batch 660, train_loss 0.704
epoch 6, batch 670, train_loss 0.702
epoch 6, batch 680, train_loss 0.712
epoch 6, batch 690, train_loss 0.703
epoch 6, batch 700, train_loss 0.708
epoch 6, batch 710, train_loss 0.714
epoch 6, batch 720, train_loss 0.700
epoch 6, batch 730, train_loss 0.711
epoch 6, batch 740, train_loss 0.705
epoch 6, batch 750, train_loss 0.708
epoch 6, batch 760, train_loss 0.703
epoch 6, batch 770, train_loss 0.711
epoch 6, batch 780, train_loss 0.704
epoch 6, batch 790, train_loss 0.706
epoch 6, batch 800, train_loss 0.704
epoch 6, batch 810, train_loss 0.705
epoch 6, batch 820, train_loss 0.716
epoch 6, batch 830, train_loss 0.695
epoch 6, batch 840, train_loss 0.713
epoch 6, batch 850, train_loss 0.710
epoch 6, batch 860, train_loss 0.712
epoch 6, batch 870, train_loss 0.704
epoch 6, batch 880, train_loss 0.706
epoch 6, batch 890, train_loss 0.698
epoch 6, batch 900, train_loss 0.716
epoch 6, batch 910, train_loss 0.706
epoch 6, batch 920, train_loss 0.706
epoch 6, batch 930, train_loss 0.707
epoch 6, batch 940, train_loss 0.706
epoch 6, batch 950, train_loss 0.705
epoch 6, batch 960, train_loss 0.702
epoch 6, batch 970, train_loss 0.700
epoch 6, batch 980, train_loss 0.700
epoch 6, batch 990, train_loss 0.699
epoch 6, batch 1000, train_loss 0.714
epoch 6, batch 1010, train_loss 0.710
epoch 6, batch 1020, train_loss 0.709
epoch 6, batch 1030, train_loss 0.710
epoch 6, batch 1040, train_loss 0.707
epoch 6, batch 1050, train_loss 0.704
epoch 6, batch 1060, train_loss 0.699
epoch 6, batch 1070, train_loss 0.713
epoch 6, batch 1080, train_loss 0.697
epoch 6, batch 1090, train_loss 0.713
epoch 6, batch 1100, train_loss 0.702
epoch 6, batch 1110, train_loss 0.703
epoch 6, batch 1120, train_loss 0.717
epoch 6, batch 1130, train_loss 0.710
epoch 6, batch 1140, train_loss 0.718
epoch 6, batch 1150, train_loss 0.713
epoch 6, batch 1160, train_loss 0.713
epoch 6, batch 1170, train_loss 0.694
epoch 6, batch 1180, train_loss 0.707
epoch 6, batch 1190, train_loss 0.697
epoch     6, train_loss 0.706, valid_loss 0.724, train_accuracy  69.54%, valid_accuracy  68.49%
epoch 7, batch 0, train_loss 0.712
epoch 7, batch 10, train_loss 0.704
epoch 7, batch 20, train_loss 0.696
epoch 7, batch 30, train_loss 0.711
epoch 7, batch 40, train_loss 0.700
epoch 7, batch 50, train_loss 0.706
epoch 7, batch 60, train_loss 0.698
epoch 7, batch 70, train_loss 0.702
epoch 7, batch 80, train_loss 0.701
epoch 7, batch 90, train_loss 0.702
epoch 7, batch 100, train_loss 0.704
epoch 7, batch 110, train_loss 0.695
epoch 7, batch 120, train_loss 0.707
epoch 7, batch 130, train_loss 0.694
epoch 7, batch 140, train_loss 0.704
epoch 7, batch 150, train_loss 0.706
epoch 7, batch 160, train_loss 0.711
epoch 7, batch 170, train_loss 0.714
epoch 7, batch 180, train_loss 0.699
epoch 7, batch 190, train_loss 0.716
epoch 7, batch 200, train_loss 0.714
epoch 7, batch 210, train_loss 0.700
epoch 7, batch 220, train_loss 0.706
epoch 7, batch 230, train_loss 0.715
epoch 7, batch 240, train_loss 0.710
epoch 7, batch 250, train_loss 0.710
epoch 7, batch 260, train_loss 0.709
epoch 7, batch 270, train_loss 0.703
epoch 7, batch 280, train_loss 0.707
epoch 7, batch 290, train_loss 0.700
epoch 7, batch 300, train_loss 0.706
epoch 7, batch 310, train_loss 0.709
epoch 7, batch 320, train_loss 0.702
epoch 7, batch 330, train_loss 0.712
epoch 7, batch 340, train_loss 0.708
epoch 7, batch 350, train_loss 0.709
epoch 7, batch 360, train_loss 0.710
epoch 7, batch 370, train_loss 0.708
epoch 7, batch 380, train_loss 0.706
epoch 7, batch 390, train_loss 0.706
epoch 7, batch 400, train_loss 0.701
epoch 7, batch 410, train_loss 0.707
epoch 7, batch 420, train_loss 0.711
epoch 7, batch 430, train_loss 0.699
epoch 7, batch 440, train_loss 0.699
epoch 7, batch 450, train_loss 0.707
epoch 7, batch 460, train_loss 0.698
epoch 7, batch 470, train_loss 0.700
epoch 7, batch 480, train_loss 0.714
epoch 7, batch 490, train_loss 0.704
epoch 7, batch 500, train_loss 0.702
epoch 7, batch 510, train_loss 0.705
epoch 7, batch 520, train_loss 0.702
epoch 7, batch 530, train_loss 0.711
epoch 7, batch 540, train_loss 0.705
epoch 7, batch 550, train_loss 0.704
epoch 7, batch 560, train_loss 0.699
epoch 7, batch 570, train_loss 0.715
epoch 7, batch 580, train_loss 0.707
epoch 7, batch 590, train_loss 0.695
epoch 7, batch 600, train_loss 0.711
epoch 7, batch 610, train_loss 0.702
epoch 7, batch 620, train_loss 0.712
epoch 7, batch 630, train_loss 0.714
epoch 7, batch 640, train_loss 0.709
epoch 7, batch 650, train_loss 0.709
epoch 7, batch 660, train_loss 0.700
epoch 7, batch 670, train_loss 0.702
epoch 7, batch 680, train_loss 0.703
epoch 7, batch 690, train_loss 0.703
epoch 7, batch 700, train_loss 0.705
epoch 7, batch 710, train_loss 0.707
epoch 7, batch 720, train_loss 0.703
epoch 7, batch 730, train_loss 0.700
epoch 7, batch 740, train_loss 0.699
epoch 7, batch 750, train_loss 0.705
epoch 7, batch 760, train_loss 0.703
epoch 7, batch 770, train_loss 0.696
epoch 7, batch 780, train_loss 0.697
epoch 7, batch 790, train_loss 0.700
epoch 7, batch 800, train_loss 0.707
epoch 7, batch 810, train_loss 0.705
epoch 7, batch 820, train_loss 0.703
epoch 7, batch 830, train_loss 0.713
epoch 7, batch 840, train_loss 0.702
epoch 7, batch 850, train_loss 0.690
epoch 7, batch 860, train_loss 0.702
epoch 7, batch 870, train_loss 0.709
epoch 7, batch 880, train_loss 0.701
epoch 7, batch 890, train_loss 0.709
epoch 7, batch 900, train_loss 0.712
epoch 7, batch 910, train_loss 0.691
epoch 7, batch 920, train_loss 0.702
epoch 7, batch 930, train_loss 0.705
epoch 7, batch 940, train_loss 0.711
epoch 7, batch 950, train_loss 0.713
epoch 7, batch 960, train_loss 0.711
epoch 7, batch 970, train_loss 0.709
epoch 7, batch 980, train_loss 0.702
epoch 7, batch 990, train_loss 0.704
epoch 7, batch 1000, train_loss 0.708
epoch 7, batch 1010, train_loss 0.704
epoch 7, batch 1020, train_loss 0.711
epoch 7, batch 1030, train_loss 0.704
epoch 7, batch 1040, train_loss 0.705
epoch 7, batch 1050, train_loss 0.707
epoch 7, batch 1060, train_loss 0.708
epoch 7, batch 1070, train_loss 0.698
epoch 7, batch 1080, train_loss 0.698
epoch 7, batch 1090, train_loss 0.705
epoch 7, batch 1100, train_loss 0.706
epoch 7, batch 1110, train_loss 0.704
epoch 7, batch 1120, train_loss 0.713
epoch 7, batch 1130, train_loss 0.695
epoch 7, batch 1140, train_loss 0.703
epoch 7, batch 1150, train_loss 0.698
epoch 7, batch 1160, train_loss 0.704
epoch 7, batch 1170, train_loss 0.708
epoch 7, batch 1180, train_loss 0.703
epoch 7, batch 1190, train_loss 0.706
epoch     7, train_loss 0.703, valid_loss 0.723, train_accuracy  69.63%, valid_accuracy  68.59%
epoch 8, batch 0, train_loss 0.708
epoch 8, batch 10, train_loss 0.700
epoch 8, batch 20, train_loss 0.703
epoch 8, batch 30, train_loss 0.715
epoch 8, batch 40, train_loss 0.705
epoch 8, batch 50, train_loss 0.704
epoch 8, batch 60, train_loss 0.711
epoch 8, batch 70, train_loss 0.704
epoch 8, batch 80, train_loss 0.706
epoch 8, batch 90, train_loss 0.700
epoch 8, batch 100, train_loss 0.704
epoch 8, batch 110, train_loss 0.702
epoch 8, batch 120, train_loss 0.696
epoch 8, batch 130, train_loss 0.702
epoch 8, batch 140, train_loss 0.714
epoch 8, batch 150, train_loss 0.702
epoch 8, batch 160, train_loss 0.707
epoch 8, batch 170, train_loss 0.704
epoch 8, batch 180, train_loss 0.711
epoch 8, batch 190, train_loss 0.705
epoch 8, batch 200, train_loss 0.711
epoch 8, batch 210, train_loss 0.707
epoch 8, batch 220, train_loss 0.707
epoch 8, batch 230, train_loss 0.699
epoch 8, batch 240, train_loss 0.701
epoch 8, batch 250, train_loss 0.695
epoch 8, batch 260, train_loss 0.703
epoch 8, batch 270, train_loss 0.704
epoch 8, batch 280, train_loss 0.709
epoch 8, batch 290, train_loss 0.705
epoch 8, batch 300, train_loss 0.698
epoch 8, batch 310, train_loss 0.702
epoch 8, batch 320, train_loss 0.704
epoch 8, batch 330, train_loss 0.699
epoch 8, batch 340, train_loss 0.701
epoch 8, batch 350, train_loss 0.698
epoch 8, batch 360, train_loss 0.700
epoch 8, batch 370, train_loss 0.704
epoch 8, batch 380, train_loss 0.707
epoch 8, batch 390, train_loss 0.688
epoch 8, batch 400, train_loss 0.704
epoch 8, batch 410, train_loss 0.701
epoch 8, batch 420, train_loss 0.703
epoch 8, batch 430, train_loss 0.705
epoch 8, batch 440, train_loss 0.706
epoch 8, batch 450, train_loss 0.704
epoch 8, batch 460, train_loss 0.704
epoch 8, batch 470, train_loss 0.706
epoch 8, batch 480, train_loss 0.711
epoch 8, batch 490, train_loss 0.704
epoch 8, batch 500, train_loss 0.708
epoch 8, batch 510, train_loss 0.698
epoch 8, batch 520, train_loss 0.703
epoch 8, batch 530, train_loss 0.704
epoch 8, batch 540, train_loss 0.699
epoch 8, batch 550, train_loss 0.708
epoch 8, batch 560, train_loss 0.692
epoch 8, batch 570, train_loss 0.703
epoch 8, batch 580, train_loss 0.710
epoch 8, batch 590, train_loss 0.701
epoch 8, batch 600, train_loss 0.708
epoch 8, batch 610, train_loss 0.707
epoch 8, batch 620, train_loss 0.710
epoch 8, batch 630, train_loss 0.707
epoch 8, batch 640, train_loss 0.712
epoch 8, batch 650, train_loss 0.706
epoch 8, batch 660, train_loss 0.709
epoch 8, batch 670, train_loss 0.709
epoch 8, batch 680, train_loss 0.698
epoch 8, batch 690, train_loss 0.709
epoch 8, batch 700, train_loss 0.700
epoch 8, batch 710, train_loss 0.704
epoch 8, batch 720, train_loss 0.696
epoch 8, batch 730, train_loss 0.707
epoch 8, batch 740, train_loss 0.697
epoch 8, batch 750, train_loss 0.706
epoch 8, batch 760, train_loss 0.714
epoch 8, batch 770, train_loss 0.711
epoch 8, batch 780, train_loss 0.708
epoch 8, batch 790, train_loss 0.717
epoch 8, batch 800, train_loss 0.716
epoch 8, batch 810, train_loss 0.709
epoch 8, batch 820, train_loss 0.701
epoch 8, batch 830, train_loss 0.702
epoch 8, batch 840, train_loss 0.696
epoch 8, batch 850, train_loss 0.706
epoch 8, batch 860, train_loss 0.693
epoch 8, batch 870, train_loss 0.712
epoch 8, batch 880, train_loss 0.708
epoch 8, batch 890, train_loss 0.697
epoch 8, batch 900, train_loss 0.718
epoch 8, batch 910, train_loss 0.701
epoch 8, batch 920, train_loss 0.710
epoch 8, batch 930, train_loss 0.709
epoch 8, batch 940, train_loss 0.711
epoch 8, batch 950, train_loss 0.721
epoch 8, batch 960, train_loss 0.703
epoch 8, batch 970, train_loss 0.704
epoch 8, batch 980, train_loss 0.710
epoch 8, batch 990, train_loss 0.710
epoch 8, batch 1000, train_loss 0.712
epoch 8, batch 1010, train_loss 0.709
epoch 8, batch 1020, train_loss 0.700
epoch 8, batch 1030, train_loss 0.701
epoch 8, batch 1040, train_loss 0.695
epoch 8, batch 1050, train_loss 0.709
epoch 8, batch 1060, train_loss 0.714
epoch 8, batch 1070, train_loss 0.701
epoch 8, batch 1080, train_loss 0.708
epoch 8, batch 1090, train_loss 0.700
epoch 8, batch 1100, train_loss 0.700
epoch 8, batch 1110, train_loss 0.704
epoch 8, batch 1120, train_loss 0.701
epoch 8, batch 1130, train_loss 0.705
epoch 8, batch 1140, train_loss 0.703
epoch 8, batch 1150, train_loss 0.697
epoch 8, batch 1160, train_loss 0.693
epoch 8, batch 1170, train_loss 0.706
epoch 8, batch 1180, train_loss 0.699
epoch 8, batch 1190, train_loss 0.713
epoch     8, train_loss 0.702, valid_loss 0.722, train_accuracy  69.71%, valid_accuracy  68.57%
epoch 9, batch 0, train_loss 0.701
epoch 9, batch 10, train_loss 0.696
epoch 9, batch 20, train_loss 0.703
epoch 9, batch 30, train_loss 0.696
epoch 9, batch 40, train_loss 0.701
epoch 9, batch 50, train_loss 0.702
epoch 9, batch 60, train_loss 0.703
epoch 9, batch 70, train_loss 0.707
epoch 9, batch 80, train_loss 0.705
epoch 9, batch 90, train_loss 0.707
epoch 9, batch 100, train_loss 0.702
epoch 9, batch 110, train_loss 0.687
epoch 9, batch 120, train_loss 0.711
epoch 9, batch 130, train_loss 0.705
epoch 9, batch 140, train_loss 0.692
epoch 9, batch 150, train_loss 0.700
epoch 9, batch 160, train_loss 0.698
epoch 9, batch 170, train_loss 0.715
epoch 9, batch 180, train_loss 0.707
epoch 9, batch 190, train_loss 0.704
epoch 9, batch 200, train_loss 0.713
epoch 9, batch 210, train_loss 0.686
epoch 9, batch 220, train_loss 0.698
epoch 9, batch 230, train_loss 0.703
epoch 9, batch 240, train_loss 0.703
epoch 9, batch 250, train_loss 0.703
epoch 9, batch 260, train_loss 0.696
epoch 9, batch 270, train_loss 0.703
epoch 9, batch 280, train_loss 0.716
epoch 9, batch 290, train_loss 0.702
epoch 9, batch 300, train_loss 0.703
epoch 9, batch 310, train_loss 0.709
epoch 9, batch 320, train_loss 0.704
epoch 9, batch 330, train_loss 0.696
epoch 9, batch 340, train_loss 0.698
epoch 9, batch 350, train_loss 0.708
epoch 9, batch 360, train_loss 0.694
epoch 9, batch 370, train_loss 0.700
epoch 9, batch 380, train_loss 0.707
epoch 9, batch 390, train_loss 0.702
epoch 9, batch 400, train_loss 0.697
epoch 9, batch 410, train_loss 0.707
epoch 9, batch 420, train_loss 0.703
epoch 9, batch 430, train_loss 0.710
epoch 9, batch 440, train_loss 0.695
epoch 9, batch 450, train_loss 0.701
epoch 9, batch 460, train_loss 0.699
epoch 9, batch 470, train_loss 0.709
epoch 9, batch 480, train_loss 0.698
epoch 9, batch 490, train_loss 0.704
epoch 9, batch 500, train_loss 0.707
epoch 9, batch 510, train_loss 0.697
epoch 9, batch 520, train_loss 0.700
epoch 9, batch 530, train_loss 0.699
epoch 9, batch 540, train_loss 0.708
epoch 9, batch 550, train_loss 0.696
epoch 9, batch 560, train_loss 0.704
epoch 9, batch 570, train_loss 0.698
epoch 9, batch 580, train_loss 0.701
epoch 9, batch 590, train_loss 0.699
epoch 9, batch 600, train_loss 0.695
epoch 9, batch 610, train_loss 0.700
epoch 9, batch 620, train_loss 0.706
epoch 9, batch 630, train_loss 0.709
epoch 9, batch 640, train_loss 0.693
epoch 9, batch 650, train_loss 0.704
epoch 9, batch 660, train_loss 0.706
epoch 9, batch 670, train_loss 0.695
epoch 9, batch 680, train_loss 0.698
epoch 9, batch 690, train_loss 0.708
epoch 9, batch 700, train_loss 0.711
epoch 9, batch 710, train_loss 0.701
epoch 9, batch 720, train_loss 0.697
epoch 9, batch 730, train_loss 0.701
epoch 9, batch 740, train_loss 0.713
epoch 9, batch 750, train_loss 0.697
epoch 9, batch 760, train_loss 0.709
epoch 9, batch 770, train_loss 0.702
epoch 9, batch 780, train_loss 0.700
epoch 9, batch 790, train_loss 0.708
epoch 9, batch 800, train_loss 0.701
epoch 9, batch 810, train_loss 0.703
epoch 9, batch 820, train_loss 0.704
epoch 9, batch 830, train_loss 0.699
epoch 9, batch 840, train_loss 0.699
epoch 9, batch 850, train_loss 0.702
epoch 9, batch 860, train_loss 0.706
epoch 9, batch 870, train_loss 0.715
epoch 9, batch 880, train_loss 0.702
epoch 9, batch 890, train_loss 0.706
epoch 9, batch 900, train_loss 0.700
epoch 9, batch 910, train_loss 0.707
epoch 9, batch 920, train_loss 0.708
epoch 9, batch 930, train_loss 0.702
epoch 9, batch 940, train_loss 0.698
epoch 9, batch 950, train_loss 0.695
epoch 9, batch 960, train_loss 0.704
epoch 9, batch 970, train_loss 0.707
epoch 9, batch 980, train_loss 0.698
epoch 9, batch 990, train_loss 0.697
epoch 9, batch 1000, train_loss 0.714
epoch 9, batch 1010, train_loss 0.706
epoch 9, batch 1020, train_loss 0.701
epoch 9, batch 1030, train_loss 0.707
epoch 9, batch 1040, train_loss 0.696
epoch 9, batch 1050, train_loss 0.706
epoch 9, batch 1060, train_loss 0.697
epoch 9, batch 1070, train_loss 0.701
epoch 9, batch 1080, train_loss 0.708
epoch 9, batch 1090, train_loss 0.709
epoch 9, batch 1100, train_loss 0.708
epoch 9, batch 1110, train_loss 0.707
epoch 9, batch 1120, train_loss 0.705
epoch 9, batch 1130, train_loss 0.703
epoch 9, batch 1140, train_loss 0.704
epoch 9, batch 1150, train_loss 0.706
epoch 9, batch 1160, train_loss 0.700
epoch 9, batch 1170, train_loss 0.703
epoch 9, batch 1180, train_loss 0.709
epoch 9, batch 1190, train_loss 0.701
epoch     9, train_loss 0.702, valid_loss 0.723, train_accuracy  69.70%, valid_accuracy  68.59%
epoch 10, batch 0, train_loss 0.700
epoch 10, batch 10, train_loss 0.700
epoch 10, batch 20, train_loss 0.714
epoch 10, batch 30, train_loss 0.700
epoch 10, batch 40, train_loss 0.698
epoch 10, batch 50, train_loss 0.703
epoch 10, batch 60, train_loss 0.708
epoch 10, batch 70, train_loss 0.706
epoch 10, batch 80, train_loss 0.703
epoch 10, batch 90, train_loss 0.703
epoch 10, batch 100, train_loss 0.705
epoch 10, batch 110, train_loss 0.704
epoch 10, batch 120, train_loss 0.702
epoch 10, batch 130, train_loss 0.692
epoch 10, batch 140, train_loss 0.702
epoch 10, batch 150, train_loss 0.712
epoch 10, batch 160, train_loss 0.701
epoch 10, batch 170, train_loss 0.705
epoch 10, batch 180, train_loss 0.712
epoch 10, batch 190, train_loss 0.700
epoch 10, batch 200, train_loss 0.713
epoch 10, batch 210, train_loss 0.701
epoch 10, batch 220, train_loss 0.706
epoch 10, batch 230, train_loss 0.709
epoch 10, batch 240, train_loss 0.700
epoch 10, batch 250, train_loss 0.704
epoch 10, batch 260, train_loss 0.705
epoch 10, batch 270, train_loss 0.700
epoch 10, batch 280, train_loss 0.696
epoch 10, batch 290, train_loss 0.702
epoch 10, batch 300, train_loss 0.701
epoch 10, batch 310, train_loss 0.703
epoch 10, batch 320, train_loss 0.691
epoch 10, batch 330, train_loss 0.703
epoch 10, batch 340, train_loss 0.702
epoch 10, batch 350, train_loss 0.702
epoch 10, batch 360, train_loss 0.704
epoch 10, batch 370, train_loss 0.705
epoch 10, batch 380, train_loss 0.707
epoch 10, batch 390, train_loss 0.697
epoch 10, batch 400, train_loss 0.701
epoch 10, batch 410, train_loss 0.699
epoch 10, batch 420, train_loss 0.688
epoch 10, batch 430, train_loss 0.697
epoch 10, batch 440, train_loss 0.707
epoch 10, batch 450, train_loss 0.716
epoch 10, batch 460, train_loss 0.707
epoch 10, batch 470, train_loss 0.697
epoch 10, batch 480, train_loss 0.699
epoch 10, batch 490, train_loss 0.706
epoch 10, batch 500, train_loss 0.702
epoch 10, batch 510, train_loss 0.694
epoch 10, batch 520, train_loss 0.696
epoch 10, batch 530, train_loss 0.695
epoch 10, batch 540, train_loss 0.697
epoch 10, batch 550, train_loss 0.699
epoch 10, batch 560, train_loss 0.703
epoch 10, batch 570, train_loss 0.708
epoch 10, batch 580, train_loss 0.703
epoch 10, batch 590, train_loss 0.694
epoch 10, batch 600, train_loss 0.696
epoch 10, batch 610, train_loss 0.702
epoch 10, batch 620, train_loss 0.717
epoch 10, batch 630, train_loss 0.698
epoch 10, batch 640, train_loss 0.702
epoch 10, batch 650, train_loss 0.703
epoch 10, batch 660, train_loss 0.702
epoch 10, batch 670, train_loss 0.705
epoch 10, batch 680, train_loss 0.704
epoch 10, batch 690, train_loss 0.713
epoch 10, batch 700, train_loss 0.699
epoch 10, batch 710, train_loss 0.703
epoch 10, batch 720, train_loss 0.708
epoch 10, batch 730, train_loss 0.694
epoch 10, batch 740, train_loss 0.702
epoch 10, batch 750, train_loss 0.706
epoch 10, batch 760, train_loss 0.705
epoch 10, batch 770, train_loss 0.698
epoch 10, batch 780, train_loss 0.709
epoch 10, batch 790, train_loss 0.706
epoch 10, batch 800, train_loss 0.708
epoch 10, batch 810, train_loss 0.700
epoch 10, batch 820, train_loss 0.708
epoch 10, batch 830, train_loss 0.701
epoch 10, batch 840, train_loss 0.699
epoch 10, batch 850, train_loss 0.700
epoch 10, batch 860, train_loss 0.705
epoch 10, batch 870, train_loss 0.701
epoch 10, batch 880, train_loss 0.707
epoch 10, batch 890, train_loss 0.701
epoch 10, batch 900, train_loss 0.698
epoch 10, batch 910, train_loss 0.708
epoch 10, batch 920, train_loss 0.704
epoch 10, batch 930, train_loss 0.695
epoch 10, batch 940, train_loss 0.702
epoch 10, batch 950, train_loss 0.700
epoch 10, batch 960, train_loss 0.692
epoch 10, batch 970, train_loss 0.696
epoch 10, batch 980, train_loss 0.702
epoch 10, batch 990, train_loss 0.708
epoch 10, batch 1000, train_loss 0.708
epoch 10, batch 1010, train_loss 0.709
epoch 10, batch 1020, train_loss 0.707
epoch 10, batch 1030, train_loss 0.705
epoch 10, batch 1040, train_loss 0.708
epoch 10, batch 1050, train_loss 0.692
epoch 10, batch 1060, train_loss 0.695
epoch 10, batch 1070, train_loss 0.706
epoch 10, batch 1080, train_loss 0.703
epoch 10, batch 1090, train_loss 0.693
epoch 10, batch 1100, train_loss 0.710
epoch 10, batch 1110, train_loss 0.707
epoch 10, batch 1120, train_loss 0.693
epoch 10, batch 1130, train_loss 0.706
epoch 10, batch 1140, train_loss 0.708
epoch 10, batch 1150, train_loss 0.705
epoch 10, batch 1160, train_loss 0.707
epoch 10, batch 1170, train_loss 0.698
epoch 10, batch 1180, train_loss 0.708
epoch 10, batch 1190, train_loss 0.713
epoch    10, train_loss 0.701, valid_loss 0.722, train_accuracy  69.76%, valid_accuracy  68.59%
epoch 11, batch 0, train_loss 0.695
epoch 11, batch 10, train_loss 0.702
epoch 11, batch 20, train_loss 0.708
epoch 11, batch 30, train_loss 0.708
epoch 11, batch 40, train_loss 0.702
epoch 11, batch 50, train_loss 0.702
epoch 11, batch 60, train_loss 0.700
epoch 11, batch 70, train_loss 0.706
epoch 11, batch 80, train_loss 0.698
epoch 11, batch 90, train_loss 0.713
epoch 11, batch 100, train_loss 0.700
epoch 11, batch 110, train_loss 0.710
epoch 11, batch 120, train_loss 0.691
epoch 11, batch 130, train_loss 0.702
epoch 11, batch 140, train_loss 0.703
epoch 11, batch 150, train_loss 0.702
epoch 11, batch 160, train_loss 0.708
epoch 11, batch 170, train_loss 0.700
epoch 11, batch 180, train_loss 0.704
epoch 11, batch 190, train_loss 0.698
epoch 11, batch 200, train_loss 0.704
epoch 11, batch 210, train_loss 0.700
epoch 11, batch 220, train_loss 0.704
epoch 11, batch 230, train_loss 0.706
epoch 11, batch 240, train_loss 0.699
epoch 11, batch 250, train_loss 0.699
epoch 11, batch 260, train_loss 0.694
epoch 11, batch 270, train_loss 0.700
epoch 11, batch 280, train_loss 0.697
epoch 11, batch 290, train_loss 0.700
epoch 11, batch 300, train_loss 0.687
epoch 11, batch 310, train_loss 0.703
epoch 11, batch 320, train_loss 0.713
epoch 11, batch 330, train_loss 0.699
epoch 11, batch 340, train_loss 0.706
epoch 11, batch 350, train_loss 0.713
epoch 11, batch 360, train_loss 0.705
epoch 11, batch 370, train_loss 0.694
epoch 11, batch 380, train_loss 0.702
epoch 11, batch 390, train_loss 0.708
epoch 11, batch 400, train_loss 0.701
epoch 11, batch 410, train_loss 0.706
epoch 11, batch 420, train_loss 0.696
epoch 11, batch 430, train_loss 0.701
epoch 11, batch 440, train_loss 0.693
epoch 11, batch 450, train_loss 0.699
epoch 11, batch 460, train_loss 0.702
epoch 11, batch 470, train_loss 0.706
epoch 11, batch 480, train_loss 0.704
epoch 11, batch 490, train_loss 0.690
epoch 11, batch 500, train_loss 0.698
epoch 11, batch 510, train_loss 0.695
epoch 11, batch 520, train_loss 0.704
epoch 11, batch 530, train_loss 0.703
epoch 11, batch 540, train_loss 0.703
epoch 11, batch 550, train_loss 0.707
epoch 11, batch 560, train_loss 0.701
epoch 11, batch 570, train_loss 0.699
epoch 11, batch 580, train_loss 0.695
epoch 11, batch 590, train_loss 0.700
epoch 11, batch 600, train_loss 0.696
epoch 11, batch 610, train_loss 0.698
epoch 11, batch 620, train_loss 0.703
epoch 11, batch 630, train_loss 0.704
epoch 11, batch 640, train_loss 0.707
epoch 11, batch 650, train_loss 0.694
epoch 11, batch 660, train_loss 0.703
epoch 11, batch 670, train_loss 0.704
epoch 11, batch 680, train_loss 0.706
epoch 11, batch 690, train_loss 0.711
epoch 11, batch 700, train_loss 0.701
epoch 11, batch 710, train_loss 0.697
epoch 11, batch 720, train_loss 0.711
epoch 11, batch 730, train_loss 0.706
epoch 11, batch 740, train_loss 0.703
epoch 11, batch 750, train_loss 0.693
epoch 11, batch 760, train_loss 0.705
epoch 11, batch 770, train_loss 0.704
epoch 11, batch 780, train_loss 0.699
epoch 11, batch 790, train_loss 0.704
epoch 11, batch 800, train_loss 0.691
epoch 11, batch 810, train_loss 0.712
epoch 11, batch 820, train_loss 0.712
epoch 11, batch 830, train_loss 0.703
epoch 11, batch 840, train_loss 0.698
epoch 11, batch 850, train_loss 0.714
epoch 11, batch 860, train_loss 0.704
epoch 11, batch 870, train_loss 0.705
epoch 11, batch 880, train_loss 0.707
epoch 11, batch 890, train_loss 0.699
epoch 11, batch 900, train_loss 0.704
epoch 11, batch 910, train_loss 0.714
epoch 11, batch 920, train_loss 0.693
epoch 11, batch 930, train_loss 0.706
epoch 11, batch 940, train_loss 0.702
epoch 11, batch 950, train_loss 0.707
epoch 11, batch 960, train_loss 0.699
epoch 11, batch 970, train_loss 0.702
epoch 11, batch 980, train_loss 0.703
epoch 11, batch 990, train_loss 0.705
epoch 11, batch 1000, train_loss 0.707
epoch 11, batch 1010, train_loss 0.707
epoch 11, batch 1020, train_loss 0.708
epoch 11, batch 1030, train_loss 0.705
epoch 11, batch 1040, train_loss 0.703
epoch 11, batch 1050, train_loss 0.685
epoch 11, batch 1060, train_loss 0.705
epoch 11, batch 1070, train_loss 0.693
epoch 11, batch 1080, train_loss 0.716
epoch 11, batch 1090, train_loss 0.704
epoch 11, batch 1100, train_loss 0.700
epoch 11, batch 1110, train_loss 0.710
epoch 11, batch 1120, train_loss 0.696
epoch 11, batch 1130, train_loss 0.698
epoch 11, batch 1140, train_loss 0.705
epoch 11, batch 1150, train_loss 0.702
epoch 11, batch 1160, train_loss 0.702
epoch 11, batch 1170, train_loss 0.702
epoch 11, batch 1180, train_loss 0.698
epoch 11, batch 1190, train_loss 0.707
epoch    11, train_loss 0.701, valid_loss 0.723, train_accuracy  69.76%, valid_accuracy  68.62%
epoch 12, batch 0, train_loss 0.705
epoch 12, batch 10, train_loss 0.701
epoch 12, batch 20, train_loss 0.700
epoch 12, batch 30, train_loss 0.709
epoch 12, batch 40, train_loss 0.696
epoch 12, batch 50, train_loss 0.695
epoch 12, batch 60, train_loss 0.706
epoch 12, batch 70, train_loss 0.700
epoch 12, batch 80, train_loss 0.705
epoch 12, batch 90, train_loss 0.693
epoch 12, batch 100, train_loss 0.704
epoch 12, batch 110, train_loss 0.693
epoch 12, batch 120, train_loss 0.698
epoch 12, batch 130, train_loss 0.709
epoch 12, batch 140, train_loss 0.705
epoch 12, batch 150, train_loss 0.704
epoch 12, batch 160, train_loss 0.696
epoch 12, batch 170, train_loss 0.703
epoch 12, batch 180, train_loss 0.696
epoch 12, batch 190, train_loss 0.697
epoch 12, batch 200, train_loss 0.698
epoch 12, batch 210, train_loss 0.705
epoch 12, batch 220, train_loss 0.698
epoch 12, batch 230, train_loss 0.704
epoch 12, batch 240, train_loss 0.698
epoch 12, batch 250, train_loss 0.689
epoch 12, batch 260, train_loss 0.706
epoch 12, batch 270, train_loss 0.696
epoch 12, batch 280, train_loss 0.717
epoch 12, batch 290, train_loss 0.702
epoch 12, batch 300, train_loss 0.701
epoch 12, batch 310, train_loss 0.698
epoch 12, batch 320, train_loss 0.703
epoch 12, batch 330, train_loss 0.707
epoch 12, batch 340, train_loss 0.701
epoch 12, batch 350, train_loss 0.705
epoch 12, batch 360, train_loss 0.701
epoch 12, batch 370, train_loss 0.700
epoch 12, batch 380, train_loss 0.694
epoch 12, batch 390, train_loss 0.695
epoch 12, batch 400, train_loss 0.695
epoch 12, batch 410, train_loss 0.699
epoch 12, batch 420, train_loss 0.697
epoch 12, batch 430, train_loss 0.705
epoch 12, batch 440, train_loss 0.712
epoch 12, batch 450, train_loss 0.706
epoch 12, batch 460, train_loss 0.698
epoch 12, batch 470, train_loss 0.702
epoch 12, batch 480, train_loss 0.702
epoch 12, batch 490, train_loss 0.695
epoch 12, batch 500, train_loss 0.708
epoch 12, batch 510, train_loss 0.698
epoch 12, batch 520, train_loss 0.702
epoch 12, batch 530, train_loss 0.705
epoch 12, batch 540, train_loss 0.711
epoch 12, batch 550, train_loss 0.704
epoch 12, batch 560, train_loss 0.707
epoch 12, batch 570, train_loss 0.691
epoch 12, batch 580, train_loss 0.693
epoch 12, batch 590, train_loss 0.704
epoch 12, batch 600, train_loss 0.709
epoch 12, batch 610, train_loss 0.695
epoch 12, batch 620, train_loss 0.700
epoch 12, batch 630, train_loss 0.711
epoch 12, batch 640, train_loss 0.701
epoch 12, batch 650, train_loss 0.702
epoch 12, batch 660, train_loss 0.699
epoch 12, batch 670, train_loss 0.701
epoch 12, batch 680, train_loss 0.701
epoch 12, batch 690, train_loss 0.693
epoch 12, batch 700, train_loss 0.701
epoch 12, batch 710, train_loss 0.696
epoch 12, batch 720, train_loss 0.700
epoch 12, batch 730, train_loss 0.693
epoch 12, batch 740, train_loss 0.695
epoch 12, batch 750, train_loss 0.705
epoch 12, batch 760, train_loss 0.690
epoch 12, batch 770, train_loss 0.710
epoch 12, batch 780, train_loss 0.700
epoch 12, batch 790, train_loss 0.694
epoch 12, batch 800, train_loss 0.709
epoch 12, batch 810, train_loss 0.700
epoch 12, batch 820, train_loss 0.709
epoch 12, batch 830, train_loss 0.694
epoch 12, batch 840, train_loss 0.696
epoch 12, batch 850, train_loss 0.697
epoch 12, batch 860, train_loss 0.695
epoch 12, batch 870, train_loss 0.697
epoch 12, batch 880, train_loss 0.707
epoch 12, batch 890, train_loss 0.706
epoch 12, batch 900, train_loss 0.698
epoch 12, batch 910, train_loss 0.701
epoch 12, batch 920, train_loss 0.698
epoch 12, batch 930, train_loss 0.701
epoch 12, batch 940, train_loss 0.695
epoch 12, batch 950, train_loss 0.716
epoch 12, batch 960, train_loss 0.702
epoch 12, batch 970, train_loss 0.703
epoch 12, batch 980, train_loss 0.704
epoch 12, batch 990, train_loss 0.701
epoch 12, batch 1000, train_loss 0.704
epoch 12, batch 1010, train_loss 0.695
epoch 12, batch 1020, train_loss 0.695
epoch 12, batch 1030, train_loss 0.706
epoch 12, batch 1040, train_loss 0.708
epoch 12, batch 1050, train_loss 0.696
epoch 12, batch 1060, train_loss 0.696
epoch 12, batch 1070, train_loss 0.702
epoch 12, batch 1080, train_loss 0.698
epoch 12, batch 1090, train_loss 0.702
epoch 12, batch 1100, train_loss 0.694
epoch 12, batch 1110, train_loss 0.695
epoch 12, batch 1120, train_loss 0.693
epoch 12, batch 1130, train_loss 0.701
epoch 12, batch 1140, train_loss 0.709
epoch 12, batch 1150, train_loss 0.699
epoch 12, batch 1160, train_loss 0.715
epoch 12, batch 1170, train_loss 0.711
epoch 12, batch 1180, train_loss 0.705
epoch 12, batch 1190, train_loss 0.706
epoch    12, train_loss 0.700, valid_loss 0.722, train_accuracy  69.80%, valid_accuracy  68.56%
epoch 13, batch 0, train_loss 0.708
epoch 13, batch 10, train_loss 0.710
epoch 13, batch 20, train_loss 0.690
epoch 13, batch 30, train_loss 0.696
epoch 13, batch 40, train_loss 0.694
epoch 13, batch 50, train_loss 0.705
epoch 13, batch 60, train_loss 0.703
epoch 13, batch 70, train_loss 0.704
epoch 13, batch 80, train_loss 0.704
epoch 13, batch 90, train_loss 0.693
epoch 13, batch 100, train_loss 0.704
epoch 13, batch 110, train_loss 0.699
epoch 13, batch 120, train_loss 0.689
epoch 13, batch 130, train_loss 0.702
epoch 13, batch 140, train_loss 0.700
epoch 13, batch 150, train_loss 0.704
epoch 13, batch 160, train_loss 0.703
epoch 13, batch 170, train_loss 0.700
epoch 13, batch 180, train_loss 0.701
epoch 13, batch 190, train_loss 0.695
epoch 13, batch 200, train_loss 0.706
epoch 13, batch 210, train_loss 0.709
epoch 13, batch 220, train_loss 0.694
epoch 13, batch 230, train_loss 0.705
epoch 13, batch 240, train_loss 0.693
epoch 13, batch 250, train_loss 0.702
epoch 13, batch 260, train_loss 0.700
epoch 13, batch 270, train_loss 0.699
epoch 13, batch 280, train_loss 0.697
epoch 13, batch 290, train_loss 0.690
epoch 13, batch 300, train_loss 0.695
epoch 13, batch 310, train_loss 0.703
epoch 13, batch 320, train_loss 0.702
epoch 13, batch 330, train_loss 0.712
epoch 13, batch 340, train_loss 0.706
epoch 13, batch 350, train_loss 0.715
epoch 13, batch 360, train_loss 0.699
epoch 13, batch 370, train_loss 0.700
epoch 13, batch 380, train_loss 0.705
epoch 13, batch 390, train_loss 0.691
epoch 13, batch 400, train_loss 0.707
epoch 13, batch 410, train_loss 0.701
epoch 13, batch 420, train_loss 0.700
epoch 13, batch 430, train_loss 0.691
epoch 13, batch 440, train_loss 0.694
epoch 13, batch 450, train_loss 0.707
epoch 13, batch 460, train_loss 0.705
epoch 13, batch 470, train_loss 0.698
epoch 13, batch 480, train_loss 0.704
epoch 13, batch 490, train_loss 0.698
epoch 13, batch 500, train_loss 0.699
epoch 13, batch 510, train_loss 0.698
epoch 13, batch 520, train_loss 0.708
epoch 13, batch 530, train_loss 0.700
epoch 13, batch 540, train_loss 0.698
epoch 13, batch 550, train_loss 0.692
epoch 13, batch 560, train_loss 0.710
epoch 13, batch 570, train_loss 0.690
epoch 13, batch 580, train_loss 0.707
epoch 13, batch 590, train_loss 0.704
epoch 13, batch 600, train_loss 0.700
epoch 13, batch 610, train_loss 0.703
epoch 13, batch 620, train_loss 0.708
epoch 13, batch 630, train_loss 0.694
epoch 13, batch 640, train_loss 0.693
epoch 13, batch 650, train_loss 0.698
epoch 13, batch 660, train_loss 0.701
epoch 13, batch 670, train_loss 0.694
epoch 13, batch 680, train_loss 0.690
epoch 13, batch 690, train_loss 0.704
epoch 13, batch 700, train_loss 0.698
epoch 13, batch 710, train_loss 0.701
epoch 13, batch 720, train_loss 0.706
epoch 13, batch 730, train_loss 0.699
epoch 13, batch 740, train_loss 0.705
epoch 13, batch 750, train_loss 0.691
epoch 13, batch 760, train_loss 0.705
epoch 13, batch 770, train_loss 0.706
epoch 13, batch 780, train_loss 0.699
epoch 13, batch 790, train_loss 0.710
epoch 13, batch 800, train_loss 0.693
epoch 13, batch 810, train_loss 0.700
epoch 13, batch 820, train_loss 0.703
epoch 13, batch 830, train_loss 0.696
epoch 13, batch 840, train_loss 0.703
epoch 13, batch 850, train_loss 0.694
epoch 13, batch 860, train_loss 0.691
epoch 13, batch 870, train_loss 0.694
epoch 13, batch 880, train_loss 0.702
epoch 13, batch 890, train_loss 0.698
epoch 13, batch 900, train_loss 0.708
epoch 13, batch 910, train_loss 0.708
epoch 13, batch 920, train_loss 0.695
epoch 13, batch 930, train_loss 0.701
epoch 13, batch 940, train_loss 0.706
epoch 13, batch 950, train_loss 0.702
epoch 13, batch 960, train_loss 0.701
epoch 13, batch 970, train_loss 0.704
epoch 13, batch 980, train_loss 0.699
epoch 13, batch 990, train_loss 0.697
epoch 13, batch 1000, train_loss 0.699
epoch 13, batch 1010, train_loss 0.704
epoch 13, batch 1020, train_loss 0.703
epoch 13, batch 1030, train_loss 0.695
epoch 13, batch 1040, train_loss 0.691
epoch 13, batch 1050, train_loss 0.695
epoch 13, batch 1060, train_loss 0.698
epoch 13, batch 1070, train_loss 0.697
epoch 13, batch 1080, train_loss 0.696
epoch 13, batch 1090, train_loss 0.702
epoch 13, batch 1100, train_loss 0.714
epoch 13, batch 1110, train_loss 0.692
epoch 13, batch 1120, train_loss 0.704
epoch 13, batch 1130, train_loss 0.707
epoch 13, batch 1140, train_loss 0.694
epoch 13, batch 1150, train_loss 0.697
epoch 13, batch 1160, train_loss 0.698
epoch 13, batch 1170, train_loss 0.705
epoch 13, batch 1180, train_loss 0.702
epoch 13, batch 1190, train_loss 0.696
epoch    13, train_loss 0.699, valid_loss 0.722, train_accuracy  69.87%, valid_accuracy  68.62%
epoch 14, batch 0, train_loss 0.697
epoch 14, batch 10, train_loss 0.697
epoch 14, batch 20, train_loss 0.694
epoch 14, batch 30, train_loss 0.700
epoch 14, batch 40, train_loss 0.698
epoch 14, batch 50, train_loss 0.695
epoch 14, batch 60, train_loss 0.691
epoch 14, batch 70, train_loss 0.702
epoch 14, batch 80, train_loss 0.693
epoch 14, batch 90, train_loss 0.699
epoch 14, batch 100, train_loss 0.702
epoch 14, batch 110, train_loss 0.696
epoch 14, batch 120, train_loss 0.698
epoch 14, batch 130, train_loss 0.696
epoch 14, batch 140, train_loss 0.699
epoch 14, batch 150, train_loss 0.698
epoch 14, batch 160, train_loss 0.694
epoch 14, batch 170, train_loss 0.697
epoch 14, batch 180, train_loss 0.693
epoch 14, batch 190, train_loss 0.692
epoch 14, batch 200, train_loss 0.698
epoch 14, batch 210, train_loss 0.711
epoch 14, batch 220, train_loss 0.696
epoch 14, batch 230, train_loss 0.705
epoch 14, batch 240, train_loss 0.707
epoch 14, batch 250, train_loss 0.711
epoch 14, batch 260, train_loss 0.702
epoch 14, batch 270, train_loss 0.701
epoch 14, batch 280, train_loss 0.695
epoch 14, batch 290, train_loss 0.711
epoch 14, batch 300, train_loss 0.692
epoch 14, batch 310, train_loss 0.694
epoch 14, batch 320, train_loss 0.699
epoch 14, batch 330, train_loss 0.699
epoch 14, batch 340, train_loss 0.709
epoch 14, batch 350, train_loss 0.699
epoch 14, batch 360, train_loss 0.695
epoch 14, batch 370, train_loss 0.701
epoch 14, batch 380, train_loss 0.702
epoch 14, batch 390, train_loss 0.698
epoch 14, batch 400, train_loss 0.701
epoch 14, batch 410, train_loss 0.690
epoch 14, batch 420, train_loss 0.710
epoch 14, batch 430, train_loss 0.699
epoch 14, batch 440, train_loss 0.699
epoch 14, batch 450, train_loss 0.697
epoch 14, batch 460, train_loss 0.693
epoch 14, batch 470, train_loss 0.703
epoch 14, batch 480, train_loss 0.691
epoch 14, batch 490, train_loss 0.700
epoch 14, batch 500, train_loss 0.696
epoch 14, batch 510, train_loss 0.698
epoch 14, batch 520, train_loss 0.701
epoch 14, batch 530, train_loss 0.697
epoch 14, batch 540, train_loss 0.697
epoch 14, batch 550, train_loss 0.711
epoch 14, batch 560, train_loss 0.698
epoch 14, batch 570, train_loss 0.697
epoch 14, batch 580, train_loss 0.698
epoch 14, batch 590, train_loss 0.703
epoch 14, batch 600, train_loss 0.699
epoch 14, batch 610, train_loss 0.699
epoch 14, batch 620, train_loss 0.697
epoch 14, batch 630, train_loss 0.702
epoch 14, batch 640, train_loss 0.699
epoch 14, batch 650, train_loss 0.695
epoch 14, batch 660, train_loss 0.694
epoch 14, batch 670, train_loss 0.701
epoch 14, batch 680, train_loss 0.694
epoch 14, batch 690, train_loss 0.697
epoch 14, batch 700, train_loss 0.705
epoch 14, batch 710, train_loss 0.701
epoch 14, batch 720, train_loss 0.695
epoch 14, batch 730, train_loss 0.696
epoch 14, batch 740, train_loss 0.698
epoch 14, batch 750, train_loss 0.707
epoch 14, batch 760, train_loss 0.698
epoch 14, batch 770, train_loss 0.691
epoch 14, batch 780, train_loss 0.711
epoch 14, batch 790, train_loss 0.701
epoch 14, batch 800, train_loss 0.709
epoch 14, batch 810, train_loss 0.699
epoch 14, batch 820, train_loss 0.701
epoch 14, batch 830, train_loss 0.706
epoch 14, batch 840, train_loss 0.706
epoch 14, batch 850, train_loss 0.706
epoch 14, batch 860, train_loss 0.701
epoch 14, batch 870, train_loss 0.700
epoch 14, batch 880, train_loss 0.694
epoch 14, batch 890, train_loss 0.701
epoch 14, batch 900, train_loss 0.694
epoch 14, batch 910, train_loss 0.705
epoch 14, batch 920, train_loss 0.700
epoch 14, batch 930, train_loss 0.694
epoch 14, batch 940, train_loss 0.698
epoch 14, batch 950, train_loss 0.698
epoch 14, batch 960, train_loss 0.697
epoch 14, batch 970, train_loss 0.702
epoch 14, batch 980, train_loss 0.703
epoch 14, batch 990, train_loss 0.702
epoch 14, batch 1000, train_loss 0.700
epoch 14, batch 1010, train_loss 0.708
epoch 14, batch 1020, train_loss 0.684
epoch 14, batch 1030, train_loss 0.707
epoch 14, batch 1040, train_loss 0.706
epoch 14, batch 1050, train_loss 0.697
epoch 14, batch 1060, train_loss 0.700
epoch 14, batch 1070, train_loss 0.694
epoch 14, batch 1080, train_loss 0.705
epoch 14, batch 1090, train_loss 0.705
epoch 14, batch 1100, train_loss 0.702
epoch 14, batch 1110, train_loss 0.700
epoch 14, batch 1120, train_loss 0.698
epoch 14, batch 1130, train_loss 0.699
epoch 14, batch 1140, train_loss 0.706
epoch 14, batch 1150, train_loss 0.694
epoch 14, batch 1160, train_loss 0.697
epoch 14, batch 1170, train_loss 0.706
epoch 14, batch 1180, train_loss 0.705
epoch 14, batch 1190, train_loss 0.693
epoch    14, train_loss 0.699, valid_loss 0.722, train_accuracy  69.89%, valid_accuracy  68.62%
epoch 15, batch 0, train_loss 0.692
epoch 15, batch 10, train_loss 0.698
epoch 15, batch 20, train_loss 0.691
epoch 15, batch 30, train_loss 0.695
epoch 15, batch 40, train_loss 0.694
epoch 15, batch 50, train_loss 0.697
epoch 15, batch 60, train_loss 0.698
epoch 15, batch 70, train_loss 0.693
epoch 15, batch 80, train_loss 0.697
epoch 15, batch 90, train_loss 0.703
epoch 15, batch 100, train_loss 0.700
epoch 15, batch 110, train_loss 0.705
epoch 15, batch 120, train_loss 0.709
epoch 15, batch 130, train_loss 0.703
epoch 15, batch 140, train_loss 0.699
epoch 15, batch 150, train_loss 0.707
epoch 15, batch 160, train_loss 0.701
epoch 15, batch 170, train_loss 0.698
epoch 15, batch 180, train_loss 0.702
epoch 15, batch 190, train_loss 0.701
epoch 15, batch 200, train_loss 0.694
epoch 15, batch 210, train_loss 0.695
epoch 15, batch 220, train_loss 0.698
epoch 15, batch 230, train_loss 0.698
epoch 15, batch 240, train_loss 0.697
epoch 15, batch 250, train_loss 0.703
epoch 15, batch 260, train_loss 0.700
epoch 15, batch 270, train_loss 0.698
epoch 15, batch 280, train_loss 0.698
epoch 15, batch 290, train_loss 0.694
epoch 15, batch 300, train_loss 0.708
epoch 15, batch 310, train_loss 0.702
epoch 15, batch 320, train_loss 0.694
epoch 15, batch 330, train_loss 0.705
epoch 15, batch 340, train_loss 0.689
epoch 15, batch 350, train_loss 0.698
epoch 15, batch 360, train_loss 0.691
epoch 15, batch 370, train_loss 0.702
epoch 15, batch 380, train_loss 0.706
epoch 15, batch 390, train_loss 0.694
epoch 15, batch 400, train_loss 0.692
epoch 15, batch 410, train_loss 0.705
epoch 15, batch 420, train_loss 0.692
epoch 15, batch 430, train_loss 0.701
epoch 15, batch 440, train_loss 0.696
epoch 15, batch 450, train_loss 0.706
epoch 15, batch 460, train_loss 0.703
epoch 15, batch 470, train_loss 0.713
epoch 15, batch 480, train_loss 0.693
epoch 15, batch 490, train_loss 0.697
epoch 15, batch 500, train_loss 0.699
epoch 15, batch 510, train_loss 0.697
epoch 15, batch 520, train_loss 0.708
epoch 15, batch 530, train_loss 0.703
epoch 15, batch 540, train_loss 0.710
epoch 15, batch 550, train_loss 0.691
epoch 15, batch 560, train_loss 0.694
epoch 15, batch 570, train_loss 0.713
epoch 15, batch 580, train_loss 0.709
epoch 15, batch 590, train_loss 0.699
epoch 15, batch 600, train_loss 0.698
epoch 15, batch 610, train_loss 0.704
epoch 15, batch 620, train_loss 0.695
epoch 15, batch 630, train_loss 0.704
epoch 15, batch 640, train_loss 0.703
epoch 15, batch 650, train_loss 0.704
epoch 15, batch 660, train_loss 0.691
epoch 15, batch 670, train_loss 0.689
epoch 15, batch 680, train_loss 0.695
epoch 15, batch 690, train_loss 0.694
epoch 15, batch 700, train_loss 0.697
epoch 15, batch 710, train_loss 0.700
epoch 15, batch 720, train_loss 0.708
epoch 15, batch 730, train_loss 0.698
epoch 15, batch 740, train_loss 0.700
epoch 15, batch 750, train_loss 0.705
epoch 15, batch 760, train_loss 0.702
epoch 15, batch 770, train_loss 0.702
epoch 15, batch 780, train_loss 0.701
epoch 15, batch 790, train_loss 0.702
epoch 15, batch 800, train_loss 0.700
epoch 15, batch 810, train_loss 0.694
epoch 15, batch 820, train_loss 0.706
epoch 15, batch 830, train_loss 0.704
epoch 15, batch 840, train_loss 0.702
epoch 15, batch 850, train_loss 0.701
epoch 15, batch 860, train_loss 0.692
epoch 15, batch 870, train_loss 0.691
epoch 15, batch 880, train_loss 0.696
epoch 15, batch 890, train_loss 0.704
epoch 15, batch 900, train_loss 0.698
epoch 15, batch 910, train_loss 0.695
epoch 15, batch 920, train_loss 0.700
epoch 15, batch 930, train_loss 0.686
epoch 15, batch 940, train_loss 0.695
epoch 15, batch 950, train_loss 0.699
epoch 15, batch 960, train_loss 0.696
epoch 15, batch 970, train_loss 0.699
epoch 15, batch 980, train_loss 0.694
epoch 15, batch 990, train_loss 0.694
epoch 15, batch 1000, train_loss 0.695
epoch 15, batch 1010, train_loss 0.690
epoch 15, batch 1020, train_loss 0.702
epoch 15, batch 1030, train_loss 0.704
epoch 15, batch 1040, train_loss 0.693
epoch 15, batch 1050, train_loss 0.693
epoch 15, batch 1060, train_loss 0.700
epoch 15, batch 1070, train_loss 0.702
epoch 15, batch 1080, train_loss 0.705
epoch 15, batch 1090, train_loss 0.693
epoch 15, batch 1100, train_loss 0.712
epoch 15, batch 1110, train_loss 0.697
epoch 15, batch 1120, train_loss 0.699
epoch 15, batch 1130, train_loss 0.707
epoch 15, batch 1140, train_loss 0.699
epoch 15, batch 1150, train_loss 0.700
epoch 15, batch 1160, train_loss 0.691
epoch 15, batch 1170, train_loss 0.701
epoch 15, batch 1180, train_loss 0.691
epoch 15, batch 1190, train_loss 0.705
epoch    15, train_loss 0.699, valid_loss 0.723, train_accuracy  69.87%, valid_accuracy  68.56%
epoch 16, batch 0, train_loss 0.697
epoch 16, batch 10, train_loss 0.701
epoch 16, batch 20, train_loss 0.698
epoch 16, batch 30, train_loss 0.703
epoch 16, batch 40, train_loss 0.705
epoch 16, batch 50, train_loss 0.703
epoch 16, batch 60, train_loss 0.701
epoch 16, batch 70, train_loss 0.702
epoch 16, batch 80, train_loss 0.690
epoch 16, batch 90, train_loss 0.700
epoch 16, batch 100, train_loss 0.700
epoch 16, batch 110, train_loss 0.695
epoch 16, batch 120, train_loss 0.703
epoch 16, batch 130, train_loss 0.689
epoch 16, batch 140, train_loss 0.697
epoch 16, batch 150, train_loss 0.702
epoch 16, batch 160, train_loss 0.701
epoch 16, batch 170, train_loss 0.699
epoch 16, batch 180, train_loss 0.695
epoch 16, batch 190, train_loss 0.702
epoch 16, batch 200, train_loss 0.700
epoch 16, batch 210, train_loss 0.692
epoch 16, batch 220, train_loss 0.698
epoch 16, batch 230, train_loss 0.696
epoch 16, batch 240, train_loss 0.704
epoch 16, batch 250, train_loss 0.700
epoch 16, batch 260, train_loss 0.716
epoch 16, batch 270, train_loss 0.689
epoch 16, batch 280, train_loss 0.691
epoch 16, batch 290, train_loss 0.696
epoch 16, batch 300, train_loss 0.696
epoch 16, batch 310, train_loss 0.694
epoch 16, batch 320, train_loss 0.703
epoch 16, batch 330, train_loss 0.696
epoch 16, batch 340, train_loss 0.697
epoch 16, batch 350, train_loss 0.705
epoch 16, batch 360, train_loss 0.696
epoch 16, batch 370, train_loss 0.693
epoch 16, batch 380, train_loss 0.693
epoch 16, batch 390, train_loss 0.690
epoch 16, batch 400, train_loss 0.694
epoch 16, batch 410, train_loss 0.703
epoch 16, batch 420, train_loss 0.692
epoch 16, batch 430, train_loss 0.694
epoch 16, batch 440, train_loss 0.693
epoch 16, batch 450, train_loss 0.689
epoch 16, batch 460, train_loss 0.702
epoch 16, batch 470, train_loss 0.701
epoch 16, batch 480, train_loss 0.706
epoch 16, batch 490, train_loss 0.703
epoch 16, batch 500, train_loss 0.694
epoch 16, batch 510, train_loss 0.702
epoch 16, batch 520, train_loss 0.706
epoch 16, batch 530, train_loss 0.696
epoch 16, batch 540, train_loss 0.706
epoch 16, batch 550, train_loss 0.700
epoch 16, batch 560, train_loss 0.697
epoch 16, batch 570, train_loss 0.698
epoch 16, batch 580, train_loss 0.697
epoch 16, batch 590, train_loss 0.702
epoch 16, batch 600, train_loss 0.693
epoch 16, batch 610, train_loss 0.701
epoch 16, batch 620, train_loss 0.703
epoch 16, batch 630, train_loss 0.693
epoch 16, batch 640, train_loss 0.693
epoch 16, batch 650, train_loss 0.687
epoch 16, batch 660, train_loss 0.698
epoch 16, batch 670, train_loss 0.691
epoch 16, batch 680, train_loss 0.697
epoch 16, batch 690, train_loss 0.693
epoch 16, batch 700, train_loss 0.697
epoch 16, batch 710, train_loss 0.695
epoch 16, batch 720, train_loss 0.698
epoch 16, batch 730, train_loss 0.691
epoch 16, batch 740, train_loss 0.701
epoch 16, batch 750, train_loss 0.704
epoch 16, batch 760, train_loss 0.700
epoch 16, batch 770, train_loss 0.701
epoch 16, batch 780, train_loss 0.697
epoch 16, batch 790, train_loss 0.700
epoch 16, batch 800, train_loss 0.710
epoch 16, batch 810, train_loss 0.696
epoch 16, batch 820, train_loss 0.697
epoch 16, batch 830, train_loss 0.707
epoch 16, batch 840, train_loss 0.704
epoch 16, batch 850, train_loss 0.697
epoch 16, batch 860, train_loss 0.690
epoch 16, batch 870, train_loss 0.700
epoch 16, batch 880, train_loss 0.701
epoch 16, batch 890, train_loss 0.696
epoch 16, batch 900, train_loss 0.701
epoch 16, batch 910, train_loss 0.701
epoch 16, batch 920, train_loss 0.701
epoch 16, batch 930, train_loss 0.692
epoch 16, batch 940, train_loss 0.700
epoch 16, batch 950, train_loss 0.699
epoch 16, batch 960, train_loss 0.697
epoch 16, batch 970, train_loss 0.690
epoch 16, batch 980, train_loss 0.690
epoch 16, batch 990, train_loss 0.699
epoch 16, batch 1000, train_loss 0.705
epoch 16, batch 1010, train_loss 0.702
epoch 16, batch 1020, train_loss 0.696
epoch 16, batch 1030, train_loss 0.692
epoch 16, batch 1040, train_loss 0.702
epoch 16, batch 1050, train_loss 0.701
epoch 16, batch 1060, train_loss 0.695
epoch 16, batch 1070, train_loss 0.698
epoch 16, batch 1080, train_loss 0.698
epoch 16, batch 1090, train_loss 0.700
epoch 16, batch 1100, train_loss 0.701
epoch 16, batch 1110, train_loss 0.697
epoch 16, batch 1120, train_loss 0.700
epoch 16, batch 1130, train_loss 0.698
epoch 16, batch 1140, train_loss 0.696
epoch 16, batch 1150, train_loss 0.699
epoch 16, batch 1160, train_loss 0.700
epoch 16, batch 1170, train_loss 0.691
epoch 16, batch 1180, train_loss 0.695
epoch 16, batch 1190, train_loss 0.701
epoch    16, train_loss 0.699, valid_loss 0.723, train_accuracy  69.88%, valid_accuracy  68.58%
epoch 17, batch 0, train_loss 0.695
epoch 17, batch 10, train_loss 0.703
epoch 17, batch 20, train_loss 0.709
epoch 17, batch 30, train_loss 0.701
epoch 17, batch 40, train_loss 0.706
epoch 17, batch 50, train_loss 0.694
epoch 17, batch 60, train_loss 0.695
epoch 17, batch 70, train_loss 0.703
epoch 17, batch 80, train_loss 0.704
epoch 17, batch 90, train_loss 0.691
epoch 17, batch 100, train_loss 0.699
epoch 17, batch 110, train_loss 0.699
epoch 17, batch 120, train_loss 0.693
epoch 17, batch 130, train_loss 0.694
epoch 17, batch 140, train_loss 0.704
epoch 17, batch 150, train_loss 0.690
epoch 17, batch 160, train_loss 0.692
epoch 17, batch 170, train_loss 0.700
epoch 17, batch 180, train_loss 0.698
epoch 17, batch 190, train_loss 0.701
epoch 17, batch 200, train_loss 0.703
epoch 17, batch 210, train_loss 0.705
epoch 17, batch 220, train_loss 0.693
epoch 17, batch 230, train_loss 0.700
epoch 17, batch 240, train_loss 0.697
epoch 17, batch 250, train_loss 0.698
epoch 17, batch 260, train_loss 0.700
epoch 17, batch 270, train_loss 0.707
epoch 17, batch 280, train_loss 0.701
epoch 17, batch 290, train_loss 0.699
epoch 17, batch 300, train_loss 0.695
epoch 17, batch 310, train_loss 0.705
epoch 17, batch 320, train_loss 0.692
epoch 17, batch 330, train_loss 0.698
epoch 17, batch 340, train_loss 0.695
epoch 17, batch 350, train_loss 0.696
epoch 17, batch 360, train_loss 0.714
epoch 17, batch 370, train_loss 0.701
epoch 17, batch 380, train_loss 0.702
epoch 17, batch 390, train_loss 0.701
epoch 17, batch 400, train_loss 0.691
epoch 17, batch 410, train_loss 0.686
epoch 17, batch 420, train_loss 0.707
epoch 17, batch 430, train_loss 0.704
epoch 17, batch 440, train_loss 0.699
epoch 17, batch 450, train_loss 0.697
epoch 17, batch 460, train_loss 0.697
epoch 17, batch 470, train_loss 0.704
epoch 17, batch 480, train_loss 0.699
epoch 17, batch 490, train_loss 0.700
epoch 17, batch 500, train_loss 0.695
epoch 17, batch 510, train_loss 0.694
epoch 17, batch 520, train_loss 0.699
epoch 17, batch 530, train_loss 0.692
epoch 17, batch 540, train_loss 0.703
epoch 17, batch 550, train_loss 0.706
epoch 17, batch 560, train_loss 0.709
epoch 17, batch 570, train_loss 0.701
epoch 17, batch 580, train_loss 0.681
epoch 17, batch 590, train_loss 0.694
epoch 17, batch 600, train_loss 0.700
epoch 17, batch 610, train_loss 0.698
epoch 17, batch 620, train_loss 0.701
epoch 17, batch 630, train_loss 0.700
epoch 17, batch 640, train_loss 0.705
epoch 17, batch 650, train_loss 0.702
epoch 17, batch 660, train_loss 0.701
epoch 17, batch 670, train_loss 0.699
epoch 17, batch 680, train_loss 0.697
epoch 17, batch 690, train_loss 0.700
epoch 17, batch 700, train_loss 0.700
epoch 17, batch 710, train_loss 0.704
epoch 17, batch 720, train_loss 0.710
epoch 17, batch 730, train_loss 0.702
epoch 17, batch 740, train_loss 0.695
epoch 17, batch 750, train_loss 0.690
epoch 17, batch 760, train_loss 0.704
epoch 17, batch 770, train_loss 0.694
epoch 17, batch 780, train_loss 0.695
epoch 17, batch 790, train_loss 0.695
epoch 17, batch 800, train_loss 0.694
epoch 17, batch 810, train_loss 0.702
epoch 17, batch 820, train_loss 0.693
epoch 17, batch 830, train_loss 0.697
epoch 17, batch 840, train_loss 0.700
epoch 17, batch 850, train_loss 0.694
epoch 17, batch 860, train_loss 0.700
epoch 17, batch 870, train_loss 0.695
epoch 17, batch 880, train_loss 0.694
epoch 17, batch 890, train_loss 0.702
epoch 17, batch 900, train_loss 0.700
epoch 17, batch 910, train_loss 0.698
epoch 17, batch 920, train_loss 0.702
epoch 17, batch 930, train_loss 0.696
epoch 17, batch 940, train_loss 0.706
epoch 17, batch 950, train_loss 0.695
epoch 17, batch 960, train_loss 0.699
epoch 17, batch 970, train_loss 0.708
epoch 17, batch 980, train_loss 0.700
epoch 17, batch 990, train_loss 0.698
epoch 17, batch 1000, train_loss 0.698
epoch 17, batch 1010, train_loss 0.699
epoch 17, batch 1020, train_loss 0.692
epoch 17, batch 1030, train_loss 0.701
epoch 17, batch 1040, train_loss 0.690
epoch 17, batch 1050, train_loss 0.698
epoch 17, batch 1060, train_loss 0.689
epoch 17, batch 1070, train_loss 0.699
epoch 17, batch 1080, train_loss 0.695
epoch 17, batch 1090, train_loss 0.690
epoch 17, batch 1100, train_loss 0.705
epoch 17, batch 1110, train_loss 0.688
epoch 17, batch 1120, train_loss 0.700
epoch 17, batch 1130, train_loss 0.692
epoch 17, batch 1140, train_loss 0.696
epoch 17, batch 1150, train_loss 0.696
epoch 17, batch 1160, train_loss 0.700
epoch 17, batch 1170, train_loss 0.699
epoch 17, batch 1180, train_loss 0.693
epoch 17, batch 1190, train_loss 0.700
epoch    17, train_loss 0.698, valid_loss 0.723, train_accuracy  69.92%, valid_accuracy  68.59%
epoch 18, batch 0, train_loss 0.701
epoch 18, batch 10, train_loss 0.699
epoch 18, batch 20, train_loss 0.698
epoch 18, batch 30, train_loss 0.700
epoch 18, batch 40, train_loss 0.701
epoch 18, batch 50, train_loss 0.696
epoch 18, batch 60, train_loss 0.700
epoch 18, batch 70, train_loss 0.686
epoch 18, batch 80, train_loss 0.695
epoch 18, batch 90, train_loss 0.702
epoch 18, batch 100, train_loss 0.706
epoch 18, batch 110, train_loss 0.698
epoch 18, batch 120, train_loss 0.691
epoch 18, batch 130, train_loss 0.690
epoch 18, batch 140, train_loss 0.699
epoch 18, batch 150, train_loss 0.698
epoch 18, batch 160, train_loss 0.701
epoch 18, batch 170, train_loss 0.696
epoch 18, batch 180, train_loss 0.692
epoch 18, batch 190, train_loss 0.707
epoch 18, batch 200, train_loss 0.701
epoch 18, batch 210, train_loss 0.690
epoch 18, batch 220, train_loss 0.695
epoch 18, batch 230, train_loss 0.694
epoch 18, batch 240, train_loss 0.704
epoch 18, batch 250, train_loss 0.701
epoch 18, batch 260, train_loss 0.704
epoch 18, batch 270, train_loss 0.690
epoch 18, batch 280, train_loss 0.704
epoch 18, batch 290, train_loss 0.692
epoch 18, batch 300, train_loss 0.695
epoch 18, batch 310, train_loss 0.694
epoch 18, batch 320, train_loss 0.693
epoch 18, batch 330, train_loss 0.709
epoch 18, batch 340, train_loss 0.704
epoch 18, batch 350, train_loss 0.700
epoch 18, batch 360, train_loss 0.703
epoch 18, batch 370, train_loss 0.695
epoch 18, batch 380, train_loss 0.703
epoch 18, batch 390, train_loss 0.695
epoch 18, batch 400, train_loss 0.690
epoch 18, batch 410, train_loss 0.701
epoch 18, batch 420, train_loss 0.695
epoch 18, batch 430, train_loss 0.699
epoch 18, batch 440, train_loss 0.696
epoch 18, batch 450, train_loss 0.692
epoch 18, batch 460, train_loss 0.698
epoch 18, batch 470, train_loss 0.705
epoch 18, batch 480, train_loss 0.708
epoch 18, batch 490, train_loss 0.699
epoch 18, batch 500, train_loss 0.693
epoch 18, batch 510, train_loss 0.704
epoch 18, batch 520, train_loss 0.691
epoch 18, batch 530, train_loss 0.700
epoch 18, batch 540, train_loss 0.706
epoch 18, batch 550, train_loss 0.693
epoch 18, batch 560, train_loss 0.691
epoch 18, batch 570, train_loss 0.711
epoch 18, batch 580, train_loss 0.699
epoch 18, batch 590, train_loss 0.695
epoch 18, batch 600, train_loss 0.709
epoch 18, batch 610, train_loss 0.689
epoch 18, batch 620, train_loss 0.698
epoch 18, batch 630, train_loss 0.701
epoch 18, batch 640, train_loss 0.701
epoch 18, batch 650, train_loss 0.708
epoch 18, batch 660, train_loss 0.696
epoch 18, batch 670, train_loss 0.699
epoch 18, batch 680, train_loss 0.687
epoch 18, batch 690, train_loss 0.694
epoch 18, batch 700, train_loss 0.707
epoch 18, batch 710, train_loss 0.697
epoch 18, batch 720, train_loss 0.704
epoch 18, batch 730, train_loss 0.700
epoch 18, batch 740, train_loss 0.690
epoch 18, batch 750, train_loss 0.703
epoch 18, batch 760, train_loss 0.696
epoch 18, batch 770, train_loss 0.700
epoch 18, batch 780, train_loss 0.692
epoch 18, batch 790, train_loss 0.696
epoch 18, batch 800, train_loss 0.692
epoch 18, batch 810, train_loss 0.687
epoch 18, batch 820, train_loss 0.700
epoch 18, batch 830, train_loss 0.700
epoch 18, batch 840, train_loss 0.702
epoch 18, batch 850, train_loss 0.704
epoch 18, batch 860, train_loss 0.700
epoch 18, batch 870, train_loss 0.692
epoch 18, batch 880, train_loss 0.698
epoch 18, batch 890, train_loss 0.709
epoch 18, batch 900, train_loss 0.694
epoch 18, batch 910, train_loss 0.696
epoch 18, batch 920, train_loss 0.691
epoch 18, batch 930, train_loss 0.695
epoch 18, batch 940, train_loss 0.705
epoch 18, batch 950, train_loss 0.697
epoch 18, batch 960, train_loss 0.702
epoch 18, batch 970, train_loss 0.697
epoch 18, batch 980, train_loss 0.702
epoch 18, batch 990, train_loss 0.693
epoch 18, batch 1000, train_loss 0.696
epoch 18, batch 1010, train_loss 0.693
epoch 18, batch 1020, train_loss 0.701
epoch 18, batch 1030, train_loss 0.697
epoch 18, batch 1040, train_loss 0.695
epoch 18, batch 1050, train_loss 0.698
epoch 18, batch 1060, train_loss 0.700
epoch 18, batch 1070, train_loss 0.702
epoch 18, batch 1080, train_loss 0.694
epoch 18, batch 1090, train_loss 0.705
epoch 18, batch 1100, train_loss 0.695
epoch 18, batch 1110, train_loss 0.701
epoch 18, batch 1120, train_loss 0.706
epoch 18, batch 1130, train_loss 0.693
epoch 18, batch 1140, train_loss 0.695
epoch 18, batch 1150, train_loss 0.701
epoch 18, batch 1160, train_loss 0.708
epoch 18, batch 1170, train_loss 0.699
epoch 18, batch 1180, train_loss 0.692
epoch 18, batch 1190, train_loss 0.688
epoch    18, train_loss 0.697, valid_loss 0.722, train_accuracy  69.97%, valid_accuracy  68.63%
epoch 19, batch 0, train_loss 0.703
epoch 19, batch 10, train_loss 0.699
epoch 19, batch 20, train_loss 0.702
epoch 19, batch 30, train_loss 0.698
epoch 19, batch 40, train_loss 0.700
epoch 19, batch 50, train_loss 0.701
epoch 19, batch 60, train_loss 0.697
epoch 19, batch 70, train_loss 0.702
epoch 19, batch 80, train_loss 0.699
epoch 19, batch 90, train_loss 0.700
epoch 19, batch 100, train_loss 0.703
epoch 19, batch 110, train_loss 0.705
epoch 19, batch 120, train_loss 0.698
epoch 19, batch 130, train_loss 0.705
epoch 19, batch 140, train_loss 0.692
epoch 19, batch 150, train_loss 0.696
epoch 19, batch 160, train_loss 0.699
epoch 19, batch 170, train_loss 0.688
epoch 19, batch 180, train_loss 0.693
epoch 19, batch 190, train_loss 0.702
epoch 19, batch 200, train_loss 0.693
epoch 19, batch 210, train_loss 0.697
epoch 19, batch 220, train_loss 0.689
epoch 19, batch 230, train_loss 0.698
epoch 19, batch 240, train_loss 0.696
epoch 19, batch 250, train_loss 0.691
epoch 19, batch 260, train_loss 0.704
epoch 19, batch 270, train_loss 0.701
epoch 19, batch 280, train_loss 0.693
epoch 19, batch 290, train_loss 0.698
epoch 19, batch 300, train_loss 0.706
epoch 19, batch 310, train_loss 0.695
epoch 19, batch 320, train_loss 0.694
epoch 19, batch 330, train_loss 0.705
epoch 19, batch 340, train_loss 0.703
epoch 19, batch 350, train_loss 0.694
epoch 19, batch 360, train_loss 0.686
epoch 19, batch 370, train_loss 0.695
epoch 19, batch 380, train_loss 0.690
epoch 19, batch 390, train_loss 0.695
epoch 19, batch 400, train_loss 0.704
epoch 19, batch 410, train_loss 0.696
epoch 19, batch 420, train_loss 0.704
epoch 19, batch 430, train_loss 0.702
epoch 19, batch 440, train_loss 0.693
epoch 19, batch 450, train_loss 0.691
epoch 19, batch 460, train_loss 0.697
epoch 19, batch 470, train_loss 0.687
epoch 19, batch 480, train_loss 0.691
epoch 19, batch 490, train_loss 0.693
epoch 19, batch 500, train_loss 0.700
epoch 19, batch 510, train_loss 0.703
epoch 19, batch 520, train_loss 0.693
epoch 19, batch 530, train_loss 0.696
epoch 19, batch 540, train_loss 0.697
epoch 19, batch 550, train_loss 0.703
epoch 19, batch 560, train_loss 0.699
epoch 19, batch 570, train_loss 0.697
epoch 19, batch 580, train_loss 0.694
epoch 19, batch 590, train_loss 0.692
epoch 19, batch 600, train_loss 0.691
epoch 19, batch 610, train_loss 0.702
epoch 19, batch 620, train_loss 0.698
epoch 19, batch 630, train_loss 0.703
epoch 19, batch 640, train_loss 0.697
epoch 19, batch 650, train_loss 0.695
epoch 19, batch 660, train_loss 0.698
epoch 19, batch 670, train_loss 0.695
epoch 19, batch 680, train_loss 0.705
epoch 19, batch 690, train_loss 0.708
epoch 19, batch 700, train_loss 0.706
epoch 19, batch 710, train_loss 0.705
epoch 19, batch 720, train_loss 0.695
epoch 19, batch 730, train_loss 0.694
epoch 19, batch 740, train_loss 0.710
epoch 19, batch 750, train_loss 0.690
epoch 19, batch 760, train_loss 0.702
epoch 19, batch 770, train_loss 0.708
epoch 19, batch 780, train_loss 0.697
epoch 19, batch 790, train_loss 0.701
epoch 19, batch 800, train_loss 0.693
epoch 19, batch 810, train_loss 0.703
epoch 19, batch 820, train_loss 0.704
epoch 19, batch 830, train_loss 0.701
epoch 19, batch 840, train_loss 0.696
epoch 19, batch 850, train_loss 0.702
epoch 19, batch 860, train_loss 0.691
epoch 19, batch 870, train_loss 0.692
epoch 19, batch 880, train_loss 0.703
epoch 19, batch 890, train_loss 0.688
epoch 19, batch 900, train_loss 0.692
epoch 19, batch 910, train_loss 0.695
epoch 19, batch 920, train_loss 0.695
epoch 19, batch 930, train_loss 0.695
epoch 19, batch 940, train_loss 0.705
epoch 19, batch 950, train_loss 0.697
epoch 19, batch 960, train_loss 0.688
epoch 19, batch 970, train_loss 0.706
epoch 19, batch 980, train_loss 0.706
epoch 19, batch 990, train_loss 0.697
epoch 19, batch 1000, train_loss 0.700
epoch 19, batch 1010, train_loss 0.703
epoch 19, batch 1020, train_loss 0.707
epoch 19, batch 1030, train_loss 0.695
epoch 19, batch 1040, train_loss 0.697
epoch 19, batch 1050, train_loss 0.700
epoch 19, batch 1060, train_loss 0.702
epoch 19, batch 1070, train_loss 0.700
epoch 19, batch 1080, train_loss 0.692
epoch 19, batch 1090, train_loss 0.706
epoch 19, batch 1100, train_loss 0.692
epoch 19, batch 1110, train_loss 0.692
epoch 19, batch 1120, train_loss 0.704
epoch 19, batch 1130, train_loss 0.699
epoch 19, batch 1140, train_loss 0.694
epoch 19, batch 1150, train_loss 0.706
epoch 19, batch 1160, train_loss 0.692
epoch 19, batch 1170, train_loss 0.694
epoch 19, batch 1180, train_loss 0.695
epoch 19, batch 1190, train_loss 0.702
epoch    19, train_loss 0.697, valid_loss 0.722, train_accuracy  69.99%, valid_accuracy  68.59%
epoch 20, batch 0, train_loss 0.698
epoch 20, batch 10, train_loss 0.699
epoch 20, batch 20, train_loss 0.704
epoch 20, batch 30, train_loss 0.702
epoch 20, batch 40, train_loss 0.692
epoch 20, batch 50, train_loss 0.691
epoch 20, batch 60, train_loss 0.690
epoch 20, batch 70, train_loss 0.701
epoch 20, batch 80, train_loss 0.689
epoch 20, batch 90, train_loss 0.701
epoch 20, batch 100, train_loss 0.698
epoch 20, batch 110, train_loss 0.701
epoch 20, batch 120, train_loss 0.692
epoch 20, batch 130, train_loss 0.704
epoch 20, batch 140, train_loss 0.697
epoch 20, batch 150, train_loss 0.699
epoch 20, batch 160, train_loss 0.696
epoch 20, batch 170, train_loss 0.703
epoch 20, batch 180, train_loss 0.691
epoch 20, batch 190, train_loss 0.700
epoch 20, batch 200, train_loss 0.699
epoch 20, batch 210, train_loss 0.697
epoch 20, batch 220, train_loss 0.694
epoch 20, batch 230, train_loss 0.695
epoch 20, batch 240, train_loss 0.698
epoch 20, batch 250, train_loss 0.694
epoch 20, batch 260, train_loss 0.698
epoch 20, batch 270, train_loss 0.703
epoch 20, batch 280, train_loss 0.695
epoch 20, batch 290, train_loss 0.697
epoch 20, batch 300, train_loss 0.695
epoch 20, batch 310, train_loss 0.693
epoch 20, batch 320, train_loss 0.685
epoch 20, batch 330, train_loss 0.706
epoch 20, batch 340, train_loss 0.708
epoch 20, batch 350, train_loss 0.687
epoch 20, batch 360, train_loss 0.698
epoch 20, batch 370, train_loss 0.688
epoch 20, batch 380, train_loss 0.689
epoch 20, batch 390, train_loss 0.703
epoch 20, batch 400, train_loss 0.703
epoch 20, batch 410, train_loss 0.703
epoch 20, batch 420, train_loss 0.698
epoch 20, batch 430, train_loss 0.700
epoch 20, batch 440, train_loss 0.701
epoch 20, batch 450, train_loss 0.697
epoch 20, batch 460, train_loss 0.693
epoch 20, batch 470, train_loss 0.700
epoch 20, batch 480, train_loss 0.701
epoch 20, batch 490, train_loss 0.694
epoch 20, batch 500, train_loss 0.703
epoch 20, batch 510, train_loss 0.702
epoch 20, batch 520, train_loss 0.693
epoch 20, batch 530, train_loss 0.696
epoch 20, batch 540, train_loss 0.702
epoch 20, batch 550, train_loss 0.697
epoch 20, batch 560, train_loss 0.692
epoch 20, batch 570, train_loss 0.705
epoch 20, batch 580, train_loss 0.701
epoch 20, batch 590, train_loss 0.700
epoch 20, batch 600, train_loss 0.700
epoch 20, batch 610, train_loss 0.709
epoch 20, batch 620, train_loss 0.696
epoch 20, batch 630, train_loss 0.694
epoch 20, batch 640, train_loss 0.696
epoch 20, batch 650, train_loss 0.696
epoch 20, batch 660, train_loss 0.703
epoch 20, batch 670, train_loss 0.700
epoch 20, batch 680, train_loss 0.686
epoch 20, batch 690, train_loss 0.701
epoch 20, batch 700, train_loss 0.695
epoch 20, batch 710, train_loss 0.699
epoch 20, batch 720, train_loss 0.690
epoch 20, batch 730, train_loss 0.690
epoch 20, batch 740, train_loss 0.701
epoch 20, batch 750, train_loss 0.698
epoch 20, batch 760, train_loss 0.697
epoch 20, batch 770, train_loss 0.698
epoch 20, batch 780, train_loss 0.689
epoch 20, batch 790, train_loss 0.697
epoch 20, batch 800, train_loss 0.705
epoch 20, batch 810, train_loss 0.688
epoch 20, batch 820, train_loss 0.701
epoch 20, batch 830, train_loss 0.701
epoch 20, batch 840, train_loss 0.695
epoch 20, batch 850, train_loss 0.703
epoch 20, batch 860, train_loss 0.704
epoch 20, batch 870, train_loss 0.708
epoch 20, batch 880, train_loss 0.701
epoch 20, batch 890, train_loss 0.694
epoch 20, batch 900, train_loss 0.697
epoch 20, batch 910, train_loss 0.698
epoch 20, batch 920, train_loss 0.692
epoch 20, batch 930, train_loss 0.692
epoch 20, batch 940, train_loss 0.699
epoch 20, batch 950, train_loss 0.697
epoch 20, batch 960, train_loss 0.704
epoch 20, batch 970, train_loss 0.705
epoch 20, batch 980, train_loss 0.698
epoch 20, batch 990, train_loss 0.687
epoch 20, batch 1000, train_loss 0.694
epoch 20, batch 1010, train_loss 0.696
epoch 20, batch 1020, train_loss 0.690
epoch 20, batch 1030, train_loss 0.705
epoch 20, batch 1040, train_loss 0.699
epoch 20, batch 1050, train_loss 0.691
epoch 20, batch 1060, train_loss 0.693
epoch 20, batch 1070, train_loss 0.685
epoch 20, batch 1080, train_loss 0.703
epoch 20, batch 1090, train_loss 0.698
epoch 20, batch 1100, train_loss 0.695
epoch 20, batch 1110, train_loss 0.690
epoch 20, batch 1120, train_loss 0.692
epoch 20, batch 1130, train_loss 0.697
epoch 20, batch 1140, train_loss 0.688
epoch 20, batch 1150, train_loss 0.684
epoch 20, batch 1160, train_loss 0.694
epoch 20, batch 1170, train_loss 0.700
epoch 20, batch 1180, train_loss 0.699
epoch 20, batch 1190, train_loss 0.685
epoch    20, train_loss 0.696, valid_loss 0.722, train_accuracy  70.02%, valid_accuracy  68.66%
epoch 21, batch 0, train_loss 0.685
epoch 21, batch 10, train_loss 0.694
epoch 21, batch 20, train_loss 0.708
epoch 21, batch 30, train_loss 0.700
epoch 21, batch 40, train_loss 0.697
epoch 21, batch 50, train_loss 0.699
epoch 21, batch 60, train_loss 0.683
epoch 21, batch 70, train_loss 0.694
epoch 21, batch 80, train_loss 0.701
epoch 21, batch 90, train_loss 0.692
epoch 21, batch 100, train_loss 0.697
epoch 21, batch 110, train_loss 0.691
epoch 21, batch 120, train_loss 0.710
epoch 21, batch 130, train_loss 0.694
epoch 21, batch 140, train_loss 0.697
epoch 21, batch 150, train_loss 0.698
epoch 21, batch 160, train_loss 0.696
epoch 21, batch 170, train_loss 0.690
epoch 21, batch 180, train_loss 0.692
epoch 21, batch 190, train_loss 0.703
epoch 21, batch 200, train_loss 0.696
epoch 21, batch 210, train_loss 0.696
epoch 21, batch 220, train_loss 0.693
epoch 21, batch 230, train_loss 0.704
epoch 21, batch 240, train_loss 0.695
epoch 21, batch 250, train_loss 0.695
epoch 21, batch 260, train_loss 0.709
epoch 21, batch 270, train_loss 0.707
epoch 21, batch 280, train_loss 0.681
epoch 21, batch 290, train_loss 0.703
epoch 21, batch 300, train_loss 0.704
epoch 21, batch 310, train_loss 0.702
epoch 21, batch 320, train_loss 0.697
epoch 21, batch 330, train_loss 0.695
epoch 21, batch 340, train_loss 0.699
epoch 21, batch 350, train_loss 0.707
epoch 21, batch 360, train_loss 0.697
epoch 21, batch 370, train_loss 0.705
epoch 21, batch 380, train_loss 0.692
epoch 21, batch 390, train_loss 0.694
epoch 21, batch 400, train_loss 0.701
epoch 21, batch 410, train_loss 0.691
epoch 21, batch 420, train_loss 0.704
epoch 21, batch 430, train_loss 0.690
epoch 21, batch 440, train_loss 0.694
epoch 21, batch 450, train_loss 0.697
epoch 21, batch 460, train_loss 0.697
epoch 21, batch 470, train_loss 0.697
epoch 21, batch 480, train_loss 0.694
epoch 21, batch 490, train_loss 0.702
epoch 21, batch 500, train_loss 0.700
epoch 21, batch 510, train_loss 0.695
epoch 21, batch 520, train_loss 0.697
epoch 21, batch 530, train_loss 0.690
epoch 21, batch 540, train_loss 0.696
epoch 21, batch 550, train_loss 0.703
epoch 21, batch 560, train_loss 0.701
epoch 21, batch 570, train_loss 0.698
epoch 21, batch 580, train_loss 0.691
epoch 21, batch 590, train_loss 0.699
epoch 21, batch 600, train_loss 0.690
epoch 21, batch 610, train_loss 0.702
epoch 21, batch 620, train_loss 0.702
epoch 21, batch 630, train_loss 0.699
epoch 21, batch 640, train_loss 0.698
epoch 21, batch 650, train_loss 0.691
epoch 21, batch 660, train_loss 0.703
epoch 21, batch 670, train_loss 0.698
epoch 21, batch 680, train_loss 0.697
epoch 21, batch 690, train_loss 0.699
epoch 21, batch 700, train_loss 0.700
epoch 21, batch 710, train_loss 0.696
epoch 21, batch 720, train_loss 0.689
epoch 21, batch 730, train_loss 0.694
epoch 21, batch 740, train_loss 0.688
epoch 21, batch 750, train_loss 0.697
epoch 21, batch 760, train_loss 0.708
epoch 21, batch 770, train_loss 0.693
epoch 21, batch 780, train_loss 0.704
epoch 21, batch 790, train_loss 0.705
epoch 21, batch 800, train_loss 0.688
epoch 21, batch 810, train_loss 0.700
epoch 21, batch 820, train_loss 0.704
epoch 21, batch 830, train_loss 0.702
epoch 21, batch 840, train_loss 0.701
epoch 21, batch 850, train_loss 0.679
epoch 21, batch 860, train_loss 0.710
epoch 21, batch 870, train_loss 0.695
epoch 21, batch 880, train_loss 0.705
epoch 21, batch 890, train_loss 0.688
epoch 21, batch 900, train_loss 0.705
epoch 21, batch 910, train_loss 0.702
epoch 21, batch 920, train_loss 0.713
epoch 21, batch 930, train_loss 0.690
epoch 21, batch 940, train_loss 0.701
epoch 21, batch 950, train_loss 0.698
epoch 21, batch 960, train_loss 0.698
epoch 21, batch 970, train_loss 0.696
epoch 21, batch 980, train_loss 0.696
epoch 21, batch 990, train_loss 0.696
epoch 21, batch 1000, train_loss 0.696
epoch 21, batch 1010, train_loss 0.699
epoch 21, batch 1020, train_loss 0.691
epoch 21, batch 1030, train_loss 0.702
epoch 21, batch 1040, train_loss 0.694
epoch 21, batch 1050, train_loss 0.709
epoch 21, batch 1060, train_loss 0.690
epoch 21, batch 1070, train_loss 0.703
epoch 21, batch 1080, train_loss 0.702
epoch 21, batch 1090, train_loss 0.699
epoch 21, batch 1100, train_loss 0.689
epoch 21, batch 1110, train_loss 0.701
epoch 21, batch 1120, train_loss 0.708
epoch 21, batch 1130, train_loss 0.694
epoch 21, batch 1140, train_loss 0.696
epoch 21, batch 1150, train_loss 0.701
epoch 21, batch 1160, train_loss 0.701
epoch 21, batch 1170, train_loss 0.706
epoch 21, batch 1180, train_loss 0.703
epoch 21, batch 1190, train_loss 0.697
epoch    21, train_loss 0.697, valid_loss 0.723, train_accuracy  69.97%, valid_accuracy  68.58%
epoch 22, batch 0, train_loss 0.697
epoch 22, batch 10, train_loss 0.697
epoch 22, batch 20, train_loss 0.699
epoch 22, batch 30, train_loss 0.697
epoch 22, batch 40, train_loss 0.692
epoch 22, batch 50, train_loss 0.701
epoch 22, batch 60, train_loss 0.705
epoch 22, batch 70, train_loss 0.688
epoch 22, batch 80, train_loss 0.692
epoch 22, batch 90, train_loss 0.699
epoch 22, batch 100, train_loss 0.682
epoch 22, batch 110, train_loss 0.704
epoch 22, batch 120, train_loss 0.704
epoch 22, batch 130, train_loss 0.697
epoch 22, batch 140, train_loss 0.685
epoch 22, batch 150, train_loss 0.697
epoch 22, batch 160, train_loss 0.693
epoch 22, batch 170, train_loss 0.691
epoch 22, batch 180, train_loss 0.692
epoch 22, batch 190, train_loss 0.697
epoch 22, batch 200, train_loss 0.698
epoch 22, batch 210, train_loss 0.698
epoch 22, batch 220, train_loss 0.700
epoch 22, batch 230, train_loss 0.700
epoch 22, batch 240, train_loss 0.684
epoch 22, batch 250, train_loss 0.708
epoch 22, batch 260, train_loss 0.694
epoch 22, batch 270, train_loss 0.695
epoch 22, batch 280, train_loss 0.708
epoch 22, batch 290, train_loss 0.697
epoch 22, batch 300, train_loss 0.693
epoch 22, batch 310, train_loss 0.699
epoch 22, batch 320, train_loss 0.698
epoch 22, batch 330, train_loss 0.695
epoch 22, batch 340, train_loss 0.704
epoch 22, batch 350, train_loss 0.697
epoch 22, batch 360, train_loss 0.695
epoch 22, batch 370, train_loss 0.700
epoch 22, batch 380, train_loss 0.698
epoch 22, batch 390, train_loss 0.693
epoch 22, batch 400, train_loss 0.696
epoch 22, batch 410, train_loss 0.701
epoch 22, batch 420, train_loss 0.705
epoch 22, batch 430, train_loss 0.698
epoch 22, batch 440, train_loss 0.708
epoch 22, batch 450, train_loss 0.696
epoch 22, batch 460, train_loss 0.696
epoch 22, batch 470, train_loss 0.692
epoch 22, batch 480, train_loss 0.694
epoch 22, batch 490, train_loss 0.698
epoch 22, batch 500, train_loss 0.701
epoch 22, batch 510, train_loss 0.699
epoch 22, batch 520, train_loss 0.698
epoch 22, batch 530, train_loss 0.693
epoch 22, batch 540, train_loss 0.696
epoch 22, batch 550, train_loss 0.703
epoch 22, batch 560, train_loss 0.698
epoch 22, batch 570, train_loss 0.700
epoch 22, batch 580, train_loss 0.695
epoch 22, batch 590, train_loss 0.696
epoch 22, batch 600, train_loss 0.694
epoch 22, batch 610, train_loss 0.688
epoch 22, batch 620, train_loss 0.701
epoch 22, batch 630, train_loss 0.692
epoch 22, batch 640, train_loss 0.693
epoch 22, batch 650, train_loss 0.685
epoch 22, batch 660, train_loss 0.706
epoch 22, batch 670, train_loss 0.694
epoch 22, batch 680, train_loss 0.689
epoch 22, batch 690, train_loss 0.699
epoch 22, batch 700, train_loss 0.701
epoch 22, batch 710, train_loss 0.695
epoch 22, batch 720, train_loss 0.699
epoch 22, batch 730, train_loss 0.695
epoch 22, batch 740, train_loss 0.690
epoch 22, batch 750, train_loss 0.685
epoch 22, batch 760, train_loss 0.700
epoch 22, batch 770, train_loss 0.695
epoch 22, batch 780, train_loss 0.699
epoch 22, batch 790, train_loss 0.706
epoch 22, batch 800, train_loss 0.701
epoch 22, batch 810, train_loss 0.687
epoch 22, batch 820, train_loss 0.689
epoch 22, batch 830, train_loss 0.698
epoch 22, batch 840, train_loss 0.695
epoch 22, batch 850, train_loss 0.702
epoch 22, batch 860, train_loss 0.702
epoch 22, batch 870, train_loss 0.692
epoch 22, batch 880, train_loss 0.688
epoch 22, batch 890, train_loss 0.704
epoch 22, batch 900, train_loss 0.705
epoch 22, batch 910, train_loss 0.692
epoch 22, batch 920, train_loss 0.711
epoch 22, batch 930, train_loss 0.704
epoch 22, batch 940, train_loss 0.692
epoch 22, batch 950, train_loss 0.703
epoch 22, batch 960, train_loss 0.695
epoch 22, batch 970, train_loss 0.697
epoch 22, batch 980, train_loss 0.690
epoch 22, batch 990, train_loss 0.707
epoch 22, batch 1000, train_loss 0.699
epoch 22, batch 1010, train_loss 0.694
epoch 22, batch 1020, train_loss 0.697
epoch 22, batch 1030, train_loss 0.699
epoch 22, batch 1040, train_loss 0.693
epoch 22, batch 1050, train_loss 0.708
epoch 22, batch 1060, train_loss 0.692
epoch 22, batch 1070, train_loss 0.704
epoch 22, batch 1080, train_loss 0.697
epoch 22, batch 1090, train_loss 0.691
epoch 22, batch 1100, train_loss 0.700
epoch 22, batch 1110, train_loss 0.698
epoch 22, batch 1120, train_loss 0.697
epoch 22, batch 1130, train_loss 0.698
epoch 22, batch 1140, train_loss 0.702
epoch 22, batch 1150, train_loss 0.694
epoch 22, batch 1160, train_loss 0.703
epoch 22, batch 1170, train_loss 0.695
epoch 22, batch 1180, train_loss 0.703
epoch 22, batch 1190, train_loss 0.697
epoch    22, train_loss 0.696, valid_loss 0.721, train_accuracy  70.10%, valid_accuracy  68.62%
epoch 23, batch 0, train_loss 0.696
epoch 23, batch 10, train_loss 0.697
epoch 23, batch 20, train_loss 0.693
epoch 23, batch 30, train_loss 0.694
epoch 23, batch 40, train_loss 0.691
epoch 23, batch 50, train_loss 0.693
epoch 23, batch 60, train_loss 0.697
epoch 23, batch 70, train_loss 0.698
epoch 23, batch 80, train_loss 0.689
epoch 23, batch 90, train_loss 0.693
epoch 23, batch 100, train_loss 0.697
epoch 23, batch 110, train_loss 0.697
epoch 23, batch 120, train_loss 0.691
epoch 23, batch 130, train_loss 0.699
epoch 23, batch 140, train_loss 0.695
epoch 23, batch 150, train_loss 0.696
epoch 23, batch 160, train_loss 0.687
epoch 23, batch 170, train_loss 0.693
epoch 23, batch 180, train_loss 0.682
epoch 23, batch 190, train_loss 0.699
epoch 23, batch 200, train_loss 0.704
epoch 23, batch 210, train_loss 0.696
epoch 23, batch 220, train_loss 0.683
epoch 23, batch 230, train_loss 0.703
epoch 23, batch 240, train_loss 0.702
epoch 23, batch 250, train_loss 0.691
epoch 23, batch 260, train_loss 0.702
epoch 23, batch 270, train_loss 0.695
epoch 23, batch 280, train_loss 0.691
epoch 23, batch 290, train_loss 0.697
epoch 23, batch 300, train_loss 0.693
epoch 23, batch 310, train_loss 0.709
epoch 23, batch 320, train_loss 0.699
epoch 23, batch 330, train_loss 0.702
epoch 23, batch 340, train_loss 0.702
epoch 23, batch 350, train_loss 0.704
epoch 23, batch 360, train_loss 0.694
epoch 23, batch 370, train_loss 0.693
epoch 23, batch 380, train_loss 0.713
epoch 23, batch 390, train_loss 0.701
epoch 23, batch 400, train_loss 0.693
epoch 23, batch 410, train_loss 0.708
epoch 23, batch 420, train_loss 0.701
epoch 23, batch 430, train_loss 0.696
epoch 23, batch 440, train_loss 0.695
epoch 23, batch 450, train_loss 0.686
epoch 23, batch 460, train_loss 0.700
epoch 23, batch 470, train_loss 0.702
epoch 23, batch 480, train_loss 0.688
epoch 23, batch 490, train_loss 0.702
epoch 23, batch 500, train_loss 0.701
epoch 23, batch 510, train_loss 0.694
epoch 23, batch 520, train_loss 0.693
epoch 23, batch 530, train_loss 0.694
epoch 23, batch 540, train_loss 0.701
epoch 23, batch 550, train_loss 0.695
epoch 23, batch 560, train_loss 0.693
epoch 23, batch 570, train_loss 0.696
epoch 23, batch 580, train_loss 0.699
epoch 23, batch 590, train_loss 0.702
epoch 23, batch 600, train_loss 0.696
epoch 23, batch 610, train_loss 0.705
epoch 23, batch 620, train_loss 0.695
epoch 23, batch 630, train_loss 0.694
epoch 23, batch 640, train_loss 0.702
epoch 23, batch 650, train_loss 0.702
epoch 23, batch 660, train_loss 0.697
epoch 23, batch 670, train_loss 0.702
epoch 23, batch 680, train_loss 0.699
epoch 23, batch 690, train_loss 0.696
epoch 23, batch 700, train_loss 0.698
epoch 23, batch 710, train_loss 0.697
epoch 23, batch 720, train_loss 0.692
epoch 23, batch 730, train_loss 0.700
epoch 23, batch 740, train_loss 0.694
epoch 23, batch 750, train_loss 0.694
epoch 23, batch 760, train_loss 0.710
epoch 23, batch 770, train_loss 0.694
epoch 23, batch 780, train_loss 0.701
epoch 23, batch 790, train_loss 0.691
epoch 23, batch 800, train_loss 0.702
epoch 23, batch 810, train_loss 0.694
epoch 23, batch 820, train_loss 0.704
epoch 23, batch 830, train_loss 0.691
epoch 23, batch 840, train_loss 0.705
epoch 23, batch 850, train_loss 0.701
epoch 23, batch 860, train_loss 0.690
epoch 23, batch 870, train_loss 0.701
epoch 23, batch 880, train_loss 0.702
epoch 23, batch 890, train_loss 0.704
epoch 23, batch 900, train_loss 0.690
epoch 23, batch 910, train_loss 0.689
epoch 23, batch 920, train_loss 0.703
epoch 23, batch 930, train_loss 0.692
epoch 23, batch 940, train_loss 0.700
epoch 23, batch 950, train_loss 0.705
epoch 23, batch 960, train_loss 0.691
epoch 23, batch 970, train_loss 0.698
epoch 23, batch 980, train_loss 0.688
epoch 23, batch 990, train_loss 0.697
epoch 23, batch 1000, train_loss 0.694
epoch 23, batch 1010, train_loss 0.690
epoch 23, batch 1020, train_loss 0.701
epoch 23, batch 1030, train_loss 0.697
epoch 23, batch 1040, train_loss 0.700
epoch 23, batch 1050, train_loss 0.692
epoch 23, batch 1060, train_loss 0.698
epoch 23, batch 1070, train_loss 0.692
epoch 23, batch 1080, train_loss 0.694
epoch 23, batch 1090, train_loss 0.709
epoch 23, batch 1100, train_loss 0.688
epoch 23, batch 1110, train_loss 0.695
epoch 23, batch 1120, train_loss 0.702
epoch 23, batch 1130, train_loss 0.701
epoch 23, batch 1140, train_loss 0.695
epoch 23, batch 1150, train_loss 0.703
epoch 23, batch 1160, train_loss 0.700
epoch 23, batch 1170, train_loss 0.699
epoch 23, batch 1180, train_loss 0.706
epoch 23, batch 1190, train_loss 0.699
epoch    23, train_loss 0.695, valid_loss 0.722, train_accuracy  70.08%, valid_accuracy  68.62%
epoch 24, batch 0, train_loss 0.703
epoch 24, batch 10, train_loss 0.699
epoch 24, batch 20, train_loss 0.698
epoch 24, batch 30, train_loss 0.684
epoch 24, batch 40, train_loss 0.698
epoch 24, batch 50, train_loss 0.694
epoch 24, batch 60, train_loss 0.696
epoch 24, batch 70, train_loss 0.688
epoch 24, batch 80, train_loss 0.698
epoch 24, batch 90, train_loss 0.706
epoch 24, batch 100, train_loss 0.704
epoch 24, batch 110, train_loss 0.694
epoch 24, batch 120, train_loss 0.696
epoch 24, batch 130, train_loss 0.699
epoch 24, batch 140, train_loss 0.695
epoch 24, batch 150, train_loss 0.689
epoch 24, batch 160, train_loss 0.696
epoch 24, batch 170, train_loss 0.694
epoch 24, batch 180, train_loss 0.694
epoch 24, batch 190, train_loss 0.707
epoch 24, batch 200, train_loss 0.700
epoch 24, batch 210, train_loss 0.687
epoch 24, batch 220, train_loss 0.697
epoch 24, batch 230, train_loss 0.692
epoch 24, batch 240, train_loss 0.691
epoch 24, batch 250, train_loss 0.696
epoch 24, batch 260, train_loss 0.703
epoch 24, batch 270, train_loss 0.703
epoch 24, batch 280, train_loss 0.696
epoch 24, batch 290, train_loss 0.694
epoch 24, batch 300, train_loss 0.696
epoch 24, batch 310, train_loss 0.689
epoch 24, batch 320, train_loss 0.702
epoch 24, batch 330, train_loss 0.690
epoch 24, batch 340, train_loss 0.699
epoch 24, batch 350, train_loss 0.697
epoch 24, batch 360, train_loss 0.688
epoch 24, batch 370, train_loss 0.703
epoch 24, batch 380, train_loss 0.693
epoch 24, batch 390, train_loss 0.694
epoch 24, batch 400, train_loss 0.698
epoch 24, batch 410, train_loss 0.694
epoch 24, batch 420, train_loss 0.693
epoch 24, batch 430, train_loss 0.710
epoch 24, batch 440, train_loss 0.707
epoch 24, batch 450, train_loss 0.710
epoch 24, batch 460, train_loss 0.698
epoch 24, batch 470, train_loss 0.692
epoch 24, batch 480, train_loss 0.699
epoch 24, batch 490, train_loss 0.696
epoch 24, batch 500, train_loss 0.700
epoch 24, batch 510, train_loss 0.691
epoch 24, batch 520, train_loss 0.704
epoch 24, batch 530, train_loss 0.699
epoch 24, batch 540, train_loss 0.696
epoch 24, batch 550, train_loss 0.696
epoch 24, batch 560, train_loss 0.701
epoch 24, batch 570, train_loss 0.694
epoch 24, batch 580, train_loss 0.708
epoch 24, batch 590, train_loss 0.689
epoch 24, batch 600, train_loss 0.704
epoch 24, batch 610, train_loss 0.695
epoch 24, batch 620, train_loss 0.691
epoch 24, batch 630, train_loss 0.693
epoch 24, batch 640, train_loss 0.700
epoch 24, batch 650, train_loss 0.694
epoch 24, batch 660, train_loss 0.702
epoch 24, batch 670, train_loss 0.698
epoch 24, batch 680, train_loss 0.700
epoch 24, batch 690, train_loss 0.692
epoch 24, batch 700, train_loss 0.690
epoch 24, batch 710, train_loss 0.696
epoch 24, batch 720, train_loss 0.697
epoch 24, batch 730, train_loss 0.693
epoch 24, batch 740, train_loss 0.702
epoch 24, batch 750, train_loss 0.698
epoch 24, batch 760, train_loss 0.702
epoch 24, batch 770, train_loss 0.699
epoch 24, batch 780, train_loss 0.697
epoch 24, batch 790, train_loss 0.703
epoch 24, batch 800, train_loss 0.704
epoch 24, batch 810, train_loss 0.700
epoch 24, batch 820, train_loss 0.696
epoch 24, batch 830, train_loss 0.695
epoch 24, batch 840, train_loss 0.692
epoch 24, batch 850, train_loss 0.694
epoch 24, batch 860, train_loss 0.695
epoch 24, batch 870, train_loss 0.696
epoch 24, batch 880, train_loss 0.698
epoch 24, batch 890, train_loss 0.701
epoch 24, batch 900, train_loss 0.694
epoch 24, batch 910, train_loss 0.698
epoch 24, batch 920, train_loss 0.697
epoch 24, batch 930, train_loss 0.697
epoch 24, batch 940, train_loss 0.710
epoch 24, batch 950, train_loss 0.697
epoch 24, batch 960, train_loss 0.695
epoch 24, batch 970, train_loss 0.693
epoch 24, batch 980, train_loss 0.703
epoch 24, batch 990, train_loss 0.703
epoch 24, batch 1000, train_loss 0.701
epoch 24, batch 1010, train_loss 0.688
epoch 24, batch 1020, train_loss 0.693
epoch 24, batch 1030, train_loss 0.697
epoch 24, batch 1040, train_loss 0.700
epoch 24, batch 1050, train_loss 0.690
epoch 24, batch 1060, train_loss 0.690
epoch 24, batch 1070, train_loss 0.695
epoch 24, batch 1080, train_loss 0.685
epoch 24, batch 1090, train_loss 0.689
epoch 24, batch 1100, train_loss 0.690
epoch 24, batch 1110, train_loss 0.692
epoch 24, batch 1120, train_loss 0.698
epoch 24, batch 1130, train_loss 0.702
epoch 24, batch 1140, train_loss 0.696
epoch 24, batch 1150, train_loss 0.708
epoch 24, batch 1160, train_loss 0.700
epoch 24, batch 1170, train_loss 0.695
epoch 24, batch 1180, train_loss 0.696
epoch 24, batch 1190, train_loss 0.696
epoch    24, train_loss 0.695, valid_loss 0.722, train_accuracy  70.10%, valid_accuracy  68.61%
epoch 25, batch 0, train_loss 0.693
epoch 25, batch 10, train_loss 0.685
epoch 25, batch 20, train_loss 0.701
epoch 25, batch 30, train_loss 0.696
epoch 25, batch 40, train_loss 0.691
epoch 25, batch 50, train_loss 0.695
epoch 25, batch 60, train_loss 0.692
epoch 25, batch 70, train_loss 0.698
epoch 25, batch 80, train_loss 0.695
epoch 25, batch 90, train_loss 0.699
epoch 25, batch 100, train_loss 0.689
epoch 25, batch 110, train_loss 0.697
epoch 25, batch 120, train_loss 0.697
epoch 25, batch 130, train_loss 0.693
epoch 25, batch 140, train_loss 0.697
epoch 25, batch 150, train_loss 0.693
epoch 25, batch 160, train_loss 0.690
epoch 25, batch 170, train_loss 0.709
epoch 25, batch 180, train_loss 0.693
epoch 25, batch 190, train_loss 0.692
epoch 25, batch 200, train_loss 0.689
epoch 25, batch 210, train_loss 0.700
epoch 25, batch 220, train_loss 0.701
epoch 25, batch 230, train_loss 0.692
epoch 25, batch 240, train_loss 0.696
epoch 25, batch 250, train_loss 0.694
epoch 25, batch 260, train_loss 0.697
epoch 25, batch 270, train_loss 0.690
epoch 25, batch 280, train_loss 0.695
epoch 25, batch 290, train_loss 0.691
epoch 25, batch 300, train_loss 0.695
epoch 25, batch 310, train_loss 0.702
epoch 25, batch 320, train_loss 0.697
epoch 25, batch 330, train_loss 0.687
epoch 25, batch 340, train_loss 0.700
epoch 25, batch 350, train_loss 0.695
epoch 25, batch 360, train_loss 0.702
epoch 25, batch 370, train_loss 0.688
epoch 25, batch 380, train_loss 0.699
epoch 25, batch 390, train_loss 0.697
epoch 25, batch 400, train_loss 0.694
epoch 25, batch 410, train_loss 0.697
epoch 25, batch 420, train_loss 0.691
epoch 25, batch 430, train_loss 0.681
epoch 25, batch 440, train_loss 0.696
epoch 25, batch 450, train_loss 0.699
epoch 25, batch 460, train_loss 0.700
epoch 25, batch 470, train_loss 0.692
epoch 25, batch 480, train_loss 0.696
epoch 25, batch 490, train_loss 0.698
epoch 25, batch 500, train_loss 0.700
epoch 25, batch 510, train_loss 0.694
epoch 25, batch 520, train_loss 0.702
epoch 25, batch 530, train_loss 0.698
epoch 25, batch 540, train_loss 0.701
epoch 25, batch 550, train_loss 0.698
epoch 25, batch 560, train_loss 0.705
epoch 25, batch 570, train_loss 0.706
epoch 25, batch 580, train_loss 0.690
epoch 25, batch 590, train_loss 0.693
epoch 25, batch 600, train_loss 0.706
epoch 25, batch 610, train_loss 0.700
epoch 25, batch 620, train_loss 0.689
epoch 25, batch 630, train_loss 0.693
epoch 25, batch 640, train_loss 0.696
epoch 25, batch 650, train_loss 0.697
epoch 25, batch 660, train_loss 0.691
epoch 25, batch 670, train_loss 0.698
epoch 25, batch 680, train_loss 0.696
epoch 25, batch 690, train_loss 0.699
epoch 25, batch 700, train_loss 0.698
epoch 25, batch 710, train_loss 0.695
epoch 25, batch 720, train_loss 0.686
epoch 25, batch 730, train_loss 0.692
epoch 25, batch 740, train_loss 0.708
epoch 25, batch 750, train_loss 0.693
epoch 25, batch 760, train_loss 0.693
epoch 25, batch 770, train_loss 0.698
epoch 25, batch 780, train_loss 0.697
epoch 25, batch 790, train_loss 0.693
epoch 25, batch 800, train_loss 0.701
epoch 25, batch 810, train_loss 0.695
epoch 25, batch 820, train_loss 0.702
epoch 25, batch 830, train_loss 0.698
epoch 25, batch 840, train_loss 0.690
epoch 25, batch 850, train_loss 0.703
epoch 25, batch 860, train_loss 0.704
epoch 25, batch 870, train_loss 0.686
epoch 25, batch 880, train_loss 0.698
epoch 25, batch 890, train_loss 0.702
epoch 25, batch 900, train_loss 0.703
epoch 25, batch 910, train_loss 0.700
epoch 25, batch 920, train_loss 0.702
epoch 25, batch 930, train_loss 0.693
epoch 25, batch 940, train_loss 0.700
epoch 25, batch 950, train_loss 0.699
epoch 25, batch 960, train_loss 0.701
epoch 25, batch 970, train_loss 0.704
epoch 25, batch 980, train_loss 0.692
epoch 25, batch 990, train_loss 0.696
epoch 25, batch 1000, train_loss 0.701
epoch 25, batch 1010, train_loss 0.696
epoch 25, batch 1020, train_loss 0.700
epoch 25, batch 1030, train_loss 0.692
epoch 25, batch 1040, train_loss 0.700
epoch 25, batch 1050, train_loss 0.696
epoch 25, batch 1060, train_loss 0.685
epoch 25, batch 1070, train_loss 0.705
epoch 25, batch 1080, train_loss 0.695
epoch 25, batch 1090, train_loss 0.698
epoch 25, batch 1100, train_loss 0.693
epoch 25, batch 1110, train_loss 0.700
epoch 25, batch 1120, train_loss 0.688
epoch 25, batch 1130, train_loss 0.696
epoch 25, batch 1140, train_loss 0.698
epoch 25, batch 1150, train_loss 0.692
epoch 25, batch 1160, train_loss 0.693
epoch 25, batch 1170, train_loss 0.694
epoch 25, batch 1180, train_loss 0.699
epoch 25, batch 1190, train_loss 0.699
epoch    25, train_loss 0.695, valid_loss 0.722, train_accuracy  70.11%, valid_accuracy  68.62%
epoch 26, batch 0, train_loss 0.699
epoch 26, batch 10, train_loss 0.697
epoch 26, batch 20, train_loss 0.698
epoch 26, batch 30, train_loss 0.692
epoch 26, batch 40, train_loss 0.694
epoch 26, batch 50, train_loss 0.699
epoch 26, batch 60, train_loss 0.697
epoch 26, batch 70, train_loss 0.699
epoch 26, batch 80, train_loss 0.690
epoch 26, batch 90, train_loss 0.694
epoch 26, batch 100, train_loss 0.699
epoch 26, batch 110, train_loss 0.697
epoch 26, batch 120, train_loss 0.689
epoch 26, batch 130, train_loss 0.693
epoch 26, batch 140, train_loss 0.694
epoch 26, batch 150, train_loss 0.687
epoch 26, batch 160, train_loss 0.700
epoch 26, batch 170, train_loss 0.699
epoch 26, batch 180, train_loss 0.692
epoch 26, batch 190, train_loss 0.688
epoch 26, batch 200, train_loss 0.695
epoch 26, batch 210, train_loss 0.695
epoch 26, batch 220, train_loss 0.701
epoch 26, batch 230, train_loss 0.702
epoch 26, batch 240, train_loss 0.691
epoch 26, batch 250, train_loss 0.708
epoch 26, batch 260, train_loss 0.699
epoch 26, batch 270, train_loss 0.700
epoch 26, batch 280, train_loss 0.711
epoch 26, batch 290, train_loss 0.689
epoch 26, batch 300, train_loss 0.696
epoch 26, batch 310, train_loss 0.692
epoch 26, batch 320, train_loss 0.697
epoch 26, batch 330, train_loss 0.703
epoch 26, batch 340, train_loss 0.697
epoch 26, batch 350, train_loss 0.689
epoch 26, batch 360, train_loss 0.696
epoch 26, batch 370, train_loss 0.697
epoch 26, batch 380, train_loss 0.691
epoch 26, batch 390, train_loss 0.688
epoch 26, batch 400, train_loss 0.694
epoch 26, batch 410, train_loss 0.692
epoch 26, batch 420, train_loss 0.700
epoch 26, batch 430, train_loss 0.704
epoch 26, batch 440, train_loss 0.696
epoch 26, batch 450, train_loss 0.700
epoch 26, batch 460, train_loss 0.702
epoch 26, batch 470, train_loss 0.697
epoch 26, batch 480, train_loss 0.698
epoch 26, batch 490, train_loss 0.693
epoch 26, batch 500, train_loss 0.682
epoch 26, batch 510, train_loss 0.700
epoch 26, batch 520, train_loss 0.698
epoch 26, batch 530, train_loss 0.702
epoch 26, batch 540, train_loss 0.692
epoch 26, batch 550, train_loss 0.700
epoch 26, batch 560, train_loss 0.694
epoch 26, batch 570, train_loss 0.687
epoch 26, batch 580, train_loss 0.703
epoch 26, batch 590, train_loss 0.697
epoch 26, batch 600, train_loss 0.702
epoch 26, batch 610, train_loss 0.707
epoch 26, batch 620, train_loss 0.694
epoch 26, batch 630, train_loss 0.699
epoch 26, batch 640, train_loss 0.694
epoch 26, batch 650, train_loss 0.690
epoch 26, batch 660, train_loss 0.695
epoch 26, batch 670, train_loss 0.708
epoch 26, batch 680, train_loss 0.700
epoch 26, batch 690, train_loss 0.694
epoch 26, batch 700, train_loss 0.698
epoch 26, batch 710, train_loss 0.704
epoch 26, batch 720, train_loss 0.703
epoch 26, batch 730, train_loss 0.691
epoch 26, batch 740, train_loss 0.693
epoch 26, batch 750, train_loss 0.690
epoch 26, batch 760, train_loss 0.692
epoch 26, batch 770, train_loss 0.702
epoch 26, batch 780, train_loss 0.701
epoch 26, batch 790, train_loss 0.696
epoch 26, batch 800, train_loss 0.694
epoch 26, batch 810, train_loss 0.690
epoch 26, batch 820, train_loss 0.689
epoch 26, batch 830, train_loss 0.687
epoch 26, batch 840, train_loss 0.703
epoch 26, batch 850, train_loss 0.704
epoch 26, batch 860, train_loss 0.686
epoch 26, batch 870, train_loss 0.691
epoch 26, batch 880, train_loss 0.691
epoch 26, batch 890, train_loss 0.692
epoch 26, batch 900, train_loss 0.702
epoch 26, batch 910, train_loss 0.703
epoch 26, batch 920, train_loss 0.696
epoch 26, batch 930, train_loss 0.699
epoch 26, batch 940, train_loss 0.690
epoch 26, batch 950, train_loss 0.691
epoch 26, batch 960, train_loss 0.692
epoch 26, batch 970, train_loss 0.689
epoch 26, batch 980, train_loss 0.688
epoch 26, batch 990, train_loss 0.685
epoch 26, batch 1000, train_loss 0.693
epoch 26, batch 1010, train_loss 0.680
epoch 26, batch 1020, train_loss 0.696
epoch 26, batch 1030, train_loss 0.698
epoch 26, batch 1040, train_loss 0.697
epoch 26, batch 1050, train_loss 0.691
epoch 26, batch 1060, train_loss 0.689
epoch 26, batch 1070, train_loss 0.694
epoch 26, batch 1080, train_loss 0.700
epoch 26, batch 1090, train_loss 0.695
epoch 26, batch 1100, train_loss 0.692
epoch 26, batch 1110, train_loss 0.692
epoch 26, batch 1120, train_loss 0.698
epoch 26, batch 1130, train_loss 0.704
epoch 26, batch 1140, train_loss 0.696
epoch 26, batch 1150, train_loss 0.685
epoch 26, batch 1160, train_loss 0.692
epoch 26, batch 1170, train_loss 0.705
epoch 26, batch 1180, train_loss 0.692
epoch 26, batch 1190, train_loss 0.691
epoch    26, train_loss 0.695, valid_loss 0.722, train_accuracy  70.09%, valid_accuracy  68.60%
epoch 27, batch 0, train_loss 0.694
epoch 27, batch 10, train_loss 0.700
epoch 27, batch 20, train_loss 0.695
epoch 27, batch 30, train_loss 0.693
epoch 27, batch 40, train_loss 0.692
epoch 27, batch 50, train_loss 0.697
epoch 27, batch 60, train_loss 0.702
epoch 27, batch 70, train_loss 0.694
epoch 27, batch 80, train_loss 0.695
epoch 27, batch 90, train_loss 0.697
epoch 27, batch 100, train_loss 0.687
epoch 27, batch 110, train_loss 0.695
epoch 27, batch 120, train_loss 0.693
epoch 27, batch 130, train_loss 0.700
epoch 27, batch 140, train_loss 0.700
epoch 27, batch 150, train_loss 0.690
epoch 27, batch 160, train_loss 0.680
epoch 27, batch 170, train_loss 0.703
epoch 27, batch 180, train_loss 0.693
epoch 27, batch 190, train_loss 0.692
epoch 27, batch 200, train_loss 0.695
epoch 27, batch 210, train_loss 0.704
epoch 27, batch 220, train_loss 0.684
epoch 27, batch 230, train_loss 0.702
epoch 27, batch 240, train_loss 0.698
epoch 27, batch 250, train_loss 0.698
epoch 27, batch 260, train_loss 0.698
epoch 27, batch 270, train_loss 0.702
epoch 27, batch 280, train_loss 0.697
epoch 27, batch 290, train_loss 0.688
epoch 27, batch 300, train_loss 0.700
epoch 27, batch 310, train_loss 0.708
epoch 27, batch 320, train_loss 0.707
epoch 27, batch 330, train_loss 0.693
epoch 27, batch 340, train_loss 0.700
epoch 27, batch 350, train_loss 0.693
epoch 27, batch 360, train_loss 0.700
epoch 27, batch 370, train_loss 0.694
epoch 27, batch 380, train_loss 0.701
epoch 27, batch 390, train_loss 0.701
epoch 27, batch 400, train_loss 0.692
epoch 27, batch 410, train_loss 0.690
epoch 27, batch 420, train_loss 0.690
epoch 27, batch 430, train_loss 0.709
epoch 27, batch 440, train_loss 0.695
epoch 27, batch 450, train_loss 0.681
epoch 27, batch 460, train_loss 0.695
epoch 27, batch 470, train_loss 0.692
epoch 27, batch 480, train_loss 0.696
epoch 27, batch 490, train_loss 0.685
epoch 27, batch 500, train_loss 0.693
epoch 27, batch 510, train_loss 0.704
epoch 27, batch 520, train_loss 0.696
epoch 27, batch 530, train_loss 0.691
epoch 27, batch 540, train_loss 0.697
epoch 27, batch 550, train_loss 0.694
epoch 27, batch 560, train_loss 0.695
epoch 27, batch 570, train_loss 0.705
epoch 27, batch 580, train_loss 0.695
epoch 27, batch 590, train_loss 0.695
epoch 27, batch 600, train_loss 0.693
epoch 27, batch 610, train_loss 0.697
epoch 27, batch 620, train_loss 0.694
epoch 27, batch 630, train_loss 0.703
epoch 27, batch 640, train_loss 0.694
epoch 27, batch 650, train_loss 0.696
epoch 27, batch 660, train_loss 0.701
epoch 27, batch 670, train_loss 0.698
epoch 27, batch 680, train_loss 0.705
epoch 27, batch 690, train_loss 0.692
epoch 27, batch 700, train_loss 0.689
epoch 27, batch 710, train_loss 0.697
epoch 27, batch 720, train_loss 0.692
epoch 27, batch 730, train_loss 0.697
epoch 27, batch 740, train_loss 0.687
epoch 27, batch 750, train_loss 0.687
epoch 27, batch 760, train_loss 0.693
epoch 27, batch 770, train_loss 0.701
epoch 27, batch 780, train_loss 0.695
epoch 27, batch 790, train_loss 0.701
epoch 27, batch 800, train_loss 0.695
epoch 27, batch 810, train_loss 0.696
epoch 27, batch 820, train_loss 0.696
epoch 27, batch 830, train_loss 0.698
epoch 27, batch 840, train_loss 0.699
epoch 27, batch 850, train_loss 0.698
epoch 27, batch 860, train_loss 0.701
epoch 27, batch 870, train_loss 0.696
epoch 27, batch 880, train_loss 0.697
epoch 27, batch 890, train_loss 0.695
epoch 27, batch 900, train_loss 0.697
epoch 27, batch 910, train_loss 0.701
epoch 27, batch 920, train_loss 0.695
epoch 27, batch 930, train_loss 0.693
epoch 27, batch 940, train_loss 0.697
epoch 27, batch 950, train_loss 0.700
epoch 27, batch 960, train_loss 0.700
epoch 27, batch 970, train_loss 0.701
epoch 27, batch 980, train_loss 0.698
epoch 27, batch 990, train_loss 0.700
epoch 27, batch 1000, train_loss 0.699
epoch 27, batch 1010, train_loss 0.692
epoch 27, batch 1020, train_loss 0.699
epoch 27, batch 1030, train_loss 0.693
epoch 27, batch 1040, train_loss 0.698
epoch 27, batch 1050, train_loss 0.688
epoch 27, batch 1060, train_loss 0.697
epoch 27, batch 1070, train_loss 0.691
epoch 27, batch 1080, train_loss 0.693
epoch 27, batch 1090, train_loss 0.697
epoch 27, batch 1100, train_loss 0.699
epoch 27, batch 1110, train_loss 0.685
epoch 27, batch 1120, train_loss 0.695
epoch 27, batch 1130, train_loss 0.698
epoch 27, batch 1140, train_loss 0.692
epoch 27, batch 1150, train_loss 0.694
epoch 27, batch 1160, train_loss 0.700
epoch 27, batch 1170, train_loss 0.696
epoch 27, batch 1180, train_loss 0.698
epoch 27, batch 1190, train_loss 0.690
epoch    27, train_loss 0.695, valid_loss 0.722, train_accuracy  70.14%, valid_accuracy  68.61%
epoch 28, batch 0, train_loss 0.697
epoch 28, batch 10, train_loss 0.693
epoch 28, batch 20, train_loss 0.692
epoch 28, batch 30, train_loss 0.698
epoch 28, batch 40, train_loss 0.706
epoch 28, batch 50, train_loss 0.698
epoch 28, batch 60, train_loss 0.700
epoch 28, batch 70, train_loss 0.701
epoch 28, batch 80, train_loss 0.702
epoch 28, batch 90, train_loss 0.694
epoch 28, batch 100, train_loss 0.702
epoch 28, batch 110, train_loss 0.697
epoch 28, batch 120, train_loss 0.689
epoch 28, batch 130, train_loss 0.694
epoch 28, batch 140, train_loss 0.682
epoch 28, batch 150, train_loss 0.687
epoch 28, batch 160, train_loss 0.700
epoch 28, batch 170, train_loss 0.697
epoch 28, batch 180, train_loss 0.695
epoch 28, batch 190, train_loss 0.694
epoch 28, batch 200, train_loss 0.701
epoch 28, batch 210, train_loss 0.704
epoch 28, batch 220, train_loss 0.696
epoch 28, batch 230, train_loss 0.701
epoch 28, batch 240, train_loss 0.701
epoch 28, batch 250, train_loss 0.692
epoch 28, batch 260, train_loss 0.701
epoch 28, batch 270, train_loss 0.699
epoch 28, batch 280, train_loss 0.688
epoch 28, batch 290, train_loss 0.689
epoch 28, batch 300, train_loss 0.696
epoch 28, batch 310, train_loss 0.691
epoch 28, batch 320, train_loss 0.695
epoch 28, batch 330, train_loss 0.695
epoch 28, batch 340, train_loss 0.700
epoch 28, batch 350, train_loss 0.694
epoch 28, batch 360, train_loss 0.695
epoch 28, batch 370, train_loss 0.696
epoch 28, batch 380, train_loss 0.700
epoch 28, batch 390, train_loss 0.690
epoch 28, batch 400, train_loss 0.700
epoch 28, batch 410, train_loss 0.701
epoch 28, batch 420, train_loss 0.690
epoch 28, batch 430, train_loss 0.695
epoch 28, batch 440, train_loss 0.694
epoch 28, batch 450, train_loss 0.699
epoch 28, batch 460, train_loss 0.701
epoch 28, batch 470, train_loss 0.704
epoch 28, batch 480, train_loss 0.695
epoch 28, batch 490, train_loss 0.703
epoch 28, batch 500, train_loss 0.697
epoch 28, batch 510, train_loss 0.697
epoch 28, batch 520, train_loss 0.696
epoch 28, batch 530, train_loss 0.704
epoch 28, batch 540, train_loss 0.699
epoch 28, batch 550, train_loss 0.690
epoch 28, batch 560, train_loss 0.701
epoch 28, batch 570, train_loss 0.700
epoch 28, batch 580, train_loss 0.683
epoch 28, batch 590, train_loss 0.703
epoch 28, batch 600, train_loss 0.696
epoch 28, batch 610, train_loss 0.688
epoch 28, batch 620, train_loss 0.698
epoch 28, batch 630, train_loss 0.695
epoch 28, batch 640, train_loss 0.701
epoch 28, batch 650, train_loss 0.691
epoch 28, batch 660, train_loss 0.686
epoch 28, batch 670, train_loss 0.694
epoch 28, batch 680, train_loss 0.694
epoch 28, batch 690, train_loss 0.686
epoch 28, batch 700, train_loss 0.690
epoch 28, batch 710, train_loss 0.698
epoch 28, batch 720, train_loss 0.694
epoch 28, batch 730, train_loss 0.690
epoch 28, batch 740, train_loss 0.695
epoch 28, batch 750, train_loss 0.698
epoch 28, batch 760, train_loss 0.688
epoch 28, batch 770, train_loss 0.697
epoch 28, batch 780, train_loss 0.700
epoch 28, batch 790, train_loss 0.705
epoch 28, batch 800, train_loss 0.698
epoch 28, batch 810, train_loss 0.701
epoch 28, batch 820, train_loss 0.702
epoch 28, batch 830, train_loss 0.698
epoch 28, batch 840, train_loss 0.700
epoch 28, batch 850, train_loss 0.694
epoch 28, batch 860, train_loss 0.692
epoch 28, batch 870, train_loss 0.689
epoch 28, batch 880, train_loss 0.693
epoch 28, batch 890, train_loss 0.700
epoch 28, batch 900, train_loss 0.688
epoch 28, batch 910, train_loss 0.698
epoch 28, batch 920, train_loss 0.705
epoch 28, batch 930, train_loss 0.695
epoch 28, batch 940, train_loss 0.700
epoch 28, batch 950, train_loss 0.707
epoch 28, batch 960, train_loss 0.696
epoch 28, batch 970, train_loss 0.700
epoch 28, batch 980, train_loss 0.709
epoch 28, batch 990, train_loss 0.696
epoch 28, batch 1000, train_loss 0.695
epoch 28, batch 1010, train_loss 0.691
epoch 28, batch 1020, train_loss 0.688
epoch 28, batch 1030, train_loss 0.701
epoch 28, batch 1040, train_loss 0.693
epoch 28, batch 1050, train_loss 0.693
epoch 28, batch 1060, train_loss 0.690
epoch 28, batch 1070, train_loss 0.698
epoch 28, batch 1080, train_loss 0.701
epoch 28, batch 1090, train_loss 0.706
epoch 28, batch 1100, train_loss 0.698
epoch 28, batch 1110, train_loss 0.691
epoch 28, batch 1120, train_loss 0.685
epoch 28, batch 1130, train_loss 0.693
epoch 28, batch 1140, train_loss 0.688
epoch 28, batch 1150, train_loss 0.695
epoch 28, batch 1160, train_loss 0.697
epoch 28, batch 1170, train_loss 0.697
epoch 28, batch 1180, train_loss 0.696
epoch 28, batch 1190, train_loss 0.698
epoch    28, train_loss 0.694, valid_loss 0.722, train_accuracy  70.16%, valid_accuracy  68.63%
epoch 29, batch 0, train_loss 0.700
epoch 29, batch 10, train_loss 0.692
epoch 29, batch 20, train_loss 0.697
epoch 29, batch 30, train_loss 0.694
epoch 29, batch 40, train_loss 0.701
epoch 29, batch 50, train_loss 0.698
epoch 29, batch 60, train_loss 0.689
epoch 29, batch 70, train_loss 0.702
epoch 29, batch 80, train_loss 0.696
epoch 29, batch 90, train_loss 0.688
epoch 29, batch 100, train_loss 0.708
epoch 29, batch 110, train_loss 0.700
epoch 29, batch 120, train_loss 0.686
epoch 29, batch 130, train_loss 0.697
epoch 29, batch 140, train_loss 0.695
epoch 29, batch 150, train_loss 0.689
epoch 29, batch 160, train_loss 0.700
epoch 29, batch 170, train_loss 0.699
epoch 29, batch 180, train_loss 0.700
epoch 29, batch 190, train_loss 0.697
epoch 29, batch 200, train_loss 0.694
epoch 29, batch 210, train_loss 0.701
epoch 29, batch 220, train_loss 0.691
epoch 29, batch 230, train_loss 0.699
epoch 29, batch 240, train_loss 0.698
epoch 29, batch 250, train_loss 0.701
epoch 29, batch 260, train_loss 0.699
epoch 29, batch 270, train_loss 0.699
epoch 29, batch 280, train_loss 0.685
epoch 29, batch 290, train_loss 0.697
epoch 29, batch 300, train_loss 0.695
epoch 29, batch 310, train_loss 0.698
epoch 29, batch 320, train_loss 0.687
epoch 29, batch 330, train_loss 0.693
epoch 29, batch 340, train_loss 0.694
epoch 29, batch 350, train_loss 0.692
epoch 29, batch 360, train_loss 0.701
epoch 29, batch 370, train_loss 0.698
epoch 29, batch 380, train_loss 0.703
epoch 29, batch 390, train_loss 0.699
epoch 29, batch 400, train_loss 0.691
epoch 29, batch 410, train_loss 0.701
epoch 29, batch 420, train_loss 0.695
epoch 29, batch 430, train_loss 0.701
epoch 29, batch 440, train_loss 0.697
epoch 29, batch 450, train_loss 0.692
epoch 29, batch 460, train_loss 0.693
epoch 29, batch 470, train_loss 0.697
epoch 29, batch 480, train_loss 0.698
epoch 29, batch 490, train_loss 0.688
epoch 29, batch 500, train_loss 0.700
epoch 29, batch 510, train_loss 0.700
epoch 29, batch 520, train_loss 0.693
epoch 29, batch 530, train_loss 0.700
epoch 29, batch 540, train_loss 0.705
epoch 29, batch 550, train_loss 0.687
epoch 29, batch 560, train_loss 0.691
epoch 29, batch 570, train_loss 0.690
epoch 29, batch 580, train_loss 0.704
epoch 29, batch 590, train_loss 0.704
epoch 29, batch 600, train_loss 0.674
epoch 29, batch 610, train_loss 0.692
epoch 29, batch 620, train_loss 0.689
epoch 29, batch 630, train_loss 0.699
epoch 29, batch 640, train_loss 0.701
epoch 29, batch 650, train_loss 0.702
epoch 29, batch 660, train_loss 0.707
epoch 29, batch 670, train_loss 0.698
epoch 29, batch 680, train_loss 0.684
epoch 29, batch 690, train_loss 0.690
epoch 29, batch 700, train_loss 0.695
epoch 29, batch 710, train_loss 0.698
epoch 29, batch 720, train_loss 0.688
epoch 29, batch 730, train_loss 0.681
epoch 29, batch 740, train_loss 0.697
epoch 29, batch 750, train_loss 0.692
epoch 29, batch 760, train_loss 0.693
epoch 29, batch 770, train_loss 0.696
epoch 29, batch 780, train_loss 0.692
epoch 29, batch 790, train_loss 0.704
epoch 29, batch 800, train_loss 0.693
epoch 29, batch 810, train_loss 0.699
epoch 29, batch 820, train_loss 0.713
epoch 29, batch 830, train_loss 0.699
epoch 29, batch 840, train_loss 0.693
epoch 29, batch 850, train_loss 0.682
epoch 29, batch 860, train_loss 0.695
epoch 29, batch 870, train_loss 0.704
epoch 29, batch 880, train_loss 0.691
epoch 29, batch 890, train_loss 0.692
epoch 29, batch 900, train_loss 0.693
epoch 29, batch 910, train_loss 0.701
epoch 29, batch 920, train_loss 0.693
epoch 29, batch 930, train_loss 0.692
epoch 29, batch 940, train_loss 0.698
epoch 29, batch 950, train_loss 0.694
epoch 29, batch 960, train_loss 0.697
epoch 29, batch 970, train_loss 0.695
epoch 29, batch 980, train_loss 0.700
epoch 29, batch 990, train_loss 0.698
epoch 29, batch 1000, train_loss 0.694
epoch 29, batch 1010, train_loss 0.694
epoch 29, batch 1020, train_loss 0.698
epoch 29, batch 1030, train_loss 0.689
epoch 29, batch 1040, train_loss 0.707
epoch 29, batch 1050, train_loss 0.699
epoch 29, batch 1060, train_loss 0.697
epoch 29, batch 1070, train_loss 0.698
epoch 29, batch 1080, train_loss 0.689
epoch 29, batch 1090, train_loss 0.691
epoch 29, batch 1100, train_loss 0.694
epoch 29, batch 1110, train_loss 0.697
epoch 29, batch 1120, train_loss 0.695
epoch 29, batch 1130, train_loss 0.701
epoch 29, batch 1140, train_loss 0.695
epoch 29, batch 1150, train_loss 0.691
epoch 29, batch 1160, train_loss 0.701
epoch 29, batch 1170, train_loss 0.684
epoch 29, batch 1180, train_loss 0.705
epoch 29, batch 1190, train_loss 0.704
epoch    29, train_loss 0.694, valid_loss 0.722, train_accuracy  70.16%, valid_accuracy  68.57%
epoch 30, batch 0, train_loss 0.704
epoch 30, batch 10, train_loss 0.690
epoch 30, batch 20, train_loss 0.686
epoch 30, batch 30, train_loss 0.697
epoch 30, batch 40, train_loss 0.700
epoch 30, batch 50, train_loss 0.694
epoch 30, batch 60, train_loss 0.694
epoch 30, batch 70, train_loss 0.697
epoch 30, batch 80, train_loss 0.696
epoch 30, batch 90, train_loss 0.690
epoch 30, batch 100, train_loss 0.692
epoch 30, batch 110, train_loss 0.697
epoch 30, batch 120, train_loss 0.685
epoch 30, batch 130, train_loss 0.706
epoch 30, batch 140, train_loss 0.692
epoch 30, batch 150, train_loss 0.702
epoch 30, batch 160, train_loss 0.695
epoch 30, batch 170, train_loss 0.695
epoch 30, batch 180, train_loss 0.699
epoch 30, batch 190, train_loss 0.692
epoch 30, batch 200, train_loss 0.695
epoch 30, batch 210, train_loss 0.694
epoch 30, batch 220, train_loss 0.682
epoch 30, batch 230, train_loss 0.702
epoch 30, batch 240, train_loss 0.693
epoch 30, batch 250, train_loss 0.688
epoch 30, batch 260, train_loss 0.687
epoch 30, batch 270, train_loss 0.695
epoch 30, batch 280, train_loss 0.697
epoch 30, batch 290, train_loss 0.689
epoch 30, batch 300, train_loss 0.697
epoch 30, batch 310, train_loss 0.690
epoch 30, batch 320, train_loss 0.691
epoch 30, batch 330, train_loss 0.693
epoch 30, batch 340, train_loss 0.706
epoch 30, batch 350, train_loss 0.700
epoch 30, batch 360, train_loss 0.696
epoch 30, batch 370, train_loss 0.698
epoch 30, batch 380, train_loss 0.694
epoch 30, batch 390, train_loss 0.695
epoch 30, batch 400, train_loss 0.694
epoch 30, batch 410, train_loss 0.700
epoch 30, batch 420, train_loss 0.697
epoch 30, batch 430, train_loss 0.692
epoch 30, batch 440, train_loss 0.695
epoch 30, batch 450, train_loss 0.694
epoch 30, batch 460, train_loss 0.694
epoch 30, batch 470, train_loss 0.696
epoch 30, batch 480, train_loss 0.693
epoch 30, batch 490, train_loss 0.696
epoch 30, batch 500, train_loss 0.695
epoch 30, batch 510, train_loss 0.706
epoch 30, batch 520, train_loss 0.696
epoch 30, batch 530, train_loss 0.688
epoch 30, batch 540, train_loss 0.695
epoch 30, batch 550, train_loss 0.703
epoch 30, batch 560, train_loss 0.697
epoch 30, batch 570, train_loss 0.699
epoch 30, batch 580, train_loss 0.692
epoch 30, batch 590, train_loss 0.693
epoch 30, batch 600, train_loss 0.687
epoch 30, batch 610, train_loss 0.698
epoch 30, batch 620, train_loss 0.704
epoch 30, batch 630, train_loss 0.695
epoch 30, batch 640, train_loss 0.695
epoch 30, batch 650, train_loss 0.689
epoch 30, batch 660, train_loss 0.682
epoch 30, batch 670, train_loss 0.692
epoch 30, batch 680, train_loss 0.700
epoch 30, batch 690, train_loss 0.698
epoch 30, batch 700, train_loss 0.699
epoch 30, batch 710, train_loss 0.696
epoch 30, batch 720, train_loss 0.695
epoch 30, batch 730, train_loss 0.689
epoch 30, batch 740, train_loss 0.698
epoch 30, batch 750, train_loss 0.696
epoch 30, batch 760, train_loss 0.699
epoch 30, batch 770, train_loss 0.691
epoch 30, batch 780, train_loss 0.695
epoch 30, batch 790, train_loss 0.689
epoch 30, batch 800, train_loss 0.695
epoch 30, batch 810, train_loss 0.695
epoch 30, batch 820, train_loss 0.699
epoch 30, batch 830, train_loss 0.697
epoch 30, batch 840, train_loss 0.701
epoch 30, batch 850, train_loss 0.702
epoch 30, batch 860, train_loss 0.691
epoch 30, batch 870, train_loss 0.688
epoch 30, batch 880, train_loss 0.690
epoch 30, batch 890, train_loss 0.702
epoch 30, batch 900, train_loss 0.692
epoch 30, batch 910, train_loss 0.708
epoch 30, batch 920, train_loss 0.699
epoch 30, batch 930, train_loss 0.695
epoch 30, batch 940, train_loss 0.700
epoch 30, batch 950, train_loss 0.706
epoch 30, batch 960, train_loss 0.694
epoch 30, batch 970, train_loss 0.700
epoch 30, batch 980, train_loss 0.699
epoch 30, batch 990, train_loss 0.682
epoch 30, batch 1000, train_loss 0.699
epoch 30, batch 1010, train_loss 0.689
epoch 30, batch 1020, train_loss 0.690
epoch 30, batch 1030, train_loss 0.682
epoch 30, batch 1040, train_loss 0.691
epoch 30, batch 1050, train_loss 0.685
epoch 30, batch 1060, train_loss 0.700
epoch 30, batch 1070, train_loss 0.699
epoch 30, batch 1080, train_loss 0.696
epoch 30, batch 1090, train_loss 0.687
epoch 30, batch 1100, train_loss 0.685
epoch 30, batch 1110, train_loss 0.690
epoch 30, batch 1120, train_loss 0.700
epoch 30, batch 1130, train_loss 0.691
epoch 30, batch 1140, train_loss 0.681
epoch 30, batch 1150, train_loss 0.685
epoch 30, batch 1160, train_loss 0.695
epoch 30, batch 1170, train_loss 0.689
epoch 30, batch 1180, train_loss 0.698
epoch 30, batch 1190, train_loss 0.697
epoch    30, train_loss 0.694, valid_loss 0.722, train_accuracy  70.16%, valid_accuracy  68.65%
epoch 31, batch 0, train_loss 0.690
epoch 31, batch 10, train_loss 0.691
epoch 31, batch 20, train_loss 0.702
epoch 31, batch 30, train_loss 0.692
epoch 31, batch 40, train_loss 0.695
epoch 31, batch 50, train_loss 0.701
epoch 31, batch 60, train_loss 0.689
epoch 31, batch 70, train_loss 0.700
epoch 31, batch 80, train_loss 0.686
epoch 31, batch 90, train_loss 0.705
epoch 31, batch 100, train_loss 0.692
epoch 31, batch 110, train_loss 0.700
epoch 31, batch 120, train_loss 0.700
epoch 31, batch 130, train_loss 0.694
epoch 31, batch 140, train_loss 0.698
epoch 31, batch 150, train_loss 0.700
epoch 31, batch 160, train_loss 0.696
epoch 31, batch 170, train_loss 0.690
epoch 31, batch 180, train_loss 0.692
epoch 31, batch 190, train_loss 0.696
epoch 31, batch 200, train_loss 0.698
epoch 31, batch 210, train_loss 0.687
epoch 31, batch 220, train_loss 0.693
epoch 31, batch 230, train_loss 0.699
epoch 31, batch 240, train_loss 0.699
epoch 31, batch 250, train_loss 0.693
epoch 31, batch 260, train_loss 0.697
epoch 31, batch 270, train_loss 0.703
epoch 31, batch 280, train_loss 0.693
epoch 31, batch 290, train_loss 0.700
epoch 31, batch 300, train_loss 0.694
epoch 31, batch 310, train_loss 0.700
epoch 31, batch 320, train_loss 0.699
epoch 31, batch 330, train_loss 0.686
epoch 31, batch 340, train_loss 0.694
epoch 31, batch 350, train_loss 0.696
epoch 31, batch 360, train_loss 0.700
epoch 31, batch 370, train_loss 0.698
epoch 31, batch 380, train_loss 0.695
epoch 31, batch 390, train_loss 0.694
epoch 31, batch 400, train_loss 0.703
epoch 31, batch 410, train_loss 0.689
epoch 31, batch 420, train_loss 0.694
epoch 31, batch 430, train_loss 0.708
epoch 31, batch 440, train_loss 0.695
epoch 31, batch 450, train_loss 0.704
epoch 31, batch 460, train_loss 0.696
epoch 31, batch 470, train_loss 0.699
epoch 31, batch 480, train_loss 0.698
epoch 31, batch 490, train_loss 0.698
epoch 31, batch 500, train_loss 0.688
epoch 31, batch 510, train_loss 0.689
epoch 31, batch 520, train_loss 0.696
epoch 31, batch 530, train_loss 0.685
epoch 31, batch 540, train_loss 0.692
epoch 31, batch 550, train_loss 0.696
epoch 31, batch 560, train_loss 0.697
epoch 31, batch 570, train_loss 0.703
epoch 31, batch 580, train_loss 0.684
epoch 31, batch 590, train_loss 0.703
epoch 31, batch 600, train_loss 0.689
epoch 31, batch 610, train_loss 0.696
epoch 31, batch 620, train_loss 0.693
epoch 31, batch 630, train_loss 0.695
epoch 31, batch 640, train_loss 0.695
epoch 31, batch 650, train_loss 0.700
epoch 31, batch 660, train_loss 0.700
epoch 31, batch 670, train_loss 0.693
epoch 31, batch 680, train_loss 0.708
epoch 31, batch 690, train_loss 0.702
epoch 31, batch 700, train_loss 0.697
epoch 31, batch 710, train_loss 0.692
epoch 31, batch 720, train_loss 0.693
epoch 31, batch 730, train_loss 0.690
epoch 31, batch 740, train_loss 0.695
epoch 31, batch 750, train_loss 0.705
epoch 31, batch 760, train_loss 0.698
epoch 31, batch 770, train_loss 0.702
epoch 31, batch 780, train_loss 0.711
epoch 31, batch 790, train_loss 0.699
epoch 31, batch 800, train_loss 0.691
epoch 31, batch 810, train_loss 0.699
epoch 31, batch 820, train_loss 0.698
epoch 31, batch 830, train_loss 0.702
epoch 31, batch 840, train_loss 0.701
epoch 31, batch 850, train_loss 0.703
epoch 31, batch 860, train_loss 0.692
epoch 31, batch 870, train_loss 0.692
epoch 31, batch 880, train_loss 0.697
epoch 31, batch 890, train_loss 0.694
epoch 31, batch 900, train_loss 0.694
epoch 31, batch 910, train_loss 0.693
epoch 31, batch 920, train_loss 0.692
epoch 31, batch 930, train_loss 0.679
epoch 31, batch 940, train_loss 0.694
epoch 31, batch 950, train_loss 0.693
epoch 31, batch 960, train_loss 0.689
epoch 31, batch 970, train_loss 0.695
epoch 31, batch 980, train_loss 0.699
epoch 31, batch 990, train_loss 0.696
epoch 31, batch 1000, train_loss 0.693
epoch 31, batch 1010, train_loss 0.694
epoch 31, batch 1020, train_loss 0.692
epoch 31, batch 1030, train_loss 0.696
epoch 31, batch 1040, train_loss 0.696
epoch 31, batch 1050, train_loss 0.695
epoch 31, batch 1060, train_loss 0.699
epoch 31, batch 1070, train_loss 0.688
epoch 31, batch 1080, train_loss 0.696
epoch 31, batch 1090, train_loss 0.700
epoch 31, batch 1100, train_loss 0.706
epoch 31, batch 1110, train_loss 0.697
epoch 31, batch 1120, train_loss 0.686
epoch 31, batch 1130, train_loss 0.695
epoch 31, batch 1140, train_loss 0.693
epoch 31, batch 1150, train_loss 0.698
epoch 31, batch 1160, train_loss 0.693
epoch 31, batch 1170, train_loss 0.689
epoch 31, batch 1180, train_loss 0.697
epoch 31, batch 1190, train_loss 0.697
epoch    31, train_loss 0.696, valid_loss 0.723, train_accuracy  70.09%, valid_accuracy  68.57%
epoch 32, batch 0, train_loss 0.693
epoch 32, batch 10, train_loss 0.698
epoch 32, batch 20, train_loss 0.699
epoch 32, batch 30, train_loss 0.703
epoch 32, batch 40, train_loss 0.700
epoch 32, batch 50, train_loss 0.704
epoch 32, batch 60, train_loss 0.698
epoch 32, batch 70, train_loss 0.693
epoch 32, batch 80, train_loss 0.695
epoch 32, batch 90, train_loss 0.699
epoch 32, batch 100, train_loss 0.693
epoch 32, batch 110, train_loss 0.692
epoch 32, batch 120, train_loss 0.691
epoch 32, batch 130, train_loss 0.695
epoch 32, batch 140, train_loss 0.692
epoch 32, batch 150, train_loss 0.689
epoch 32, batch 160, train_loss 0.696
epoch 32, batch 170, train_loss 0.690
epoch 32, batch 180, train_loss 0.698
epoch 32, batch 190, train_loss 0.689
epoch 32, batch 200, train_loss 0.694
epoch 32, batch 210, train_loss 0.696
epoch 32, batch 220, train_loss 0.688
epoch 32, batch 230, train_loss 0.703
epoch 32, batch 240, train_loss 0.695
epoch 32, batch 250, train_loss 0.691
epoch 32, batch 260, train_loss 0.699
epoch 32, batch 270, train_loss 0.693
epoch 32, batch 280, train_loss 0.685
epoch 32, batch 290, train_loss 0.692
epoch 32, batch 300, train_loss 0.702
epoch 32, batch 310, train_loss 0.690
epoch 32, batch 320, train_loss 0.704
epoch 32, batch 330, train_loss 0.689
epoch 32, batch 340, train_loss 0.700
epoch 32, batch 350, train_loss 0.710
epoch 32, batch 360, train_loss 0.701
epoch 32, batch 370, train_loss 0.705
epoch 32, batch 380, train_loss 0.693
epoch 32, batch 390, train_loss 0.695
epoch 32, batch 400, train_loss 0.695
epoch 32, batch 410, train_loss 0.699
epoch 32, batch 420, train_loss 0.694
epoch 32, batch 430, train_loss 0.696
epoch 32, batch 440, train_loss 0.699
epoch 32, batch 450, train_loss 0.702
epoch 32, batch 460, train_loss 0.689
epoch 32, batch 470, train_loss 0.693
epoch 32, batch 480, train_loss 0.697
epoch 32, batch 490, train_loss 0.690
epoch 32, batch 500, train_loss 0.705
epoch 32, batch 510, train_loss 0.702
epoch 32, batch 520, train_loss 0.700
epoch 32, batch 530, train_loss 0.687
epoch 32, batch 540, train_loss 0.696
epoch 32, batch 550, train_loss 0.700
epoch 32, batch 560, train_loss 0.693
epoch 32, batch 570, train_loss 0.699
epoch 32, batch 580, train_loss 0.695
epoch 32, batch 590, train_loss 0.696
epoch 32, batch 600, train_loss 0.703
epoch 32, batch 610, train_loss 0.698
epoch 32, batch 620, train_loss 0.693
epoch 32, batch 630, train_loss 0.694
epoch 32, batch 640, train_loss 0.695
epoch 32, batch 650, train_loss 0.695
epoch 32, batch 660, train_loss 0.695
epoch 32, batch 670, train_loss 0.695
epoch 32, batch 680, train_loss 0.691
epoch 32, batch 690, train_loss 0.696
epoch 32, batch 700, train_loss 0.692
epoch 32, batch 710, train_loss 0.687
epoch 32, batch 720, train_loss 0.689
epoch 32, batch 730, train_loss 0.696
epoch 32, batch 740, train_loss 0.706
epoch 32, batch 750, train_loss 0.693
epoch 32, batch 760, train_loss 0.695
epoch 32, batch 770, train_loss 0.696
epoch 32, batch 780, train_loss 0.692
epoch 32, batch 790, train_loss 0.701
epoch 32, batch 800, train_loss 0.699
epoch 32, batch 810, train_loss 0.690
epoch 32, batch 820, train_loss 0.701
epoch 32, batch 830, train_loss 0.698
epoch 32, batch 840, train_loss 0.695
epoch 32, batch 850, train_loss 0.694
epoch 32, batch 860, train_loss 0.690
epoch 32, batch 870, train_loss 0.699
epoch 32, batch 880, train_loss 0.696
epoch 32, batch 890, train_loss 0.691
epoch 32, batch 900, train_loss 0.693
epoch 32, batch 910, train_loss 0.690
epoch 32, batch 920, train_loss 0.694
epoch 32, batch 930, train_loss 0.692
epoch 32, batch 940, train_loss 0.693
epoch 32, batch 950, train_loss 0.694
epoch 32, batch 960, train_loss 0.696
epoch 32, batch 970, train_loss 0.700
epoch 32, batch 980, train_loss 0.693
epoch 32, batch 990, train_loss 0.701
epoch 32, batch 1000, train_loss 0.702
epoch 32, batch 1010, train_loss 0.691
epoch 32, batch 1020, train_loss 0.693
epoch 32, batch 1030, train_loss 0.689
epoch 32, batch 1040, train_loss 0.690
epoch 32, batch 1050, train_loss 0.695
epoch 32, batch 1060, train_loss 0.695
epoch 32, batch 1070, train_loss 0.698
epoch 32, batch 1080, train_loss 0.702
epoch 32, batch 1090, train_loss 0.689
epoch 32, batch 1100, train_loss 0.696
epoch 32, batch 1110, train_loss 0.704
epoch 32, batch 1120, train_loss 0.704
epoch 32, batch 1130, train_loss 0.691
epoch 32, batch 1140, train_loss 0.697
epoch 32, batch 1150, train_loss 0.694
epoch 32, batch 1160, train_loss 0.693
epoch 32, batch 1170, train_loss 0.702
epoch 32, batch 1180, train_loss 0.686
epoch 32, batch 1190, train_loss 0.699
epoch    32, train_loss 0.694, valid_loss 0.722, train_accuracy  70.17%, valid_accuracy  68.58%
epoch 33, batch 0, train_loss 0.691
epoch 33, batch 10, train_loss 0.697
epoch 33, batch 20, train_loss 0.695
epoch 33, batch 30, train_loss 0.699
epoch 33, batch 40, train_loss 0.684
epoch 33, batch 50, train_loss 0.695
epoch 33, batch 60, train_loss 0.695
epoch 33, batch 70, train_loss 0.692
epoch 33, batch 80, train_loss 0.695
epoch 33, batch 90, train_loss 0.697
epoch 33, batch 100, train_loss 0.694
epoch 33, batch 110, train_loss 0.690
epoch 33, batch 120, train_loss 0.694
epoch 33, batch 130, train_loss 0.690
epoch 33, batch 140, train_loss 0.689
epoch 33, batch 150, train_loss 0.695
epoch 33, batch 160, train_loss 0.692
epoch 33, batch 170, train_loss 0.705
epoch 33, batch 180, train_loss 0.694
epoch 33, batch 190, train_loss 0.695
epoch 33, batch 200, train_loss 0.694
epoch 33, batch 210, train_loss 0.697
epoch 33, batch 220, train_loss 0.696
epoch 33, batch 230, train_loss 0.683
epoch 33, batch 240, train_loss 0.689
epoch 33, batch 250, train_loss 0.704
epoch 33, batch 260, train_loss 0.690
epoch 33, batch 270, train_loss 0.691
epoch 33, batch 280, train_loss 0.701
epoch 33, batch 290, train_loss 0.700
epoch 33, batch 300, train_loss 0.691
epoch 33, batch 310, train_loss 0.691
epoch 33, batch 320, train_loss 0.685
epoch 33, batch 330, train_loss 0.695
epoch 33, batch 340, train_loss 0.688
epoch 33, batch 350, train_loss 0.699
epoch 33, batch 360, train_loss 0.696
epoch 33, batch 370, train_loss 0.703
epoch 33, batch 380, train_loss 0.692
epoch 33, batch 390, train_loss 0.691
epoch 33, batch 400, train_loss 0.694
epoch 33, batch 410, train_loss 0.703
epoch 33, batch 420, train_loss 0.699
epoch 33, batch 430, train_loss 0.697
epoch 33, batch 440, train_loss 0.685
epoch 33, batch 450, train_loss 0.693
epoch 33, batch 460, train_loss 0.694
epoch 33, batch 470, train_loss 0.701
epoch 33, batch 480, train_loss 0.685
epoch 33, batch 490, train_loss 0.689
epoch 33, batch 500, train_loss 0.692
epoch 33, batch 510, train_loss 0.685
epoch 33, batch 520, train_loss 0.697
epoch 33, batch 530, train_loss 0.693
epoch 33, batch 540, train_loss 0.692
epoch 33, batch 550, train_loss 0.698
epoch 33, batch 560, train_loss 0.698
epoch 33, batch 570, train_loss 0.694
epoch 33, batch 580, train_loss 0.694
epoch 33, batch 590, train_loss 0.701
epoch 33, batch 600, train_loss 0.697
epoch 33, batch 610, train_loss 0.695
epoch 33, batch 620, train_loss 0.700
epoch 33, batch 630, train_loss 0.693
epoch 33, batch 640, train_loss 0.702
epoch 33, batch 650, train_loss 0.695
epoch 33, batch 660, train_loss 0.699
epoch 33, batch 670, train_loss 0.693
epoch 33, batch 680, train_loss 0.692
epoch 33, batch 690, train_loss 0.692
epoch 33, batch 700, train_loss 0.695
epoch 33, batch 710, train_loss 0.701
epoch 33, batch 720, train_loss 0.694
epoch 33, batch 730, train_loss 0.696
epoch 33, batch 740, train_loss 0.698
epoch 33, batch 750, train_loss 0.686
epoch 33, batch 760, train_loss 0.694
epoch 33, batch 770, train_loss 0.692
epoch 33, batch 780, train_loss 0.699
epoch 33, batch 790, train_loss 0.695
epoch 33, batch 800, train_loss 0.704
epoch 33, batch 810, train_loss 0.689
epoch 33, batch 820, train_loss 0.694
epoch 33, batch 830, train_loss 0.696
epoch 33, batch 840, train_loss 0.691
epoch 33, batch 850, train_loss 0.699
epoch 33, batch 860, train_loss 0.693
epoch 33, batch 870, train_loss 0.704
epoch 33, batch 880, train_loss 0.692
epoch 33, batch 890, train_loss 0.692
epoch 33, batch 900, train_loss 0.690
epoch 33, batch 910, train_loss 0.694
epoch 33, batch 920, train_loss 0.693
epoch 33, batch 930, train_loss 0.696
epoch 33, batch 940, train_loss 0.702
epoch 33, batch 950, train_loss 0.695
epoch 33, batch 960, train_loss 0.692
epoch 33, batch 970, train_loss 0.685
epoch 33, batch 980, train_loss 0.695
epoch 33, batch 990, train_loss 0.695
epoch 33, batch 1000, train_loss 0.691
epoch 33, batch 1010, train_loss 0.701
epoch 33, batch 1020, train_loss 0.689
epoch 33, batch 1030, train_loss 0.703
epoch 33, batch 1040, train_loss 0.686
epoch 33, batch 1050, train_loss 0.709
epoch 33, batch 1060, train_loss 0.693
epoch 33, batch 1070, train_loss 0.696
epoch 33, batch 1080, train_loss 0.697
epoch 33, batch 1090, train_loss 0.698
epoch 33, batch 1100, train_loss 0.687
epoch 33, batch 1110, train_loss 0.686
epoch 33, batch 1120, train_loss 0.698
epoch 33, batch 1130, train_loss 0.698
epoch 33, batch 1140, train_loss 0.699
epoch 33, batch 1150, train_loss 0.698
epoch 33, batch 1160, train_loss 0.684
epoch 33, batch 1170, train_loss 0.696
epoch 33, batch 1180, train_loss 0.691
epoch 33, batch 1190, train_loss 0.704
epoch    33, train_loss 0.693, valid_loss 0.722, train_accuracy  70.19%, valid_accuracy  68.57%
epoch 34, batch 0, train_loss 0.696
epoch 34, batch 10, train_loss 0.701
epoch 34, batch 20, train_loss 0.687
epoch 34, batch 30, train_loss 0.699
epoch 34, batch 40, train_loss 0.701
epoch 34, batch 50, train_loss 0.689
epoch 34, batch 60, train_loss 0.691
epoch 34, batch 70, train_loss 0.693
epoch 34, batch 80, train_loss 0.693
epoch 34, batch 90, train_loss 0.699
epoch 34, batch 100, train_loss 0.694
epoch 34, batch 110, train_loss 0.696
epoch 34, batch 120, train_loss 0.693
epoch 34, batch 130, train_loss 0.686
epoch 34, batch 140, train_loss 0.696
epoch 34, batch 150, train_loss 0.694
epoch 34, batch 160, train_loss 0.697
epoch 34, batch 170, train_loss 0.692
epoch 34, batch 180, train_loss 0.696
epoch 34, batch 190, train_loss 0.688
epoch 34, batch 200, train_loss 0.707
epoch 34, batch 210, train_loss 0.689
epoch 34, batch 220, train_loss 0.688
epoch 34, batch 230, train_loss 0.698
epoch 34, batch 240, train_loss 0.692
epoch 34, batch 250, train_loss 0.697
epoch 34, batch 260, train_loss 0.687
epoch 34, batch 270, train_loss 0.696
epoch 34, batch 280, train_loss 0.694
epoch 34, batch 290, train_loss 0.696
epoch 34, batch 300, train_loss 0.691
epoch 34, batch 310, train_loss 0.689
epoch 34, batch 320, train_loss 0.701
epoch 34, batch 330, train_loss 0.695
epoch 34, batch 340, train_loss 0.703
epoch 34, batch 350, train_loss 0.702
epoch 34, batch 360, train_loss 0.699
epoch 34, batch 370, train_loss 0.697
epoch 34, batch 380, train_loss 0.695
epoch 34, batch 390, train_loss 0.694
epoch 34, batch 400, train_loss 0.692
epoch 34, batch 410, train_loss 0.697
epoch 34, batch 420, train_loss 0.700
epoch 34, batch 430, train_loss 0.689
epoch 34, batch 440, train_loss 0.697
epoch 34, batch 450, train_loss 0.687
epoch 34, batch 460, train_loss 0.696
epoch 34, batch 470, train_loss 0.699
epoch 34, batch 480, train_loss 0.693
epoch 34, batch 490, train_loss 0.687
epoch 34, batch 500, train_loss 0.690
epoch 34, batch 510, train_loss 0.696
epoch 34, batch 520, train_loss 0.687
epoch 34, batch 530, train_loss 0.689
epoch 34, batch 540, train_loss 0.687
epoch 34, batch 550, train_loss 0.700
epoch 34, batch 560, train_loss 0.697
epoch 34, batch 570, train_loss 0.693
epoch 34, batch 580, train_loss 0.697
epoch 34, batch 590, train_loss 0.686
epoch 34, batch 600, train_loss 0.694
epoch 34, batch 610, train_loss 0.693
epoch 34, batch 620, train_loss 0.708
epoch 34, batch 630, train_loss 0.699
epoch 34, batch 640, train_loss 0.696
epoch 34, batch 650, train_loss 0.702
epoch 34, batch 660, train_loss 0.699
epoch 34, batch 670, train_loss 0.689
epoch 34, batch 680, train_loss 0.708
epoch 34, batch 690, train_loss 0.698
epoch 34, batch 700, train_loss 0.691
epoch 34, batch 710, train_loss 0.698
epoch 34, batch 720, train_loss 0.700
epoch 34, batch 730, train_loss 0.689
epoch 34, batch 740, train_loss 0.696
epoch 34, batch 750, train_loss 0.683
epoch 34, batch 760, train_loss 0.688
epoch 34, batch 770, train_loss 0.696
epoch 34, batch 780, train_loss 0.703
epoch 34, batch 790, train_loss 0.702
epoch 34, batch 800, train_loss 0.689
epoch 34, batch 810, train_loss 0.690
epoch 34, batch 820, train_loss 0.701
epoch 34, batch 830, train_loss 0.691
epoch 34, batch 840, train_loss 0.695
epoch 34, batch 850, train_loss 0.701
epoch 34, batch 860, train_loss 0.680
epoch 34, batch 870, train_loss 0.696
epoch 34, batch 880, train_loss 0.698
epoch 34, batch 890, train_loss 0.702
epoch 34, batch 900, train_loss 0.697
epoch 34, batch 910, train_loss 0.701
epoch 34, batch 920, train_loss 0.702
epoch 34, batch 930, train_loss 0.683
epoch 34, batch 940, train_loss 0.691
epoch 34, batch 950, train_loss 0.689
epoch 34, batch 960, train_loss 0.692
epoch 34, batch 970, train_loss 0.694
epoch 34, batch 980, train_loss 0.693
epoch 34, batch 990, train_loss 0.693
epoch 34, batch 1000, train_loss 0.694
epoch 34, batch 1010, train_loss 0.693
epoch 34, batch 1020, train_loss 0.699
epoch 34, batch 1030, train_loss 0.698
epoch 34, batch 1040, train_loss 0.688
epoch 34, batch 1050, train_loss 0.692
epoch 34, batch 1060, train_loss 0.708
epoch 34, batch 1070, train_loss 0.702
epoch 34, batch 1080, train_loss 0.688
epoch 34, batch 1090, train_loss 0.691
epoch 34, batch 1100, train_loss 0.693
epoch 34, batch 1110, train_loss 0.701
epoch 34, batch 1120, train_loss 0.691
epoch 34, batch 1130, train_loss 0.686
epoch 34, batch 1140, train_loss 0.700
epoch 34, batch 1150, train_loss 0.700
epoch 34, batch 1160, train_loss 0.700
epoch 34, batch 1170, train_loss 0.711
epoch 34, batch 1180, train_loss 0.697
epoch 34, batch 1190, train_loss 0.697
epoch    34, train_loss 0.694, valid_loss 0.723, train_accuracy  70.13%, valid_accuracy  68.54%
epoch 35, batch 0, train_loss 0.707
epoch 35, batch 10, train_loss 0.684
epoch 35, batch 20, train_loss 0.701
epoch 35, batch 30, train_loss 0.691
epoch 35, batch 40, train_loss 0.700
epoch 35, batch 50, train_loss 0.688
epoch 35, batch 60, train_loss 0.697
epoch 35, batch 70, train_loss 0.691
epoch 35, batch 80, train_loss 0.691
epoch 35, batch 90, train_loss 0.702
epoch 35, batch 100, train_loss 0.691
epoch 35, batch 110, train_loss 0.697
epoch 35, batch 120, train_loss 0.707
epoch 35, batch 130, train_loss 0.689
epoch 35, batch 140, train_loss 0.691
epoch 35, batch 150, train_loss 0.686
epoch 35, batch 160, train_loss 0.692
epoch 35, batch 170, train_loss 0.696
epoch 35, batch 180, train_loss 0.693
epoch 35, batch 190, train_loss 0.695
epoch 35, batch 200, train_loss 0.686
epoch 35, batch 210, train_loss 0.692
epoch 35, batch 220, train_loss 0.699
epoch 35, batch 230, train_loss 0.689
epoch 35, batch 240, train_loss 0.694
epoch 35, batch 250, train_loss 0.709
epoch 35, batch 260, train_loss 0.695
epoch 35, batch 270, train_loss 0.693
epoch 35, batch 280, train_loss 0.695
epoch 35, batch 290, train_loss 0.689
epoch 35, batch 300, train_loss 0.701
epoch 35, batch 310, train_loss 0.691
epoch 35, batch 320, train_loss 0.689
epoch 35, batch 330, train_loss 0.688
epoch 35, batch 340, train_loss 0.703
epoch 35, batch 350, train_loss 0.706
epoch 35, batch 360, train_loss 0.697
epoch 35, batch 370, train_loss 0.694
epoch 35, batch 380, train_loss 0.685
epoch 35, batch 390, train_loss 0.699
epoch 35, batch 400, train_loss 0.692
epoch 35, batch 410, train_loss 0.696
epoch 35, batch 420, train_loss 0.691
epoch 35, batch 430, train_loss 0.691
epoch 35, batch 440, train_loss 0.692
epoch 35, batch 450, train_loss 0.687
epoch 35, batch 460, train_loss 0.690
epoch 35, batch 470, train_loss 0.693
epoch 35, batch 480, train_loss 0.693
epoch 35, batch 490, train_loss 0.687
epoch 35, batch 500, train_loss 0.700
epoch 35, batch 510, train_loss 0.691
epoch 35, batch 520, train_loss 0.697
epoch 35, batch 530, train_loss 0.692
epoch 35, batch 540, train_loss 0.690
epoch 35, batch 550, train_loss 0.702
epoch 35, batch 560, train_loss 0.694
epoch 35, batch 570, train_loss 0.689
epoch 35, batch 580, train_loss 0.695
epoch 35, batch 590, train_loss 0.705
epoch 35, batch 600, train_loss 0.691
epoch 35, batch 610, train_loss 0.692
epoch 35, batch 620, train_loss 0.697
epoch 35, batch 630, train_loss 0.687
epoch 35, batch 640, train_loss 0.697
epoch 35, batch 650, train_loss 0.696
epoch 35, batch 660, train_loss 0.694
epoch 35, batch 670, train_loss 0.689
epoch 35, batch 680, train_loss 0.695
epoch 35, batch 690, train_loss 0.690
epoch 35, batch 700, train_loss 0.710
epoch 35, batch 710, train_loss 0.696
epoch 35, batch 720, train_loss 0.689
epoch 35, batch 730, train_loss 0.686
epoch 35, batch 740, train_loss 0.686
epoch 35, batch 750, train_loss 0.694
epoch 35, batch 760, train_loss 0.694
epoch 35, batch 770, train_loss 0.690
epoch 35, batch 780, train_loss 0.706
epoch 35, batch 790, train_loss 0.699
epoch 35, batch 800, train_loss 0.686
epoch 35, batch 810, train_loss 0.703
epoch 35, batch 820, train_loss 0.702
epoch 35, batch 830, train_loss 0.691
epoch 35, batch 840, train_loss 0.692
epoch 35, batch 850, train_loss 0.704
epoch 35, batch 860, train_loss 0.703
epoch 35, batch 870, train_loss 0.696
epoch 35, batch 880, train_loss 0.696
epoch 35, batch 890, train_loss 0.705
epoch 35, batch 900, train_loss 0.699
epoch 35, batch 910, train_loss 0.701
epoch 35, batch 920, train_loss 0.695
epoch 35, batch 930, train_loss 0.685
epoch 35, batch 940, train_loss 0.708
epoch 35, batch 950, train_loss 0.702
epoch 35, batch 960, train_loss 0.688
epoch 35, batch 970, train_loss 0.693
epoch 35, batch 980, train_loss 0.699
epoch 35, batch 990, train_loss 0.691
epoch 35, batch 1000, train_loss 0.687
epoch 35, batch 1010, train_loss 0.700
epoch 35, batch 1020, train_loss 0.700
epoch 35, batch 1030, train_loss 0.691
epoch 35, batch 1040, train_loss 0.693
epoch 35, batch 1050, train_loss 0.698
epoch 35, batch 1060, train_loss 0.683
epoch 35, batch 1070, train_loss 0.701
epoch 35, batch 1080, train_loss 0.680
epoch 35, batch 1090, train_loss 0.699
epoch 35, batch 1100, train_loss 0.690
epoch 35, batch 1110, train_loss 0.705
epoch 35, batch 1120, train_loss 0.696
epoch 35, batch 1130, train_loss 0.688
epoch 35, batch 1140, train_loss 0.695
epoch 35, batch 1150, train_loss 0.698
epoch 35, batch 1160, train_loss 0.696
epoch 35, batch 1170, train_loss 0.695
epoch 35, batch 1180, train_loss 0.700
epoch 35, batch 1190, train_loss 0.708
epoch    35, train_loss 0.694, valid_loss 0.723, train_accuracy  70.20%, valid_accuracy  68.60%
epoch 36, batch 0, train_loss 0.686
epoch 36, batch 10, train_loss 0.695
epoch 36, batch 20, train_loss 0.692
epoch 36, batch 30, train_loss 0.686
epoch 36, batch 40, train_loss 0.688
epoch 36, batch 50, train_loss 0.698
epoch 36, batch 60, train_loss 0.691
epoch 36, batch 70, train_loss 0.696
epoch 36, batch 80, train_loss 0.690
epoch 36, batch 90, train_loss 0.690
epoch 36, batch 100, train_loss 0.698
epoch 36, batch 110, train_loss 0.689
epoch 36, batch 120, train_loss 0.705
epoch 36, batch 130, train_loss 0.702
epoch 36, batch 140, train_loss 0.700
epoch 36, batch 150, train_loss 0.693
epoch 36, batch 160, train_loss 0.690
epoch 36, batch 170, train_loss 0.691
epoch 36, batch 180, train_loss 0.694
epoch 36, batch 190, train_loss 0.689
epoch 36, batch 200, train_loss 0.697
epoch 36, batch 210, train_loss 0.695
epoch 36, batch 220, train_loss 0.692
epoch 36, batch 230, train_loss 0.694
epoch 36, batch 240, train_loss 0.693
epoch 36, batch 250, train_loss 0.702
epoch 36, batch 260, train_loss 0.689
epoch 36, batch 270, train_loss 0.695
epoch 36, batch 280, train_loss 0.691
epoch 36, batch 290, train_loss 0.691
epoch 36, batch 300, train_loss 0.704
epoch 36, batch 310, train_loss 0.698
epoch 36, batch 320, train_loss 0.692
epoch 36, batch 330, train_loss 0.696
epoch 36, batch 340, train_loss 0.693
epoch 36, batch 350, train_loss 0.685
epoch 36, batch 360, train_loss 0.698
epoch 36, batch 370, train_loss 0.693
epoch 36, batch 380, train_loss 0.699
epoch 36, batch 390, train_loss 0.686
epoch 36, batch 400, train_loss 0.704
epoch 36, batch 410, train_loss 0.696
epoch 36, batch 420, train_loss 0.696
epoch 36, batch 430, train_loss 0.699
epoch 36, batch 440, train_loss 0.700
epoch 36, batch 450, train_loss 0.688
epoch 36, batch 460, train_loss 0.692
epoch 36, batch 470, train_loss 0.697
epoch 36, batch 480, train_loss 0.694
epoch 36, batch 490, train_loss 0.688
epoch 36, batch 500, train_loss 0.693
epoch 36, batch 510, train_loss 0.704
epoch 36, batch 520, train_loss 0.698
epoch 36, batch 530, train_loss 0.701
epoch 36, batch 540, train_loss 0.682
epoch 36, batch 550, train_loss 0.697
epoch 36, batch 560, train_loss 0.695
epoch 36, batch 570, train_loss 0.691
epoch 36, batch 580, train_loss 0.686
epoch 36, batch 590, train_loss 0.700
epoch 36, batch 600, train_loss 0.696
epoch 36, batch 610, train_loss 0.692
epoch 36, batch 620, train_loss 0.688
epoch 36, batch 630, train_loss 0.700
epoch 36, batch 640, train_loss 0.694
epoch 36, batch 650, train_loss 0.702
epoch 36, batch 660, train_loss 0.706
epoch 36, batch 670, train_loss 0.692
epoch 36, batch 680, train_loss 0.698
epoch 36, batch 690, train_loss 0.694
epoch 36, batch 700, train_loss 0.690
epoch 36, batch 710, train_loss 0.692
epoch 36, batch 720, train_loss 0.694
epoch 36, batch 730, train_loss 0.691
epoch 36, batch 740, train_loss 0.696
epoch 36, batch 750, train_loss 0.683
epoch 36, batch 760, train_loss 0.702
epoch 36, batch 770, train_loss 0.697
epoch 36, batch 780, train_loss 0.688
epoch 36, batch 790, train_loss 0.694
epoch 36, batch 800, train_loss 0.695
epoch 36, batch 810, train_loss 0.695
epoch 36, batch 820, train_loss 0.696
epoch 36, batch 830, train_loss 0.696
epoch 36, batch 840, train_loss 0.681
epoch 36, batch 850, train_loss 0.698
epoch 36, batch 860, train_loss 0.702
epoch 36, batch 870, train_loss 0.685
epoch 36, batch 880, train_loss 0.689
epoch 36, batch 890, train_loss 0.690
epoch 36, batch 900, train_loss 0.700
epoch 36, batch 910, train_loss 0.698
epoch 36, batch 920, train_loss 0.695
epoch 36, batch 930, train_loss 0.692
epoch 36, batch 940, train_loss 0.692
epoch 36, batch 950, train_loss 0.699
epoch 36, batch 960, train_loss 0.696
epoch 36, batch 970, train_loss 0.701
epoch 36, batch 980, train_loss 0.702
epoch 36, batch 990, train_loss 0.686
epoch 36, batch 1000, train_loss 0.692
epoch 36, batch 1010, train_loss 0.689
epoch 36, batch 1020, train_loss 0.682
epoch 36, batch 1030, train_loss 0.703
epoch 36, batch 1040, train_loss 0.698
epoch 36, batch 1050, train_loss 0.707
epoch 36, batch 1060, train_loss 0.700
epoch 36, batch 1070, train_loss 0.699
epoch 36, batch 1080, train_loss 0.692
epoch 36, batch 1090, train_loss 0.693
epoch 36, batch 1100, train_loss 0.695
epoch 36, batch 1110, train_loss 0.694
epoch 36, batch 1120, train_loss 0.698
epoch 36, batch 1130, train_loss 0.692
epoch 36, batch 1140, train_loss 0.687
epoch 36, batch 1150, train_loss 0.699
epoch 36, batch 1160, train_loss 0.694
epoch 36, batch 1170, train_loss 0.693
epoch 36, batch 1180, train_loss 0.699
epoch 36, batch 1190, train_loss 0.699
epoch    36, train_loss 0.693, valid_loss 0.722, train_accuracy  70.21%, valid_accuracy  68.61%
epoch 37, batch 0, train_loss 0.695
epoch 37, batch 10, train_loss 0.697
epoch 37, batch 20, train_loss 0.690
epoch 37, batch 30, train_loss 0.695
epoch 37, batch 40, train_loss 0.691
epoch 37, batch 50, train_loss 0.695
epoch 37, batch 60, train_loss 0.691
epoch 37, batch 70, train_loss 0.689
epoch 37, batch 80, train_loss 0.685
epoch 37, batch 90, train_loss 0.697
epoch 37, batch 100, train_loss 0.709
epoch 37, batch 110, train_loss 0.682
epoch 37, batch 120, train_loss 0.682
epoch 37, batch 130, train_loss 0.687
epoch 37, batch 140, train_loss 0.692
epoch 37, batch 150, train_loss 0.703
epoch 37, batch 160, train_loss 0.694
epoch 37, batch 170, train_loss 0.697
epoch 37, batch 180, train_loss 0.693
epoch 37, batch 190, train_loss 0.697
epoch 37, batch 200, train_loss 0.700
epoch 37, batch 210, train_loss 0.694
epoch 37, batch 220, train_loss 0.696
epoch 37, batch 230, train_loss 0.697
epoch 37, batch 240, train_loss 0.692
epoch 37, batch 250, train_loss 0.701
epoch 37, batch 260, train_loss 0.691
epoch 37, batch 270, train_loss 0.693
epoch 37, batch 280, train_loss 0.695
epoch 37, batch 290, train_loss 0.705
epoch 37, batch 300, train_loss 0.686
epoch 37, batch 310, train_loss 0.683
epoch 37, batch 320, train_loss 0.691
epoch 37, batch 330, train_loss 0.692
epoch 37, batch 340, train_loss 0.697
epoch 37, batch 350, train_loss 0.681
epoch 37, batch 360, train_loss 0.694
epoch 37, batch 370, train_loss 0.695
epoch 37, batch 380, train_loss 0.698
epoch 37, batch 390, train_loss 0.697
epoch 37, batch 400, train_loss 0.703
epoch 37, batch 410, train_loss 0.701
epoch 37, batch 420, train_loss 0.705
epoch 37, batch 430, train_loss 0.685
epoch 37, batch 440, train_loss 0.694
epoch 37, batch 450, train_loss 0.693
epoch 37, batch 460, train_loss 0.684
epoch 37, batch 470, train_loss 0.698
epoch 37, batch 480, train_loss 0.701
epoch 37, batch 490, train_loss 0.701
epoch 37, batch 500, train_loss 0.692
epoch 37, batch 510, train_loss 0.703
epoch 37, batch 520, train_loss 0.695
epoch 37, batch 530, train_loss 0.691
epoch 37, batch 540, train_loss 0.684
epoch 37, batch 550, train_loss 0.702
epoch 37, batch 560, train_loss 0.694
epoch 37, batch 570, train_loss 0.686
epoch 37, batch 580, train_loss 0.696
epoch 37, batch 590, train_loss 0.697
epoch 37, batch 600, train_loss 0.698
epoch 37, batch 610, train_loss 0.699
epoch 37, batch 620, train_loss 0.689
epoch 37, batch 630, train_loss 0.704
epoch 37, batch 640, train_loss 0.702
epoch 37, batch 650, train_loss 0.688
epoch 37, batch 660, train_loss 0.693
epoch 37, batch 670, train_loss 0.689
epoch 37, batch 680, train_loss 0.692
epoch 37, batch 690, train_loss 0.694
epoch 37, batch 700, train_loss 0.693
epoch 37, batch 710, train_loss 0.697
epoch 37, batch 720, train_loss 0.687
epoch 37, batch 730, train_loss 0.690
epoch 37, batch 740, train_loss 0.696
epoch 37, batch 750, train_loss 0.702
epoch 37, batch 760, train_loss 0.694
epoch 37, batch 770, train_loss 0.686
epoch 37, batch 780, train_loss 0.695
epoch 37, batch 790, train_loss 0.697
epoch 37, batch 800, train_loss 0.694
epoch 37, batch 810, train_loss 0.698
epoch 37, batch 820, train_loss 0.690
epoch 37, batch 830, train_loss 0.690
epoch 37, batch 840, train_loss 0.683
epoch 37, batch 850, train_loss 0.687
epoch 37, batch 860, train_loss 0.696
epoch 37, batch 870, train_loss 0.686
epoch 37, batch 880, train_loss 0.693
epoch 37, batch 890, train_loss 0.684
epoch 37, batch 900, train_loss 0.692
epoch 37, batch 910, train_loss 0.698
epoch 37, batch 920, train_loss 0.700
epoch 37, batch 930, train_loss 0.706
epoch 37, batch 940, train_loss 0.703
epoch 37, batch 950, train_loss 0.704
epoch 37, batch 960, train_loss 0.693
epoch 37, batch 970, train_loss 0.697
epoch 37, batch 980, train_loss 0.695
epoch 37, batch 990, train_loss 0.698
epoch 37, batch 1000, train_loss 0.688
epoch 37, batch 1010, train_loss 0.705
epoch 37, batch 1020, train_loss 0.682
epoch 37, batch 1030, train_loss 0.698
epoch 37, batch 1040, train_loss 0.694
epoch 37, batch 1050, train_loss 0.680
epoch 37, batch 1060, train_loss 0.695
epoch 37, batch 1070, train_loss 0.689
epoch 37, batch 1080, train_loss 0.702
epoch 37, batch 1090, train_loss 0.694
epoch 37, batch 1100, train_loss 0.695
epoch 37, batch 1110, train_loss 0.692
epoch 37, batch 1120, train_loss 0.691
epoch 37, batch 1130, train_loss 0.704
epoch 37, batch 1140, train_loss 0.694
epoch 37, batch 1150, train_loss 0.698
epoch 37, batch 1160, train_loss 0.687
epoch 37, batch 1170, train_loss 0.691
epoch 37, batch 1180, train_loss 0.700
epoch 37, batch 1190, train_loss 0.693
epoch    37, train_loss 0.693, valid_loss 0.722, train_accuracy  70.23%, valid_accuracy  68.58%
epoch 38, batch 0, train_loss 0.694
epoch 38, batch 10, train_loss 0.693
epoch 38, batch 20, train_loss 0.695
epoch 38, batch 30, train_loss 0.689
epoch 38, batch 40, train_loss 0.684
epoch 38, batch 50, train_loss 0.702
epoch 38, batch 60, train_loss 0.699
epoch 38, batch 70, train_loss 0.686
epoch 38, batch 80, train_loss 0.693
epoch 38, batch 90, train_loss 0.692
epoch 38, batch 100, train_loss 0.688
epoch 38, batch 110, train_loss 0.707
epoch 38, batch 120, train_loss 0.689
epoch 38, batch 130, train_loss 0.701
epoch 38, batch 140, train_loss 0.686
epoch 38, batch 150, train_loss 0.697
epoch 38, batch 160, train_loss 0.691
epoch 38, batch 170, train_loss 0.687
epoch 38, batch 180, train_loss 0.696
epoch 38, batch 190, train_loss 0.705
epoch 38, batch 200, train_loss 0.704
epoch 38, batch 210, train_loss 0.697
epoch 38, batch 220, train_loss 0.695
epoch 38, batch 230, train_loss 0.704
epoch 38, batch 240, train_loss 0.698
epoch 38, batch 250, train_loss 0.707
epoch 38, batch 260, train_loss 0.691
epoch 38, batch 270, train_loss 0.684
epoch 38, batch 280, train_loss 0.693
epoch 38, batch 290, train_loss 0.698
epoch 38, batch 300, train_loss 0.691
epoch 38, batch 310, train_loss 0.700
epoch 38, batch 320, train_loss 0.687
epoch 38, batch 330, train_loss 0.689
epoch 38, batch 340, train_loss 0.699
epoch 38, batch 350, train_loss 0.695
epoch 38, batch 360, train_loss 0.691
epoch 38, batch 370, train_loss 0.693
epoch 38, batch 380, train_loss 0.700
epoch 38, batch 390, train_loss 0.687
epoch 38, batch 400, train_loss 0.692
epoch 38, batch 410, train_loss 0.688
epoch 38, batch 420, train_loss 0.693
epoch 38, batch 430, train_loss 0.694
epoch 38, batch 440, train_loss 0.693
epoch 38, batch 450, train_loss 0.701
epoch 38, batch 460, train_loss 0.689
epoch 38, batch 470, train_loss 0.687
epoch 38, batch 480, train_loss 0.706
epoch 38, batch 490, train_loss 0.689
epoch 38, batch 500, train_loss 0.699
epoch 38, batch 510, train_loss 0.695
epoch 38, batch 520, train_loss 0.688
epoch 38, batch 530, train_loss 0.692
epoch 38, batch 540, train_loss 0.707
epoch 38, batch 550, train_loss 0.698
epoch 38, batch 560, train_loss 0.686
epoch 38, batch 570, train_loss 0.689
epoch 38, batch 580, train_loss 0.699
epoch 38, batch 590, train_loss 0.697
epoch 38, batch 600, train_loss 0.706
epoch 38, batch 610, train_loss 0.696
epoch 38, batch 620, train_loss 0.695
epoch 38, batch 630, train_loss 0.692
epoch 38, batch 640, train_loss 0.697
epoch 38, batch 650, train_loss 0.696
epoch 38, batch 660, train_loss 0.693
epoch 38, batch 670, train_loss 0.686
epoch 38, batch 680, train_loss 0.694
epoch 38, batch 690, train_loss 0.705
epoch 38, batch 700, train_loss 0.692
epoch 38, batch 710, train_loss 0.694
epoch 38, batch 720, train_loss 0.691
epoch 38, batch 730, train_loss 0.693
epoch 38, batch 740, train_loss 0.697
epoch 38, batch 750, train_loss 0.692
epoch 38, batch 760, train_loss 0.696
epoch 38, batch 770, train_loss 0.692
epoch 38, batch 780, train_loss 0.691
epoch 38, batch 790, train_loss 0.694
epoch 38, batch 800, train_loss 0.699
epoch 38, batch 810, train_loss 0.683
epoch 38, batch 820, train_loss 0.693
epoch 38, batch 830, train_loss 0.696
epoch 38, batch 840, train_loss 0.692
epoch 38, batch 850, train_loss 0.689
epoch 38, batch 860, train_loss 0.712
epoch 38, batch 870, train_loss 0.690
epoch 38, batch 880, train_loss 0.699
epoch 38, batch 890, train_loss 0.701
epoch 38, batch 900, train_loss 0.697
epoch 38, batch 910, train_loss 0.675
epoch 38, batch 920, train_loss 0.692
epoch 38, batch 930, train_loss 0.696
epoch 38, batch 940, train_loss 0.703
epoch 38, batch 950, train_loss 0.681
epoch 38, batch 960, train_loss 0.700
epoch 38, batch 970, train_loss 0.695
epoch 38, batch 980, train_loss 0.703
epoch 38, batch 990, train_loss 0.694
epoch 38, batch 1000, train_loss 0.694
epoch 38, batch 1010, train_loss 0.693
epoch 38, batch 1020, train_loss 0.694
epoch 38, batch 1030, train_loss 0.693
epoch 38, batch 1040, train_loss 0.689
epoch 38, batch 1050, train_loss 0.685
epoch 38, batch 1060, train_loss 0.697
epoch 38, batch 1070, train_loss 0.688
epoch 38, batch 1080, train_loss 0.699
epoch 38, batch 1090, train_loss 0.699
epoch 38, batch 1100, train_loss 0.690
epoch 38, batch 1110, train_loss 0.692
epoch 38, batch 1120, train_loss 0.708
epoch 38, batch 1130, train_loss 0.690
epoch 38, batch 1140, train_loss 0.682
epoch 38, batch 1150, train_loss 0.695
epoch 38, batch 1160, train_loss 0.682
epoch 38, batch 1170, train_loss 0.704
epoch 38, batch 1180, train_loss 0.700
epoch 38, batch 1190, train_loss 0.699
epoch    38, train_loss 0.693, valid_loss 0.722, train_accuracy  70.22%, valid_accuracy  68.63%
epoch 39, batch 0, train_loss 0.700
epoch 39, batch 10, train_loss 0.689
epoch 39, batch 20, train_loss 0.697
epoch 39, batch 30, train_loss 0.682
epoch 39, batch 40, train_loss 0.699
epoch 39, batch 50, train_loss 0.699
epoch 39, batch 60, train_loss 0.700
epoch 39, batch 70, train_loss 0.698
epoch 39, batch 80, train_loss 0.692
epoch 39, batch 90, train_loss 0.702
epoch 39, batch 100, train_loss 0.690
epoch 39, batch 110, train_loss 0.695
epoch 39, batch 120, train_loss 0.691
epoch 39, batch 130, train_loss 0.703
epoch 39, batch 140, train_loss 0.701
epoch 39, batch 150, train_loss 0.696
epoch 39, batch 160, train_loss 0.689
epoch 39, batch 170, train_loss 0.703
epoch 39, batch 180, train_loss 0.693
epoch 39, batch 190, train_loss 0.690
epoch 39, batch 200, train_loss 0.690
epoch 39, batch 210, train_loss 0.700
epoch 39, batch 220, train_loss 0.694
epoch 39, batch 230, train_loss 0.689
epoch 39, batch 240, train_loss 0.693
epoch 39, batch 250, train_loss 0.690
epoch 39, batch 260, train_loss 0.697
epoch 39, batch 270, train_loss 0.700
epoch 39, batch 280, train_loss 0.692
epoch 39, batch 290, train_loss 0.693
epoch 39, batch 300, train_loss 0.693
epoch 39, batch 310, train_loss 0.691
epoch 39, batch 320, train_loss 0.694
epoch 39, batch 330, train_loss 0.705
epoch 39, batch 340, train_loss 0.698
epoch 39, batch 350, train_loss 0.688
epoch 39, batch 360, train_loss 0.690
epoch 39, batch 370, train_loss 0.692
epoch 39, batch 380, train_loss 0.680
epoch 39, batch 390, train_loss 0.691
epoch 39, batch 400, train_loss 0.695
epoch 39, batch 410, train_loss 0.697
epoch 39, batch 420, train_loss 0.686
epoch 39, batch 430, train_loss 0.695
epoch 39, batch 440, train_loss 0.697
epoch 39, batch 450, train_loss 0.691
epoch 39, batch 460, train_loss 0.701
epoch 39, batch 470, train_loss 0.694
epoch 39, batch 480, train_loss 0.684
epoch 39, batch 490, train_loss 0.692
epoch 39, batch 500, train_loss 0.684
epoch 39, batch 510, train_loss 0.696
epoch 39, batch 520, train_loss 0.702
epoch 39, batch 530, train_loss 0.692
epoch 39, batch 540, train_loss 0.699
epoch 39, batch 550, train_loss 0.699
epoch 39, batch 560, train_loss 0.699
epoch 39, batch 570, train_loss 0.687
epoch 39, batch 580, train_loss 0.700
epoch 39, batch 590, train_loss 0.700
epoch 39, batch 600, train_loss 0.685
epoch 39, batch 610, train_loss 0.696
epoch 39, batch 620, train_loss 0.690
epoch 39, batch 630, train_loss 0.703
epoch 39, batch 640, train_loss 0.691
epoch 39, batch 650, train_loss 0.690
epoch 39, batch 660, train_loss 0.692
epoch 39, batch 670, train_loss 0.697
epoch 39, batch 680, train_loss 0.695
epoch 39, batch 690, train_loss 0.686
epoch 39, batch 700, train_loss 0.689
epoch 39, batch 710, train_loss 0.701
epoch 39, batch 720, train_loss 0.697
epoch 39, batch 730, train_loss 0.695
epoch 39, batch 740, train_loss 0.698
epoch 39, batch 750, train_loss 0.692
epoch 39, batch 760, train_loss 0.694
epoch 39, batch 770, train_loss 0.699
epoch 39, batch 780, train_loss 0.701
epoch 39, batch 790, train_loss 0.704
epoch 39, batch 800, train_loss 0.694
epoch 39, batch 810, train_loss 0.691
epoch 39, batch 820, train_loss 0.692
epoch 39, batch 830, train_loss 0.688
epoch 39, batch 840, train_loss 0.696
epoch 39, batch 850, train_loss 0.690
epoch 39, batch 860, train_loss 0.694
epoch 39, batch 870, train_loss 0.700
epoch 39, batch 880, train_loss 0.703
epoch 39, batch 890, train_loss 0.696
epoch 39, batch 900, train_loss 0.686
epoch 39, batch 910, train_loss 0.695
epoch 39, batch 920, train_loss 0.690
epoch 39, batch 930, train_loss 0.685
epoch 39, batch 940, train_loss 0.698
epoch 39, batch 950, train_loss 0.700
epoch 39, batch 960, train_loss 0.695
epoch 39, batch 970, train_loss 0.693
epoch 39, batch 980, train_loss 0.691
epoch 39, batch 990, train_loss 0.694
epoch 39, batch 1000, train_loss 0.696
epoch 39, batch 1010, train_loss 0.699
epoch 39, batch 1020, train_loss 0.695
epoch 39, batch 1030, train_loss 0.686
epoch 39, batch 1040, train_loss 0.694
epoch 39, batch 1050, train_loss 0.691
epoch 39, batch 1060, train_loss 0.691
epoch 39, batch 1070, train_loss 0.686
epoch 39, batch 1080, train_loss 0.703
epoch 39, batch 1090, train_loss 0.695
epoch 39, batch 1100, train_loss 0.683
epoch 39, batch 1110, train_loss 0.692
epoch 39, batch 1120, train_loss 0.690
epoch 39, batch 1130, train_loss 0.692
epoch 39, batch 1140, train_loss 0.692
epoch 39, batch 1150, train_loss 0.694
epoch 39, batch 1160, train_loss 0.683
epoch 39, batch 1170, train_loss 0.694
epoch 39, batch 1180, train_loss 0.702
epoch 39, batch 1190, train_loss 0.697
epoch    39, train_loss 0.693, valid_loss 0.723, train_accuracy  70.21%, valid_accuracy  68.58%
epoch 40, batch 0, train_loss 0.698
epoch 40, batch 10, train_loss 0.695
epoch 40, batch 20, train_loss 0.694
epoch 40, batch 30, train_loss 0.700
epoch 40, batch 40, train_loss 0.694
epoch 40, batch 50, train_loss 0.688
epoch 40, batch 60, train_loss 0.695
epoch 40, batch 70, train_loss 0.694
epoch 40, batch 80, train_loss 0.693
epoch 40, batch 90, train_loss 0.700
epoch 40, batch 100, train_loss 0.691
epoch 40, batch 110, train_loss 0.688
epoch 40, batch 120, train_loss 0.688
epoch 40, batch 130, train_loss 0.698
epoch 40, batch 140, train_loss 0.704
epoch 40, batch 150, train_loss 0.700
epoch 40, batch 160, train_loss 0.693
epoch 40, batch 170, train_loss 0.694
epoch 40, batch 180, train_loss 0.689
epoch 40, batch 190, train_loss 0.690
epoch 40, batch 200, train_loss 0.691
epoch 40, batch 210, train_loss 0.697
epoch 40, batch 220, train_loss 0.703
epoch 40, batch 230, train_loss 0.697
epoch 40, batch 240, train_loss 0.696
epoch 40, batch 250, train_loss 0.699
epoch 40, batch 260, train_loss 0.700
epoch 40, batch 270, train_loss 0.705
epoch 40, batch 280, train_loss 0.686
epoch 40, batch 290, train_loss 0.700
epoch 40, batch 300, train_loss 0.693
epoch 40, batch 310, train_loss 0.680
epoch 40, batch 320, train_loss 0.697
epoch 40, batch 330, train_loss 0.689
epoch 40, batch 340, train_loss 0.692
epoch 40, batch 350, train_loss 0.703
epoch 40, batch 360, train_loss 0.690
epoch 40, batch 370, train_loss 0.695
epoch 40, batch 380, train_loss 0.705
epoch 40, batch 390, train_loss 0.697
epoch 40, batch 400, train_loss 0.693
epoch 40, batch 410, train_loss 0.698
epoch 40, batch 420, train_loss 0.699
epoch 40, batch 430, train_loss 0.692
epoch 40, batch 440, train_loss 0.696
epoch 40, batch 450, train_loss 0.695
epoch 40, batch 460, train_loss 0.694
epoch 40, batch 470, train_loss 0.691
epoch 40, batch 480, train_loss 0.693
epoch 40, batch 490, train_loss 0.694
epoch 40, batch 500, train_loss 0.690
epoch 40, batch 510, train_loss 0.686
epoch 40, batch 520, train_loss 0.700
epoch 40, batch 530, train_loss 0.702
epoch 40, batch 540, train_loss 0.704
epoch 40, batch 550, train_loss 0.692
epoch 40, batch 560, train_loss 0.689
epoch 40, batch 570, train_loss 0.689
epoch 40, batch 580, train_loss 0.695
epoch 40, batch 590, train_loss 0.687
epoch 40, batch 600, train_loss 0.699
epoch 40, batch 610, train_loss 0.693
epoch 40, batch 620, train_loss 0.685
epoch 40, batch 630, train_loss 0.698
epoch 40, batch 640, train_loss 0.701
epoch 40, batch 650, train_loss 0.687
epoch 40, batch 660, train_loss 0.696
epoch 40, batch 670, train_loss 0.694
epoch 40, batch 680, train_loss 0.687
epoch 40, batch 690, train_loss 0.688
epoch 40, batch 700, train_loss 0.696
epoch 40, batch 710, train_loss 0.689
epoch 40, batch 720, train_loss 0.702
epoch 40, batch 730, train_loss 0.692
epoch 40, batch 740, train_loss 0.688
epoch 40, batch 750, train_loss 0.703
epoch 40, batch 760, train_loss 0.696
epoch 40, batch 770, train_loss 0.701
epoch 40, batch 780, train_loss 0.699
epoch 40, batch 790, train_loss 0.689
epoch 40, batch 800, train_loss 0.695
epoch 40, batch 810, train_loss 0.689
epoch 40, batch 820, train_loss 0.692
epoch 40, batch 830, train_loss 0.690
epoch 40, batch 840, train_loss 0.698
epoch 40, batch 850, train_loss 0.693
epoch 40, batch 860, train_loss 0.694
epoch 40, batch 870, train_loss 0.694
epoch 40, batch 880, train_loss 0.695
epoch 40, batch 890, train_loss 0.683
epoch 40, batch 900, train_loss 0.693
epoch 40, batch 910, train_loss 0.699
epoch 40, batch 920, train_loss 0.696
epoch 40, batch 930, train_loss 0.688
epoch 40, batch 940, train_loss 0.694
epoch 40, batch 950, train_loss 0.700
epoch 40, batch 960, train_loss 0.686
epoch 40, batch 970, train_loss 0.691
epoch 40, batch 980, train_loss 0.701
epoch 40, batch 990, train_loss 0.687
epoch 40, batch 1000, train_loss 0.692
epoch 40, batch 1010, train_loss 0.689
epoch 40, batch 1020, train_loss 0.694
epoch 40, batch 1030, train_loss 0.697
epoch 40, batch 1040, train_loss 0.695
epoch 40, batch 1050, train_loss 0.696
epoch 40, batch 1060, train_loss 0.690
epoch 40, batch 1070, train_loss 0.687
epoch 40, batch 1080, train_loss 0.686
epoch 40, batch 1090, train_loss 0.679
epoch 40, batch 1100, train_loss 0.690
epoch 40, batch 1110, train_loss 0.700
epoch 40, batch 1120, train_loss 0.692
epoch 40, batch 1130, train_loss 0.684
epoch 40, batch 1140, train_loss 0.688
epoch 40, batch 1150, train_loss 0.704
epoch 40, batch 1160, train_loss 0.692
epoch 40, batch 1170, train_loss 0.690
epoch 40, batch 1180, train_loss 0.690
epoch 40, batch 1190, train_loss 0.691
epoch    40, train_loss 0.693, valid_loss 0.722, train_accuracy  70.23%, valid_accuracy  68.62%
epoch 41, batch 0, train_loss 0.698
epoch 41, batch 10, train_loss 0.681
epoch 41, batch 20, train_loss 0.689
epoch 41, batch 30, train_loss 0.694
epoch 41, batch 40, train_loss 0.689
epoch 41, batch 50, train_loss 0.693
epoch 41, batch 60, train_loss 0.688
epoch 41, batch 70, train_loss 0.694
epoch 41, batch 80, train_loss 0.696
epoch 41, batch 90, train_loss 0.695
epoch 41, batch 100, train_loss 0.684
epoch 41, batch 110, train_loss 0.698
epoch 41, batch 120, train_loss 0.691
epoch 41, batch 130, train_loss 0.691
epoch 41, batch 140, train_loss 0.690
epoch 41, batch 150, train_loss 0.693
epoch 41, batch 160, train_loss 0.698
epoch 41, batch 170, train_loss 0.696
epoch 41, batch 180, train_loss 0.691
epoch 41, batch 190, train_loss 0.699
epoch 41, batch 200, train_loss 0.701
epoch 41, batch 210, train_loss 0.689
epoch 41, batch 220, train_loss 0.692
epoch 41, batch 230, train_loss 0.687
epoch 41, batch 240, train_loss 0.697
epoch 41, batch 250, train_loss 0.701
epoch 41, batch 260, train_loss 0.693
epoch 41, batch 270, train_loss 0.697
epoch 41, batch 280, train_loss 0.693
epoch 41, batch 290, train_loss 0.700
epoch 41, batch 300, train_loss 0.690
epoch 41, batch 310, train_loss 0.693
epoch 41, batch 320, train_loss 0.688
epoch 41, batch 330, train_loss 0.689
epoch 41, batch 340, train_loss 0.690
epoch 41, batch 350, train_loss 0.709
epoch 41, batch 360, train_loss 0.693
epoch 41, batch 370, train_loss 0.695
epoch 41, batch 380, train_loss 0.691
epoch 41, batch 390, train_loss 0.699
epoch 41, batch 400, train_loss 0.689
epoch 41, batch 410, train_loss 0.695
epoch 41, batch 420, train_loss 0.694
epoch 41, batch 430, train_loss 0.694
epoch 41, batch 440, train_loss 0.703
epoch 41, batch 450, train_loss 0.691
epoch 41, batch 460, train_loss 0.684
epoch 41, batch 470, train_loss 0.693
epoch 41, batch 480, train_loss 0.695
epoch 41, batch 490, train_loss 0.688
epoch 41, batch 500, train_loss 0.683
epoch 41, batch 510, train_loss 0.694
epoch 41, batch 520, train_loss 0.686
epoch 41, batch 530, train_loss 0.695
epoch 41, batch 540, train_loss 0.697
epoch 41, batch 550, train_loss 0.698
epoch 41, batch 560, train_loss 0.697
epoch 41, batch 570, train_loss 0.687
epoch 41, batch 580, train_loss 0.696
epoch 41, batch 590, train_loss 0.704
epoch 41, batch 600, train_loss 0.701
epoch 41, batch 610, train_loss 0.695
epoch 41, batch 620, train_loss 0.690
epoch 41, batch 630, train_loss 0.691
epoch 41, batch 640, train_loss 0.678
epoch 41, batch 650, train_loss 0.692
epoch 41, batch 660, train_loss 0.684
epoch 41, batch 670, train_loss 0.688
epoch 41, batch 680, train_loss 0.695
epoch 41, batch 690, train_loss 0.690
epoch 41, batch 700, train_loss 0.687
epoch 41, batch 710, train_loss 0.702
epoch 41, batch 720, train_loss 0.697
epoch 41, batch 730, train_loss 0.702
epoch 41, batch 740, train_loss 0.689
epoch 41, batch 750, train_loss 0.688
epoch 41, batch 760, train_loss 0.695
epoch 41, batch 770, train_loss 0.695
epoch 41, batch 780, train_loss 0.696
epoch 41, batch 790, train_loss 0.684
epoch 41, batch 800, train_loss 0.692
epoch 41, batch 810, train_loss 0.691
epoch 41, batch 820, train_loss 0.701
epoch 41, batch 830, train_loss 0.689
epoch 41, batch 840, train_loss 0.697
epoch 41, batch 850, train_loss 0.700
epoch 41, batch 860, train_loss 0.693
epoch 41, batch 870, train_loss 0.698
epoch 41, batch 880, train_loss 0.700
epoch 41, batch 890, train_loss 0.691
epoch 41, batch 900, train_loss 0.691
epoch 41, batch 910, train_loss 0.695
epoch 41, batch 920, train_loss 0.695
epoch 41, batch 930, train_loss 0.695
epoch 41, batch 940, train_loss 0.691
epoch 41, batch 950, train_loss 0.696
epoch 41, batch 960, train_loss 0.692
epoch 41, batch 970, train_loss 0.687
epoch 41, batch 980, train_loss 0.689
epoch 41, batch 990, train_loss 0.688
epoch 41, batch 1000, train_loss 0.687
epoch 41, batch 1010, train_loss 0.693
epoch 41, batch 1020, train_loss 0.703
epoch 41, batch 1030, train_loss 0.691
epoch 41, batch 1040, train_loss 0.707
epoch 41, batch 1050, train_loss 0.691
epoch 41, batch 1060, train_loss 0.693
epoch 41, batch 1070, train_loss 0.690
epoch 41, batch 1080, train_loss 0.687
epoch 41, batch 1090, train_loss 0.685
epoch 41, batch 1100, train_loss 0.691
epoch 41, batch 1110, train_loss 0.699
epoch 41, batch 1120, train_loss 0.700
epoch 41, batch 1130, train_loss 0.700
epoch 41, batch 1140, train_loss 0.694
epoch 41, batch 1150, train_loss 0.699
epoch 41, batch 1160, train_loss 0.687
epoch 41, batch 1170, train_loss 0.706
epoch 41, batch 1180, train_loss 0.683
epoch 41, batch 1190, train_loss 0.693
epoch    41, train_loss 0.693, valid_loss 0.723, train_accuracy  70.25%, valid_accuracy  68.58%
epoch 42, batch 0, train_loss 0.696
epoch 42, batch 10, train_loss 0.678
epoch 42, batch 20, train_loss 0.696
epoch 42, batch 30, train_loss 0.697
epoch 42, batch 40, train_loss 0.697
epoch 42, batch 50, train_loss 0.695
epoch 42, batch 60, train_loss 0.689
epoch 42, batch 70, train_loss 0.699
epoch 42, batch 80, train_loss 0.695
epoch 42, batch 90, train_loss 0.682
epoch 42, batch 100, train_loss 0.701
epoch 42, batch 110, train_loss 0.691
epoch 42, batch 120, train_loss 0.687
epoch 42, batch 130, train_loss 0.699
epoch 42, batch 140, train_loss 0.690
epoch 42, batch 150, train_loss 0.711
epoch 42, batch 160, train_loss 0.688
epoch 42, batch 170, train_loss 0.697
epoch 42, batch 180, train_loss 0.689
epoch 42, batch 190, train_loss 0.703
epoch 42, batch 200, train_loss 0.691
epoch 42, batch 210, train_loss 0.691
epoch 42, batch 220, train_loss 0.691
epoch 42, batch 230, train_loss 0.689
epoch 42, batch 240, train_loss 0.699
epoch 42, batch 250, train_loss 0.692
epoch 42, batch 260, train_loss 0.690
epoch 42, batch 270, train_loss 0.693
epoch 42, batch 280, train_loss 0.698
epoch 42, batch 290, train_loss 0.698
epoch 42, batch 300, train_loss 0.692
epoch 42, batch 310, train_loss 0.694
epoch 42, batch 320, train_loss 0.685
epoch 42, batch 330, train_loss 0.695
epoch 42, batch 340, train_loss 0.699
epoch 42, batch 350, train_loss 0.691
epoch 42, batch 360, train_loss 0.701
epoch 42, batch 370, train_loss 0.685
epoch 42, batch 380, train_loss 0.704
epoch 42, batch 390, train_loss 0.696
epoch 42, batch 400, train_loss 0.692
epoch 42, batch 410, train_loss 0.684
epoch 42, batch 420, train_loss 0.689
epoch 42, batch 430, train_loss 0.696
epoch 42, batch 440, train_loss 0.690
epoch 42, batch 450, train_loss 0.697
epoch 42, batch 460, train_loss 0.690
epoch 42, batch 470, train_loss 0.695
epoch 42, batch 480, train_loss 0.695
epoch 42, batch 490, train_loss 0.688
epoch 42, batch 500, train_loss 0.696
epoch 42, batch 510, train_loss 0.693
epoch 42, batch 520, train_loss 0.690
epoch 42, batch 530, train_loss 0.698
epoch 42, batch 540, train_loss 0.701
epoch 42, batch 550, train_loss 0.698
epoch 42, batch 560, train_loss 0.700
epoch 42, batch 570, train_loss 0.696
epoch 42, batch 580, train_loss 0.699
epoch 42, batch 590, train_loss 0.693
epoch 42, batch 600, train_loss 0.688
epoch 42, batch 610, train_loss 0.691
epoch 42, batch 620, train_loss 0.697
epoch 42, batch 630, train_loss 0.691
epoch 42, batch 640, train_loss 0.706
epoch 42, batch 650, train_loss 0.690
epoch 42, batch 660, train_loss 0.691
epoch 42, batch 670, train_loss 0.688
epoch 42, batch 680, train_loss 0.692
epoch 42, batch 690, train_loss 0.696
epoch 42, batch 700, train_loss 0.705
epoch 42, batch 710, train_loss 0.698
epoch 42, batch 720, train_loss 0.685
epoch 42, batch 730, train_loss 0.699
epoch 42, batch 740, train_loss 0.702
epoch 42, batch 750, train_loss 0.692
epoch 42, batch 760, train_loss 0.692
epoch 42, batch 770, train_loss 0.688
epoch 42, batch 780, train_loss 0.694
epoch 42, batch 790, train_loss 0.693
epoch 42, batch 800, train_loss 0.695
epoch 42, batch 810, train_loss 0.696
epoch 42, batch 820, train_loss 0.699
epoch 42, batch 830, train_loss 0.690
epoch 42, batch 840, train_loss 0.692
epoch 42, batch 850, train_loss 0.693
epoch 42, batch 860, train_loss 0.686
epoch 42, batch 870, train_loss 0.686
epoch 42, batch 880, train_loss 0.700
epoch 42, batch 890, train_loss 0.699
epoch 42, batch 900, train_loss 0.692
epoch 42, batch 910, train_loss 0.696
epoch 42, batch 920, train_loss 0.692
epoch 42, batch 930, train_loss 0.692
epoch 42, batch 940, train_loss 0.689
epoch 42, batch 950, train_loss 0.689
epoch 42, batch 960, train_loss 0.697
epoch 42, batch 970, train_loss 0.690
epoch 42, batch 980, train_loss 0.697
epoch 42, batch 990, train_loss 0.692
epoch 42, batch 1000, train_loss 0.697
epoch 42, batch 1010, train_loss 0.686
epoch 42, batch 1020, train_loss 0.687
epoch 42, batch 1030, train_loss 0.692
epoch 42, batch 1040, train_loss 0.696
epoch 42, batch 1050, train_loss 0.689
epoch 42, batch 1060, train_loss 0.692
epoch 42, batch 1070, train_loss 0.695
epoch 42, batch 1080, train_loss 0.693
epoch 42, batch 1090, train_loss 0.684
epoch 42, batch 1100, train_loss 0.691
epoch 42, batch 1110, train_loss 0.693
epoch 42, batch 1120, train_loss 0.692
epoch 42, batch 1130, train_loss 0.685
epoch 42, batch 1140, train_loss 0.698
epoch 42, batch 1150, train_loss 0.702
epoch 42, batch 1160, train_loss 0.696
epoch 42, batch 1170, train_loss 0.707
epoch 42, batch 1180, train_loss 0.701
epoch 42, batch 1190, train_loss 0.691
epoch    42, train_loss 0.693, valid_loss 0.723, train_accuracy  70.22%, valid_accuracy  68.56%
epoch 43, batch 0, train_loss 0.692
epoch 43, batch 10, train_loss 0.693
epoch 43, batch 20, train_loss 0.701
epoch 43, batch 30, train_loss 0.694
epoch 43, batch 40, train_loss 0.683
epoch 43, batch 50, train_loss 0.699
epoch 43, batch 60, train_loss 0.695
epoch 43, batch 70, train_loss 0.691
epoch 43, batch 80, train_loss 0.691
epoch 43, batch 90, train_loss 0.700
epoch 43, batch 100, train_loss 0.706
epoch 43, batch 110, train_loss 0.689
epoch 43, batch 120, train_loss 0.700
epoch 43, batch 130, train_loss 0.689
epoch 43, batch 140, train_loss 0.689
epoch 43, batch 150, train_loss 0.698
epoch 43, batch 160, train_loss 0.695
epoch 43, batch 170, train_loss 0.691
epoch 43, batch 180, train_loss 0.689
epoch 43, batch 190, train_loss 0.687
epoch 43, batch 200, train_loss 0.695
epoch 43, batch 210, train_loss 0.692
epoch 43, batch 220, train_loss 0.694
epoch 43, batch 230, train_loss 0.698
epoch 43, batch 240, train_loss 0.701
epoch 43, batch 250, train_loss 0.690
epoch 43, batch 260, train_loss 0.695
epoch 43, batch 270, train_loss 0.683
epoch 43, batch 280, train_loss 0.703
epoch 43, batch 290, train_loss 0.691
epoch 43, batch 300, train_loss 0.689
epoch 43, batch 310, train_loss 0.696
epoch 43, batch 320, train_loss 0.702
epoch 43, batch 330, train_loss 0.694
epoch 43, batch 340, train_loss 0.698
epoch 43, batch 350, train_loss 0.696
epoch 43, batch 360, train_loss 0.696
epoch 43, batch 370, train_loss 0.699
epoch 43, batch 380, train_loss 0.685
epoch 43, batch 390, train_loss 0.699
epoch 43, batch 400, train_loss 0.694
epoch 43, batch 410, train_loss 0.688
epoch 43, batch 420, train_loss 0.691
epoch 43, batch 430, train_loss 0.696
epoch 43, batch 440, train_loss 0.703
epoch 43, batch 450, train_loss 0.693
epoch 43, batch 460, train_loss 0.700
epoch 43, batch 470, train_loss 0.691
epoch 43, batch 480, train_loss 0.689
epoch 43, batch 490, train_loss 0.698
epoch 43, batch 500, train_loss 0.695
epoch 43, batch 510, train_loss 0.689
epoch 43, batch 520, train_loss 0.694
epoch 43, batch 530, train_loss 0.707
epoch 43, batch 540, train_loss 0.697
epoch 43, batch 550, train_loss 0.694
epoch 43, batch 560, train_loss 0.701
epoch 43, batch 570, train_loss 0.690
epoch 43, batch 580, train_loss 0.686
epoch 43, batch 590, train_loss 0.697
epoch 43, batch 600, train_loss 0.694
epoch 43, batch 610, train_loss 0.688
epoch 43, batch 620, train_loss 0.689
epoch 43, batch 630, train_loss 0.681
epoch 43, batch 640, train_loss 0.687
epoch 43, batch 650, train_loss 0.699
epoch 43, batch 660, train_loss 0.696
epoch 43, batch 670, train_loss 0.688
epoch 43, batch 680, train_loss 0.691
epoch 43, batch 690, train_loss 0.694
epoch 43, batch 700, train_loss 0.690
epoch 43, batch 710, train_loss 0.695
epoch 43, batch 720, train_loss 0.689
epoch 43, batch 730, train_loss 0.694
epoch 43, batch 740, train_loss 0.697
epoch 43, batch 750, train_loss 0.693
epoch 43, batch 760, train_loss 0.691
epoch 43, batch 770, train_loss 0.703
epoch 43, batch 780, train_loss 0.695
epoch 43, batch 790, train_loss 0.688
epoch 43, batch 800, train_loss 0.690
epoch 43, batch 810, train_loss 0.687
epoch 43, batch 820, train_loss 0.682
epoch 43, batch 830, train_loss 0.691
epoch 43, batch 840, train_loss 0.694
epoch 43, batch 850, train_loss 0.684
epoch 43, batch 860, train_loss 0.692
epoch 43, batch 870, train_loss 0.698
epoch 43, batch 880, train_loss 0.703
epoch 43, batch 890, train_loss 0.704
epoch 43, batch 900, train_loss 0.692
epoch 43, batch 910, train_loss 0.690
epoch 43, batch 920, train_loss 0.694
epoch 43, batch 930, train_loss 0.692
epoch 43, batch 940, train_loss 0.695
epoch 43, batch 950, train_loss 0.695
epoch 43, batch 960, train_loss 0.696
epoch 43, batch 970, train_loss 0.698
epoch 43, batch 980, train_loss 0.691
epoch 43, batch 990, train_loss 0.680
epoch 43, batch 1000, train_loss 0.687
epoch 43, batch 1010, train_loss 0.697
epoch 43, batch 1020, train_loss 0.686
epoch 43, batch 1030, train_loss 0.689
epoch 43, batch 1040, train_loss 0.695
epoch 43, batch 1050, train_loss 0.703
epoch 43, batch 1060, train_loss 0.696
epoch 43, batch 1070, train_loss 0.697
epoch 43, batch 1080, train_loss 0.694
epoch 43, batch 1090, train_loss 0.692
epoch 43, batch 1100, train_loss 0.695
epoch 43, batch 1110, train_loss 0.696
epoch 43, batch 1120, train_loss 0.690
epoch 43, batch 1130, train_loss 0.695
epoch 43, batch 1140, train_loss 0.695
epoch 43, batch 1150, train_loss 0.690
epoch 43, batch 1160, train_loss 0.702
epoch 43, batch 1170, train_loss 0.696
epoch 43, batch 1180, train_loss 0.694
epoch 43, batch 1190, train_loss 0.696
epoch    43, train_loss 0.693, valid_loss 0.722, train_accuracy  70.24%, valid_accuracy  68.60%
epoch 44, batch 0, train_loss 0.694
epoch 44, batch 10, train_loss 0.693
epoch 44, batch 20, train_loss 0.696
epoch 44, batch 30, train_loss 0.699
epoch 44, batch 40, train_loss 0.691
epoch 44, batch 50, train_loss 0.694
epoch 44, batch 60, train_loss 0.690
epoch 44, batch 70, train_loss 0.691
epoch 44, batch 80, train_loss 0.691
epoch 44, batch 90, train_loss 0.688
epoch 44, batch 100, train_loss 0.686
epoch 44, batch 110, train_loss 0.690
epoch 44, batch 120, train_loss 0.690
epoch 44, batch 130, train_loss 0.698
epoch 44, batch 140, train_loss 0.695
epoch 44, batch 150, train_loss 0.687
epoch 44, batch 160, train_loss 0.694
epoch 44, batch 170, train_loss 0.700
epoch 44, batch 180, train_loss 0.694
epoch 44, batch 190, train_loss 0.693
epoch 44, batch 200, train_loss 0.692
epoch 44, batch 210, train_loss 0.699
epoch 44, batch 220, train_loss 0.694
epoch 44, batch 230, train_loss 0.689
epoch 44, batch 240, train_loss 0.685
epoch 44, batch 250, train_loss 0.687
epoch 44, batch 260, train_loss 0.688
epoch 44, batch 270, train_loss 0.696
epoch 44, batch 280, train_loss 0.697
epoch 44, batch 290, train_loss 0.693
epoch 44, batch 300, train_loss 0.686
epoch 44, batch 310, train_loss 0.708
epoch 44, batch 320, train_loss 0.692
epoch 44, batch 330, train_loss 0.690
epoch 44, batch 340, train_loss 0.687
epoch 44, batch 350, train_loss 0.683
epoch 44, batch 360, train_loss 0.697
epoch 44, batch 370, train_loss 0.694
epoch 44, batch 380, train_loss 0.699
epoch 44, batch 390, train_loss 0.694
epoch 44, batch 400, train_loss 0.694
epoch 44, batch 410, train_loss 0.692
epoch 44, batch 420, train_loss 0.699
epoch 44, batch 430, train_loss 0.692
epoch 44, batch 440, train_loss 0.695
epoch 44, batch 450, train_loss 0.698
epoch 44, batch 460, train_loss 0.689
epoch 44, batch 470, train_loss 0.687
epoch 44, batch 480, train_loss 0.694
epoch 44, batch 490, train_loss 0.692
epoch 44, batch 500, train_loss 0.690
epoch 44, batch 510, train_loss 0.687
epoch 44, batch 520, train_loss 0.689
epoch 44, batch 530, train_loss 0.691
epoch 44, batch 540, train_loss 0.692
epoch 44, batch 550, train_loss 0.697
epoch 44, batch 560, train_loss 0.693
epoch 44, batch 570, train_loss 0.693
epoch 44, batch 580, train_loss 0.690
epoch 44, batch 590, train_loss 0.690
epoch 44, batch 600, train_loss 0.696
epoch 44, batch 610, train_loss 0.689
epoch 44, batch 620, train_loss 0.692
epoch 44, batch 630, train_loss 0.690
epoch 44, batch 640, train_loss 0.694
epoch 44, batch 650, train_loss 0.689
epoch 44, batch 660, train_loss 0.705
epoch 44, batch 670, train_loss 0.689
epoch 44, batch 680, train_loss 0.694
epoch 44, batch 690, train_loss 0.688
epoch 44, batch 700, train_loss 0.690
epoch 44, batch 710, train_loss 0.692
epoch 44, batch 720, train_loss 0.683
epoch 44, batch 730, train_loss 0.695
epoch 44, batch 740, train_loss 0.699
epoch 44, batch 750, train_loss 0.689
epoch 44, batch 760, train_loss 0.699
epoch 44, batch 770, train_loss 0.686
epoch 44, batch 780, train_loss 0.699
epoch 44, batch 790, train_loss 0.695
epoch 44, batch 800, train_loss 0.697
epoch 44, batch 810, train_loss 0.693
epoch 44, batch 820, train_loss 0.694
epoch 44, batch 830, train_loss 0.698
epoch 44, batch 840, train_loss 0.696
epoch 44, batch 850, train_loss 0.698
epoch 44, batch 860, train_loss 0.688
epoch 44, batch 870, train_loss 0.691
epoch 44, batch 880, train_loss 0.694
epoch 44, batch 890, train_loss 0.697
epoch 44, batch 900, train_loss 0.699
epoch 44, batch 910, train_loss 0.696
epoch 44, batch 920, train_loss 0.686
epoch 44, batch 930, train_loss 0.695
epoch 44, batch 940, train_loss 0.699
epoch 44, batch 950, train_loss 0.703
epoch 44, batch 960, train_loss 0.694
epoch 44, batch 970, train_loss 0.696
epoch 44, batch 980, train_loss 0.696
epoch 44, batch 990, train_loss 0.691
epoch 44, batch 1000, train_loss 0.693
epoch 44, batch 1010, train_loss 0.690
epoch 44, batch 1020, train_loss 0.694
epoch 44, batch 1030, train_loss 0.697
epoch 44, batch 1040, train_loss 0.680
epoch 44, batch 1050, train_loss 0.690
epoch 44, batch 1060, train_loss 0.694
epoch 44, batch 1070, train_loss 0.692
epoch 44, batch 1080, train_loss 0.688
epoch 44, batch 1090, train_loss 0.700
epoch 44, batch 1100, train_loss 0.709
epoch 44, batch 1110, train_loss 0.696
epoch 44, batch 1120, train_loss 0.692
epoch 44, batch 1130, train_loss 0.693
epoch 44, batch 1140, train_loss 0.703
epoch 44, batch 1150, train_loss 0.695
epoch 44, batch 1160, train_loss 0.697
epoch 44, batch 1170, train_loss 0.697
epoch 44, batch 1180, train_loss 0.686
epoch 44, batch 1190, train_loss 0.701
epoch    44, train_loss 0.694, valid_loss 0.724, train_accuracy  70.19%, valid_accuracy  68.49%
epoch 45, batch 0, train_loss 0.697
epoch 45, batch 10, train_loss 0.699
epoch 45, batch 20, train_loss 0.693
epoch 45, batch 30, train_loss 0.690
epoch 45, batch 40, train_loss 0.686
epoch 45, batch 50, train_loss 0.701
epoch 45, batch 60, train_loss 0.691
epoch 45, batch 70, train_loss 0.702
epoch 45, batch 80, train_loss 0.699
epoch 45, batch 90, train_loss 0.700
epoch 45, batch 100, train_loss 0.693
epoch 45, batch 110, train_loss 0.699
epoch 45, batch 120, train_loss 0.697
epoch 45, batch 130, train_loss 0.691
epoch 45, batch 140, train_loss 0.699
epoch 45, batch 150, train_loss 0.696
epoch 45, batch 160, train_loss 0.690
epoch 45, batch 170, train_loss 0.686
epoch 45, batch 180, train_loss 0.690
epoch 45, batch 190, train_loss 0.693
epoch 45, batch 200, train_loss 0.687
epoch 45, batch 210, train_loss 0.698
epoch 45, batch 220, train_loss 0.684
epoch 45, batch 230, train_loss 0.689
epoch 45, batch 240, train_loss 0.687
epoch 45, batch 250, train_loss 0.697
epoch 45, batch 260, train_loss 0.700
epoch 45, batch 270, train_loss 0.693
epoch 45, batch 280, train_loss 0.699
epoch 45, batch 290, train_loss 0.695
epoch 45, batch 300, train_loss 0.701
epoch 45, batch 310, train_loss 0.701
epoch 45, batch 320, train_loss 0.698
epoch 45, batch 330, train_loss 0.695
epoch 45, batch 340, train_loss 0.686
epoch 45, batch 350, train_loss 0.698
epoch 45, batch 360, train_loss 0.684
epoch 45, batch 370, train_loss 0.687
epoch 45, batch 380, train_loss 0.688
epoch 45, batch 390, train_loss 0.694
epoch 45, batch 400, train_loss 0.700
epoch 45, batch 410, train_loss 0.691
epoch 45, batch 420, train_loss 0.696
epoch 45, batch 430, train_loss 0.695
epoch 45, batch 440, train_loss 0.694
epoch 45, batch 450, train_loss 0.694
epoch 45, batch 460, train_loss 0.697
epoch 45, batch 470, train_loss 0.701
epoch 45, batch 480, train_loss 0.698
epoch 45, batch 490, train_loss 0.696
epoch 45, batch 500, train_loss 0.693
epoch 45, batch 510, train_loss 0.686
epoch 45, batch 520, train_loss 0.692
epoch 45, batch 530, train_loss 0.694
epoch 45, batch 540, train_loss 0.698
epoch 45, batch 550, train_loss 0.689
epoch 45, batch 560, train_loss 0.698
epoch 45, batch 570, train_loss 0.691
epoch 45, batch 580, train_loss 0.698
epoch 45, batch 590, train_loss 0.688
epoch 45, batch 600, train_loss 0.690
epoch 45, batch 610, train_loss 0.688
epoch 45, batch 620, train_loss 0.691
epoch 45, batch 630, train_loss 0.699
epoch 45, batch 640, train_loss 0.688
epoch 45, batch 650, train_loss 0.710
epoch 45, batch 660, train_loss 0.699
epoch 45, batch 670, train_loss 0.688
epoch 45, batch 680, train_loss 0.694
epoch 45, batch 690, train_loss 0.694
epoch 45, batch 700, train_loss 0.690
epoch 45, batch 710, train_loss 0.705
epoch 45, batch 720, train_loss 0.693
epoch 45, batch 730, train_loss 0.690
epoch 45, batch 740, train_loss 0.694
epoch 45, batch 750, train_loss 0.691
epoch 45, batch 760, train_loss 0.704
epoch 45, batch 770, train_loss 0.696
epoch 45, batch 780, train_loss 0.696
epoch 45, batch 790, train_loss 0.702
epoch 45, batch 800, train_loss 0.687
epoch 45, batch 810, train_loss 0.694
epoch 45, batch 820, train_loss 0.696
epoch 45, batch 830, train_loss 0.694
epoch 45, batch 840, train_loss 0.697
epoch 45, batch 850, train_loss 0.699
epoch 45, batch 860, train_loss 0.703
epoch 45, batch 870, train_loss 0.702
epoch 45, batch 880, train_loss 0.704
epoch 45, batch 890, train_loss 0.685
epoch 45, batch 900, train_loss 0.691
epoch 45, batch 910, train_loss 0.694
epoch 45, batch 920, train_loss 0.688
epoch 45, batch 930, train_loss 0.686
epoch 45, batch 940, train_loss 0.691
epoch 45, batch 950, train_loss 0.696
epoch 45, batch 960, train_loss 0.692
epoch 45, batch 970, train_loss 0.702
epoch 45, batch 980, train_loss 0.689
epoch 45, batch 990, train_loss 0.690
epoch 45, batch 1000, train_loss 0.696
epoch 45, batch 1010, train_loss 0.704
epoch 45, batch 1020, train_loss 0.691
epoch 45, batch 1030, train_loss 0.692
epoch 45, batch 1040, train_loss 0.700
epoch 45, batch 1050, train_loss 0.691
epoch 45, batch 1060, train_loss 0.699
epoch 45, batch 1070, train_loss 0.687
epoch 45, batch 1080, train_loss 0.704
epoch 45, batch 1090, train_loss 0.701
epoch 45, batch 1100, train_loss 0.694
epoch 45, batch 1110, train_loss 0.689
epoch 45, batch 1120, train_loss 0.691
epoch 45, batch 1130, train_loss 0.697
epoch 45, batch 1140, train_loss 0.689
epoch 45, batch 1150, train_loss 0.686
epoch 45, batch 1160, train_loss 0.686
epoch 45, batch 1170, train_loss 0.688
epoch 45, batch 1180, train_loss 0.700
epoch 45, batch 1190, train_loss 0.695
epoch    45, train_loss 0.692, valid_loss 0.722, train_accuracy  70.28%, valid_accuracy  68.58%
epoch 46, batch 0, train_loss 0.696
epoch 46, batch 10, train_loss 0.696
epoch 46, batch 20, train_loss 0.696
epoch 46, batch 30, train_loss 0.690
epoch 46, batch 40, train_loss 0.691
epoch 46, batch 50, train_loss 0.701
epoch 46, batch 60, train_loss 0.693
epoch 46, batch 70, train_loss 0.689
epoch 46, batch 80, train_loss 0.683
epoch 46, batch 90, train_loss 0.687
epoch 46, batch 100, train_loss 0.695
epoch 46, batch 110, train_loss 0.702
epoch 46, batch 120, train_loss 0.690
epoch 46, batch 130, train_loss 0.698
epoch 46, batch 140, train_loss 0.706
epoch 46, batch 150, train_loss 0.691
epoch 46, batch 160, train_loss 0.684
epoch 46, batch 170, train_loss 0.695
epoch 46, batch 180, train_loss 0.701
epoch 46, batch 190, train_loss 0.688
epoch 46, batch 200, train_loss 0.693
epoch 46, batch 210, train_loss 0.700
epoch 46, batch 220, train_loss 0.699
epoch 46, batch 230, train_loss 0.693
epoch 46, batch 240, train_loss 0.697
epoch 46, batch 250, train_loss 0.692
epoch 46, batch 260, train_loss 0.685
epoch 46, batch 270, train_loss 0.685
epoch 46, batch 280, train_loss 0.693
epoch 46, batch 290, train_loss 0.689
epoch 46, batch 300, train_loss 0.691
epoch 46, batch 310, train_loss 0.701
epoch 46, batch 320, train_loss 0.690
epoch 46, batch 330, train_loss 0.692
epoch 46, batch 340, train_loss 0.685
epoch 46, batch 350, train_loss 0.690
epoch 46, batch 360, train_loss 0.703
epoch 46, batch 370, train_loss 0.694
epoch 46, batch 380, train_loss 0.695
epoch 46, batch 390, train_loss 0.696
epoch 46, batch 400, train_loss 0.701
epoch 46, batch 410, train_loss 0.696
epoch 46, batch 420, train_loss 0.688
epoch 46, batch 430, train_loss 0.692
epoch 46, batch 440, train_loss 0.699
epoch 46, batch 450, train_loss 0.700
epoch 46, batch 460, train_loss 0.690
epoch 46, batch 470, train_loss 0.690
epoch 46, batch 480, train_loss 0.692
epoch 46, batch 490, train_loss 0.689
epoch 46, batch 500, train_loss 0.684
epoch 46, batch 510, train_loss 0.691
epoch 46, batch 520, train_loss 0.694
epoch 46, batch 530, train_loss 0.695
epoch 46, batch 540, train_loss 0.695
epoch 46, batch 550, train_loss 0.700
epoch 46, batch 560, train_loss 0.696
epoch 46, batch 570, train_loss 0.697
epoch 46, batch 580, train_loss 0.693
epoch 46, batch 590, train_loss 0.682
epoch 46, batch 600, train_loss 0.698
epoch 46, batch 610, train_loss 0.696
epoch 46, batch 620, train_loss 0.689
epoch 46, batch 630, train_loss 0.704
epoch 46, batch 640, train_loss 0.689
epoch 46, batch 650, train_loss 0.694
epoch 46, batch 660, train_loss 0.701
epoch 46, batch 670, train_loss 0.702
epoch 46, batch 680, train_loss 0.689
epoch 46, batch 690, train_loss 0.698
epoch 46, batch 700, train_loss 0.700
epoch 46, batch 710, train_loss 0.692
epoch 46, batch 720, train_loss 0.693
epoch 46, batch 730, train_loss 0.694
epoch 46, batch 740, train_loss 0.690
epoch 46, batch 750, train_loss 0.685
epoch 46, batch 760, train_loss 0.701
epoch 46, batch 770, train_loss 0.691
epoch 46, batch 780, train_loss 0.680
epoch 46, batch 790, train_loss 0.694
epoch 46, batch 800, train_loss 0.695
epoch 46, batch 810, train_loss 0.698
epoch 46, batch 820, train_loss 0.692
epoch 46, batch 830, train_loss 0.700
epoch 46, batch 840, train_loss 0.692
epoch 46, batch 850, train_loss 0.695
epoch 46, batch 860, train_loss 0.692
epoch 46, batch 870, train_loss 0.695
epoch 46, batch 880, train_loss 0.685
epoch 46, batch 890, train_loss 0.692
epoch 46, batch 900, train_loss 0.689
epoch 46, batch 910, train_loss 0.698
epoch 46, batch 920, train_loss 0.696
epoch 46, batch 930, train_loss 0.694
epoch 46, batch 940, train_loss 0.696
epoch 46, batch 950, train_loss 0.693
epoch 46, batch 960, train_loss 0.693
epoch 46, batch 970, train_loss 0.692
epoch 46, batch 980, train_loss 0.706
epoch 46, batch 990, train_loss 0.694
epoch 46, batch 1000, train_loss 0.677
epoch 46, batch 1010, train_loss 0.698
epoch 46, batch 1020, train_loss 0.690
epoch 46, batch 1030, train_loss 0.703
epoch 46, batch 1040, train_loss 0.695
epoch 46, batch 1050, train_loss 0.700
epoch 46, batch 1060, train_loss 0.696
epoch 46, batch 1070, train_loss 0.684
epoch 46, batch 1080, train_loss 0.685
epoch 46, batch 1090, train_loss 0.694
epoch 46, batch 1100, train_loss 0.699
epoch 46, batch 1110, train_loss 0.692
epoch 46, batch 1120, train_loss 0.682
epoch 46, batch 1130, train_loss 0.693
epoch 46, batch 1140, train_loss 0.698
epoch 46, batch 1150, train_loss 0.686
epoch 46, batch 1160, train_loss 0.695
epoch 46, batch 1170, train_loss 0.694
epoch 46, batch 1180, train_loss 0.697
epoch 46, batch 1190, train_loss 0.699
epoch    46, train_loss 0.692, valid_loss 0.722, train_accuracy  70.27%, valid_accuracy  68.58%
epoch 47, batch 0, train_loss 0.688
epoch 47, batch 10, train_loss 0.690
epoch 47, batch 20, train_loss 0.695
epoch 47, batch 30, train_loss 0.693
epoch 47, batch 40, train_loss 0.689
epoch 47, batch 50, train_loss 0.688
epoch 47, batch 60, train_loss 0.686
epoch 47, batch 70, train_loss 0.694
epoch 47, batch 80, train_loss 0.693
epoch 47, batch 90, train_loss 0.685
epoch 47, batch 100, train_loss 0.688
epoch 47, batch 110, train_loss 0.694
epoch 47, batch 120, train_loss 0.694
epoch 47, batch 130, train_loss 0.698
epoch 47, batch 140, train_loss 0.694
epoch 47, batch 150, train_loss 0.694
epoch 47, batch 160, train_loss 0.690
epoch 47, batch 170, train_loss 0.693
epoch 47, batch 180, train_loss 0.682
epoch 47, batch 190, train_loss 0.699
epoch 47, batch 200, train_loss 0.683
epoch 47, batch 210, train_loss 0.702
epoch 47, batch 220, train_loss 0.693
epoch 47, batch 230, train_loss 0.687
epoch 47, batch 240, train_loss 0.691
epoch 47, batch 250, train_loss 0.697
epoch 47, batch 260, train_loss 0.693
epoch 47, batch 270, train_loss 0.690
epoch 47, batch 280, train_loss 0.694
epoch 47, batch 290, train_loss 0.691
epoch 47, batch 300, train_loss 0.700
epoch 47, batch 310, train_loss 0.691
epoch 47, batch 320, train_loss 0.693
epoch 47, batch 330, train_loss 0.692
epoch 47, batch 340, train_loss 0.692
epoch 47, batch 350, train_loss 0.689
epoch 47, batch 360, train_loss 0.692
epoch 47, batch 370, train_loss 0.698
epoch 47, batch 380, train_loss 0.695
epoch 47, batch 390, train_loss 0.688
epoch 47, batch 400, train_loss 0.700
epoch 47, batch 410, train_loss 0.698
epoch 47, batch 420, train_loss 0.705
epoch 47, batch 430, train_loss 0.691
epoch 47, batch 440, train_loss 0.693
epoch 47, batch 450, train_loss 0.699
epoch 47, batch 460, train_loss 0.693
epoch 47, batch 470, train_loss 0.693
epoch 47, batch 480, train_loss 0.706
epoch 47, batch 490, train_loss 0.691
epoch 47, batch 500, train_loss 0.681
epoch 47, batch 510, train_loss 0.693
epoch 47, batch 520, train_loss 0.700
epoch 47, batch 530, train_loss 0.698
epoch 47, batch 540, train_loss 0.689
epoch 47, batch 550, train_loss 0.678
epoch 47, batch 560, train_loss 0.701
epoch 47, batch 570, train_loss 0.695
epoch 47, batch 580, train_loss 0.693
epoch 47, batch 590, train_loss 0.688
epoch 47, batch 600, train_loss 0.700
epoch 47, batch 610, train_loss 0.690
epoch 47, batch 620, train_loss 0.678
epoch 47, batch 630, train_loss 0.699
epoch 47, batch 640, train_loss 0.694
epoch 47, batch 650, train_loss 0.705
epoch 47, batch 660, train_loss 0.692
epoch 47, batch 670, train_loss 0.693
epoch 47, batch 680, train_loss 0.694
epoch 47, batch 690, train_loss 0.693
epoch 47, batch 700, train_loss 0.693
epoch 47, batch 710, train_loss 0.705
epoch 47, batch 720, train_loss 0.694
epoch 47, batch 730, train_loss 0.685
epoch 47, batch 740, train_loss 0.689
epoch 47, batch 750, train_loss 0.688
epoch 47, batch 760, train_loss 0.689
epoch 47, batch 770, train_loss 0.693
epoch 47, batch 780, train_loss 0.693
epoch 47, batch 790, train_loss 0.693
epoch 47, batch 800, train_loss 0.700
epoch 47, batch 810, train_loss 0.704
epoch 47, batch 820, train_loss 0.699
epoch 47, batch 830, train_loss 0.691
epoch 47, batch 840, train_loss 0.693
epoch 47, batch 850, train_loss 0.694
epoch 47, batch 860, train_loss 0.698
epoch 47, batch 870, train_loss 0.696
epoch 47, batch 880, train_loss 0.692
epoch 47, batch 890, train_loss 0.703
epoch 47, batch 900, train_loss 0.698
epoch 47, batch 910, train_loss 0.692
epoch 47, batch 920, train_loss 0.697
epoch 47, batch 930, train_loss 0.701
epoch 47, batch 940, train_loss 0.686
epoch 47, batch 950, train_loss 0.697
epoch 47, batch 960, train_loss 0.688
epoch 47, batch 970, train_loss 0.686
epoch 47, batch 980, train_loss 0.695
epoch 47, batch 990, train_loss 0.695
epoch 47, batch 1000, train_loss 0.693
epoch 47, batch 1010, train_loss 0.698
epoch 47, batch 1020, train_loss 0.685
epoch 47, batch 1030, train_loss 0.697
epoch 47, batch 1040, train_loss 0.695
epoch 47, batch 1050, train_loss 0.692
epoch 47, batch 1060, train_loss 0.699
epoch 47, batch 1070, train_loss 0.696
epoch 47, batch 1080, train_loss 0.681
epoch 47, batch 1090, train_loss 0.688
epoch 47, batch 1100, train_loss 0.695
epoch 47, batch 1110, train_loss 0.694
epoch 47, batch 1120, train_loss 0.700
epoch 47, batch 1130, train_loss 0.691
epoch 47, batch 1140, train_loss 0.691
epoch 47, batch 1150, train_loss 0.693
epoch 47, batch 1160, train_loss 0.702
epoch 47, batch 1170, train_loss 0.700
epoch 47, batch 1180, train_loss 0.703
epoch 47, batch 1190, train_loss 0.682
epoch    47, train_loss 0.692, valid_loss 0.723, train_accuracy  70.27%, valid_accuracy  68.58%
epoch 48, batch 0, train_loss 0.690
epoch 48, batch 10, train_loss 0.692
epoch 48, batch 20, train_loss 0.691
epoch 48, batch 30, train_loss 0.691
epoch 48, batch 40, train_loss 0.695
epoch 48, batch 50, train_loss 0.694
epoch 48, batch 60, train_loss 0.699
epoch 48, batch 70, train_loss 0.705
epoch 48, batch 80, train_loss 0.690
epoch 48, batch 90, train_loss 0.694
epoch 48, batch 100, train_loss 0.683
epoch 48, batch 110, train_loss 0.689
epoch 48, batch 120, train_loss 0.695
epoch 48, batch 130, train_loss 0.683
epoch 48, batch 140, train_loss 0.696
epoch 48, batch 150, train_loss 0.689
epoch 48, batch 160, train_loss 0.690
epoch 48, batch 170, train_loss 0.691
epoch 48, batch 180, train_loss 0.691
epoch 48, batch 190, train_loss 0.693
epoch 48, batch 200, train_loss 0.698
epoch 48, batch 210, train_loss 0.697
epoch 48, batch 220, train_loss 0.689
epoch 48, batch 230, train_loss 0.699
epoch 48, batch 240, train_loss 0.688
epoch 48, batch 250, train_loss 0.703
epoch 48, batch 260, train_loss 0.700
epoch 48, batch 270, train_loss 0.691
epoch 48, batch 280, train_loss 0.704
epoch 48, batch 290, train_loss 0.689
epoch 48, batch 300, train_loss 0.695
epoch 48, batch 310, train_loss 0.692
epoch 48, batch 320, train_loss 0.692
epoch 48, batch 330, train_loss 0.697
epoch 48, batch 340, train_loss 0.687
epoch 48, batch 350, train_loss 0.689
epoch 48, batch 360, train_loss 0.692
epoch 48, batch 370, train_loss 0.700
epoch 48, batch 380, train_loss 0.696
epoch 48, batch 390, train_loss 0.706
epoch 48, batch 400, train_loss 0.699
epoch 48, batch 410, train_loss 0.695
epoch 48, batch 420, train_loss 0.675
epoch 48, batch 430, train_loss 0.696
epoch 48, batch 440, train_loss 0.689
epoch 48, batch 450, train_loss 0.698
epoch 48, batch 460, train_loss 0.698
epoch 48, batch 470, train_loss 0.692
epoch 48, batch 480, train_loss 0.688
epoch 48, batch 490, train_loss 0.700
epoch 48, batch 500, train_loss 0.707
epoch 48, batch 510, train_loss 0.685
epoch 48, batch 520, train_loss 0.679
epoch 48, batch 530, train_loss 0.696
epoch 48, batch 540, train_loss 0.700
epoch 48, batch 550, train_loss 0.697
epoch 48, batch 560, train_loss 0.689
epoch 48, batch 570, train_loss 0.693
epoch 48, batch 580, train_loss 0.683
epoch 48, batch 590, train_loss 0.691
epoch 48, batch 600, train_loss 0.694
epoch 48, batch 610, train_loss 0.698
epoch 48, batch 620, train_loss 0.693
epoch 48, batch 630, train_loss 0.693
epoch 48, batch 640, train_loss 0.693
epoch 48, batch 650, train_loss 0.706
epoch 48, batch 660, train_loss 0.691
epoch 48, batch 670, train_loss 0.697
epoch 48, batch 680, train_loss 0.692
epoch 48, batch 690, train_loss 0.700
epoch 48, batch 700, train_loss 0.692
epoch 48, batch 710, train_loss 0.691
epoch 48, batch 720, train_loss 0.694
epoch 48, batch 730, train_loss 0.681
epoch 48, batch 740, train_loss 0.697
epoch 48, batch 750, train_loss 0.701
epoch 48, batch 760, train_loss 0.698
epoch 48, batch 770, train_loss 0.696
epoch 48, batch 780, train_loss 0.687
epoch 48, batch 790, train_loss 0.688
epoch 48, batch 800, train_loss 0.686
epoch 48, batch 810, train_loss 0.695
epoch 48, batch 820, train_loss 0.686
epoch 48, batch 830, train_loss 0.686
epoch 48, batch 840, train_loss 0.695
epoch 48, batch 850, train_loss 0.694
epoch 48, batch 860, train_loss 0.701
epoch 48, batch 870, train_loss 0.690
epoch 48, batch 880, train_loss 0.683
epoch 48, batch 890, train_loss 0.679
epoch 48, batch 900, train_loss 0.690
epoch 48, batch 910, train_loss 0.696
epoch 48, batch 920, train_loss 0.691
epoch 48, batch 930, train_loss 0.693
epoch 48, batch 940, train_loss 0.687
epoch 48, batch 950, train_loss 0.687
epoch 48, batch 960, train_loss 0.698
epoch 48, batch 970, train_loss 0.692
epoch 48, batch 980, train_loss 0.705
epoch 48, batch 990, train_loss 0.700
epoch 48, batch 1000, train_loss 0.693
epoch 48, batch 1010, train_loss 0.682
epoch 48, batch 1020, train_loss 0.697
epoch 48, batch 1030, train_loss 0.702
epoch 48, batch 1040, train_loss 0.706
epoch 48, batch 1050, train_loss 0.693
epoch 48, batch 1060, train_loss 0.702
epoch 48, batch 1070, train_loss 0.694
epoch 48, batch 1080, train_loss 0.693
epoch 48, batch 1090, train_loss 0.688
epoch 48, batch 1100, train_loss 0.677
epoch 48, batch 1110, train_loss 0.697
epoch 48, batch 1120, train_loss 0.696
epoch 48, batch 1130, train_loss 0.696
epoch 48, batch 1140, train_loss 0.684
epoch 48, batch 1150, train_loss 0.690
epoch 48, batch 1160, train_loss 0.681
epoch 48, batch 1170, train_loss 0.686
epoch 48, batch 1180, train_loss 0.697
epoch 48, batch 1190, train_loss 0.692
epoch    48, train_loss 0.695, valid_loss 0.725, train_accuracy  70.14%, valid_accuracy  68.47%
epoch 49, batch 0, train_loss 0.689
epoch 49, batch 10, train_loss 0.694
epoch 49, batch 20, train_loss 0.691
epoch 49, batch 30, train_loss 0.702
epoch 49, batch 40, train_loss 0.692
epoch 49, batch 50, train_loss 0.691
epoch 49, batch 60, train_loss 0.686
epoch 49, batch 70, train_loss 0.696
epoch 49, batch 80, train_loss 0.688
epoch 49, batch 90, train_loss 0.695
epoch 49, batch 100, train_loss 0.698
epoch 49, batch 110, train_loss 0.710
epoch 49, batch 120, train_loss 0.694
epoch 49, batch 130, train_loss 0.695
epoch 49, batch 140, train_loss 0.697
epoch 49, batch 150, train_loss 0.690
epoch 49, batch 160, train_loss 0.697
epoch 49, batch 170, train_loss 0.693
epoch 49, batch 180, train_loss 0.698
epoch 49, batch 190, train_loss 0.691
epoch 49, batch 200, train_loss 0.694
epoch 49, batch 210, train_loss 0.699
epoch 49, batch 220, train_loss 0.706
epoch 49, batch 230, train_loss 0.691
epoch 49, batch 240, train_loss 0.699
epoch 49, batch 250, train_loss 0.700
epoch 49, batch 260, train_loss 0.686
epoch 49, batch 270, train_loss 0.697
epoch 49, batch 280, train_loss 0.693
epoch 49, batch 290, train_loss 0.694
epoch 49, batch 300, train_loss 0.699
epoch 49, batch 310, train_loss 0.696
epoch 49, batch 320, train_loss 0.694
epoch 49, batch 330, train_loss 0.693
epoch 49, batch 340, train_loss 0.694
epoch 49, batch 350, train_loss 0.690
epoch 49, batch 360, train_loss 0.689
epoch 49, batch 370, train_loss 0.704
epoch 49, batch 380, train_loss 0.695
epoch 49, batch 390, train_loss 0.696
epoch 49, batch 400, train_loss 0.703
epoch 49, batch 410, train_loss 0.699
epoch 49, batch 420, train_loss 0.691
epoch 49, batch 430, train_loss 0.692
epoch 49, batch 440, train_loss 0.702
epoch 49, batch 450, train_loss 0.695
epoch 49, batch 460, train_loss 0.686
epoch 49, batch 470, train_loss 0.702
epoch 49, batch 480, train_loss 0.696
epoch 49, batch 490, train_loss 0.701
epoch 49, batch 500, train_loss 0.689
epoch 49, batch 510, train_loss 0.688
epoch 49, batch 520, train_loss 0.692
epoch 49, batch 530, train_loss 0.691
epoch 49, batch 540, train_loss 0.692
epoch 49, batch 550, train_loss 0.685
epoch 49, batch 560, train_loss 0.697
epoch 49, batch 570, train_loss 0.699
epoch 49, batch 580, train_loss 0.698
epoch 49, batch 590, train_loss 0.692
epoch 49, batch 600, train_loss 0.688
epoch 49, batch 610, train_loss 0.690
epoch 49, batch 620, train_loss 0.692
epoch 49, batch 630, train_loss 0.698
epoch 49, batch 640, train_loss 0.693
epoch 49, batch 650, train_loss 0.685
epoch 49, batch 660, train_loss 0.698
epoch 49, batch 670, train_loss 0.697
epoch 49, batch 680, train_loss 0.697
epoch 49, batch 690, train_loss 0.701
epoch 49, batch 700, train_loss 0.689
epoch 49, batch 710, train_loss 0.693
epoch 49, batch 720, train_loss 0.705
epoch 49, batch 730, train_loss 0.689
epoch 49, batch 740, train_loss 0.701
epoch 49, batch 750, train_loss 0.698
epoch 49, batch 760, train_loss 0.705
epoch 49, batch 770, train_loss 0.698
epoch 49, batch 780, train_loss 0.704
epoch 49, batch 790, train_loss 0.688
epoch 49, batch 800, train_loss 0.689
epoch 49, batch 810, train_loss 0.683
epoch 49, batch 820, train_loss 0.698
epoch 49, batch 830, train_loss 0.697
epoch 49, batch 840, train_loss 0.683
epoch 49, batch 850, train_loss 0.689
epoch 49, batch 860, train_loss 0.684
epoch 49, batch 870, train_loss 0.699
epoch 49, batch 880, train_loss 0.690
epoch 49, batch 890, train_loss 0.687
epoch 49, batch 900, train_loss 0.695
epoch 49, batch 910, train_loss 0.697
epoch 49, batch 920, train_loss 0.695
epoch 49, batch 930, train_loss 0.690
epoch 49, batch 940, train_loss 0.683
epoch 49, batch 950, train_loss 0.694
epoch 49, batch 960, train_loss 0.695
epoch 49, batch 970, train_loss 0.691
epoch 49, batch 980, train_loss 0.697
epoch 49, batch 990, train_loss 0.696
epoch 49, batch 1000, train_loss 0.701
epoch 49, batch 1010, train_loss 0.701
epoch 49, batch 1020, train_loss 0.695
epoch 49, batch 1030, train_loss 0.690
epoch 49, batch 1040, train_loss 0.688
epoch 49, batch 1050, train_loss 0.692
epoch 49, batch 1060, train_loss 0.693
epoch 49, batch 1070, train_loss 0.697
epoch 49, batch 1080, train_loss 0.692
epoch 49, batch 1090, train_loss 0.685
epoch 49, batch 1100, train_loss 0.695
epoch 49, batch 1110, train_loss 0.691
epoch 49, batch 1120, train_loss 0.690
epoch 49, batch 1130, train_loss 0.684
epoch 49, batch 1140, train_loss 0.696
epoch 49, batch 1150, train_loss 0.691
epoch 49, batch 1160, train_loss 0.698
epoch 49, batch 1170, train_loss 0.690
epoch 49, batch 1180, train_loss 0.698
epoch 49, batch 1190, train_loss 0.697
epoch    49, train_loss 0.692, valid_loss 0.722, train_accuracy  70.26%, valid_accuracy  68.59%
</pre></div></div>
</div>
</section>
<section id="Plot-the-loss-and-accuracy-curves-during-training">
<h3>Plot the loss and accuracy curves during training<a class="headerlink" href="#Plot-the-loss-and-accuracy-curves-during-training" title="Link to this heading">#</a></h3>
<p>To visualize the training process, we plot the loss and accuracy curves during training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_loss_record</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;train_loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">valid_loss_record</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;valid_loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/homework_3-protein-secondary-structure-nn_script_homework_with_solutions_16_0.png" src="../../../_images/homework_3-protein-secondary-structure-nn_script_homework_with_solutions_16_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_accuracy_record</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;train_accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">valid_accuracy_record</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;valid_accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/homework_3-protein-secondary-structure-nn_script_homework_with_solutions_17_0.png" src="../../../_images/homework_3-protein-secondary-structure-nn_script_homework_with_solutions_17_0.png" />
</div>
</div>
<p><strong>Based on the loss and accuracy curves, answer the following question</strong>:</p>
<p>As the number of epochs increases, what happens to the loss and accuracy on the training and validation datasets? Why the behavior of the loss/accuracy curves is different on the training and validation datasets?</p>
<p><em>Your answer to the above question</em></p>
</section>
<section id="Save-the-model-with-the-highest-validation-accuracy">
<h3>Save the model with the highest validation accuracy<a class="headerlink" href="#Save-the-model-with-the-highest-validation-accuracy" title="Link to this heading">#</a></h3>
<p>To avoid overfitting, we save the model with the highest validation accuracy after each epoch.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## re-initialize the model</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNetwork</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>


<span class="c1">## initialize the optimizer</span>
<span class="c1">## the learning rate is set to 0.001</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">adamw</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">opt_state</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">eqx</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">eqx</span><span class="o">.</span><span class="n">is_array</span><span class="p">))</span>


<span class="c1">## you can change the number of epochs and batch size as needed</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">16</span>

<span class="n">highest_valid_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_xs</span><span class="p">))</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
    <span class="n">train_xs</span> <span class="o">=</span> <span class="n">train_xs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="n">train_ys</span> <span class="o">=</span> <span class="n">train_ys</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_xs</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>
    <span class="k">for</span> <span class="n">idx_batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
        <span class="n">start_idx</span> <span class="o">=</span> <span class="n">idx_batch</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="n">end_idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">batch_size</span>
        <span class="n">batch_xs</span> <span class="o">=</span> <span class="n">train_xs</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
        <span class="n">batch_ys</span> <span class="o">=</span> <span class="n">train_ys</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>

        <span class="n">model</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">,</span> <span class="n">loss_value</span> <span class="o">=</span> <span class="n">make_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch_xs</span><span class="p">,</span> <span class="n">batch_ys</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">idx_batch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="s2">5&gt;d</span><span class="si">}</span><span class="s2">, batch </span><span class="si">{</span><span class="n">idx_batch</span><span class="si">:</span><span class="s2">5&gt;d</span><span class="si">}</span><span class="s2">, train_loss </span><span class="si">{</span><span class="n">loss_value</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">compute_average_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_xs</span><span class="p">,</span> <span class="n">train_ys</span><span class="p">)</span>
    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_xs</span><span class="p">,</span> <span class="n">train_ys</span><span class="p">)</span>

    <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">compute_average_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_xs</span><span class="p">,</span> <span class="n">valid_ys</span><span class="p">)</span>
    <span class="n">valid_accuracy</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_xs</span><span class="p">,</span> <span class="n">valid_ys</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="s2">5&gt;d</span><span class="si">}</span><span class="s2">, train_loss </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">, valid_loss </span><span class="si">{</span><span class="n">valid_loss</span><span class="si">:</span><span class="s2">5.3f</span><span class="si">}</span><span class="s2">, train_accuracy </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s2">7.2%</span><span class="si">}</span><span class="s2">, valid_accuracy </span><span class="si">{</span><span class="n">valid_accuracy</span><span class="si">:</span><span class="s2">7.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">valid_accuracy</span> <span class="o">&gt;</span> <span class="n">highest_valid_accuracy</span><span class="p">:</span>
        <span class="n">highest_valid_accuracy</span> <span class="o">=</span> <span class="n">valid_accuracy</span>
        <span class="n">eqx</span><span class="o">.</span><span class="n">tree_serialise_leaves</span><span class="p">(</span><span class="s2">&quot;../output/model-with-highest-valid-accuracy.eqx&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;model saved with highest valid accuracy: </span><span class="si">{</span><span class="n">highest_valid_accuracy</span><span class="si">:</span><span class="s2">7.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
epoch 0, batch 0, train_loss 1.128
epoch 0, batch 10, train_loss 1.036
epoch 0, batch 20, train_loss 0.986
epoch 0, batch 30, train_loss 0.954
epoch 0, batch 40, train_loss 0.925
epoch 0, batch 50, train_loss 0.906
epoch 0, batch 60, train_loss 0.895
epoch 0, batch 70, train_loss 0.877
epoch 0, batch 80, train_loss 0.861
epoch 0, batch 90, train_loss 0.858
epoch 0, batch 100, train_loss 0.850
epoch 0, batch 110, train_loss 0.841
epoch 0, batch 120, train_loss 0.828
epoch 0, batch 130, train_loss 0.839
epoch 0, batch 140, train_loss 0.836
epoch 0, batch 150, train_loss 0.825
epoch 0, batch 160, train_loss 0.819
epoch 0, batch 170, train_loss 0.822
epoch 0, batch 180, train_loss 0.821
epoch 0, batch 190, train_loss 0.812
epoch 0, batch 200, train_loss 0.807
epoch 0, batch 210, train_loss 0.809
epoch 0, batch 220, train_loss 0.808
epoch 0, batch 230, train_loss 0.803
epoch 0, batch 240, train_loss 0.793
epoch 0, batch 250, train_loss 0.783
epoch 0, batch 260, train_loss 0.793
epoch 0, batch 270, train_loss 0.787
epoch 0, batch 280, train_loss 0.780
epoch 0, batch 290, train_loss 0.780
epoch 0, batch 300, train_loss 0.775
epoch 0, batch 310, train_loss 0.775
epoch 0, batch 320, train_loss 0.775
epoch 0, batch 330, train_loss 0.774
epoch 0, batch 340, train_loss 0.763
epoch 0, batch 350, train_loss 0.766
epoch 0, batch 360, train_loss 0.768
epoch 0, batch 370, train_loss 0.756
epoch 0, batch 380, train_loss 0.766
epoch 0, batch 390, train_loss 0.757
epoch 0, batch 400, train_loss 0.756
epoch 0, batch 410, train_loss 0.769
epoch 0, batch 420, train_loss 0.760
epoch 0, batch 430, train_loss 0.757
epoch 0, batch 440, train_loss 0.751
epoch 0, batch 450, train_loss 0.751
epoch 0, batch 460, train_loss 0.758
epoch 0, batch 470, train_loss 0.763
epoch 0, batch 480, train_loss 0.758
epoch 0, batch 490, train_loss 0.761
epoch 0, batch 500, train_loss 0.746
epoch 0, batch 510, train_loss 0.749
epoch 0, batch 520, train_loss 0.752
epoch 0, batch 530, train_loss 0.756
epoch 0, batch 540, train_loss 0.756
epoch 0, batch 550, train_loss 0.752
epoch 0, batch 560, train_loss 0.747
epoch 0, batch 570, train_loss 0.749
epoch 0, batch 580, train_loss 0.746
epoch 0, batch 590, train_loss 0.750
epoch 0, batch 600, train_loss 0.753
epoch 0, batch 610, train_loss 0.746
epoch 0, batch 620, train_loss 0.743
epoch 0, batch 630, train_loss 0.741
epoch 0, batch 640, train_loss 0.742
epoch 0, batch 650, train_loss 0.742
epoch 0, batch 660, train_loss 0.744
epoch 0, batch 670, train_loss 0.744
epoch 0, batch 680, train_loss 0.747
epoch 0, batch 690, train_loss 0.732
epoch 0, batch 700, train_loss 0.737
epoch 0, batch 710, train_loss 0.746
epoch 0, batch 720, train_loss 0.734
epoch 0, batch 730, train_loss 0.737
epoch 0, batch 740, train_loss 0.746
epoch 0, batch 750, train_loss 0.734
epoch 0, batch 760, train_loss 0.739
epoch 0, batch 770, train_loss 0.735
epoch 0, batch 780, train_loss 0.739
epoch 0, batch 790, train_loss 0.741
epoch 0, batch 800, train_loss 0.737
epoch 0, batch 810, train_loss 0.736
epoch 0, batch 820, train_loss 0.740
epoch 0, batch 830, train_loss 0.734
epoch 0, batch 840, train_loss 0.723
epoch 0, batch 850, train_loss 0.735
epoch 0, batch 860, train_loss 0.745
epoch 0, batch 870, train_loss 0.740
epoch 0, batch 880, train_loss 0.744
epoch 0, batch 890, train_loss 0.725
epoch 0, batch 900, train_loss 0.730
epoch 0, batch 910, train_loss 0.740
epoch 0, batch 920, train_loss 0.728
epoch 0, batch 930, train_loss 0.725
epoch 0, batch 940, train_loss 0.736
epoch 0, batch 950, train_loss 0.738
epoch 0, batch 960, train_loss 0.737
epoch 0, batch 970, train_loss 0.744
epoch 0, batch 980, train_loss 0.732
epoch 0, batch 990, train_loss 0.726
epoch 0, batch 1000, train_loss 0.715
epoch 0, batch 1010, train_loss 0.736
epoch 0, batch 1020, train_loss 0.725
epoch 0, batch 1030, train_loss 0.731
epoch 0, batch 1040, train_loss 0.728
epoch 0, batch 1050, train_loss 0.722
epoch 0, batch 1060, train_loss 0.735
epoch 0, batch 1070, train_loss 0.729
epoch 0, batch 1080, train_loss 0.738
epoch 0, batch 1090, train_loss 0.726
epoch 0, batch 1100, train_loss 0.729
epoch 0, batch 1110, train_loss 0.729
epoch 0, batch 1120, train_loss 0.737
epoch 0, batch 1130, train_loss 0.727
epoch 0, batch 1140, train_loss 0.742
epoch 0, batch 1150, train_loss 0.730
epoch 0, batch 1160, train_loss 0.735
epoch 0, batch 1170, train_loss 0.734
epoch 0, batch 1180, train_loss 0.735
epoch 0, batch 1190, train_loss 0.724
epoch 0, train_loss 0.729, valid_loss 0.740, train_accuracy  68.29%, valid_accuracy  67.68%
model saved with highest valid accuracy:  67.68%
epoch 1, batch 0, train_loss 0.728
epoch 1, batch 10, train_loss 0.726
epoch 1, batch 20, train_loss 0.720
epoch 1, batch 30, train_loss 0.732
epoch 1, batch 40, train_loss 0.720
epoch 1, batch 50, train_loss 0.734
epoch 1, batch 60, train_loss 0.729
epoch 1, batch 70, train_loss 0.735
epoch 1, batch 80, train_loss 0.728
epoch 1, batch 90, train_loss 0.733
epoch 1, batch 100, train_loss 0.719
epoch 1, batch 110, train_loss 0.738
epoch 1, batch 120, train_loss 0.726
epoch 1, batch 130, train_loss 0.730
epoch 1, batch 140, train_loss 0.737
epoch 1, batch 150, train_loss 0.730
epoch 1, batch 160, train_loss 0.715
epoch 1, batch 170, train_loss 0.726
epoch 1, batch 180, train_loss 0.728
epoch 1, batch 190, train_loss 0.723
epoch 1, batch 200, train_loss 0.730
epoch 1, batch 210, train_loss 0.728
epoch 1, batch 220, train_loss 0.721
epoch 1, batch 230, train_loss 0.727
epoch 1, batch 240, train_loss 0.729
epoch 1, batch 250, train_loss 0.729
epoch 1, batch 260, train_loss 0.732
epoch 1, batch 270, train_loss 0.728
epoch 1, batch 280, train_loss 0.722
epoch 1, batch 290, train_loss 0.720
epoch 1, batch 300, train_loss 0.720
epoch 1, batch 310, train_loss 0.721
epoch 1, batch 320, train_loss 0.713
epoch 1, batch 330, train_loss 0.717
epoch 1, batch 340, train_loss 0.710
epoch 1, batch 350, train_loss 0.727
epoch 1, batch 360, train_loss 0.733
epoch 1, batch 370, train_loss 0.725
epoch 1, batch 380, train_loss 0.712
epoch 1, batch 390, train_loss 0.723
epoch 1, batch 400, train_loss 0.722
epoch 1, batch 410, train_loss 0.720
epoch 1, batch 420, train_loss 0.724
epoch 1, batch 430, train_loss 0.724
epoch 1, batch 440, train_loss 0.716
epoch 1, batch 450, train_loss 0.715
epoch 1, batch 460, train_loss 0.730
epoch 1, batch 470, train_loss 0.719
epoch 1, batch 480, train_loss 0.726
epoch 1, batch 490, train_loss 0.732
epoch 1, batch 500, train_loss 0.723
epoch 1, batch 510, train_loss 0.721
epoch 1, batch 520, train_loss 0.721
epoch 1, batch 530, train_loss 0.727
epoch 1, batch 540, train_loss 0.726
epoch 1, batch 550, train_loss 0.713
epoch 1, batch 560, train_loss 0.724
epoch 1, batch 570, train_loss 0.723
epoch 1, batch 580, train_loss 0.718
epoch 1, batch 590, train_loss 0.716
epoch 1, batch 600, train_loss 0.726
epoch 1, batch 610, train_loss 0.725
epoch 1, batch 620, train_loss 0.716
epoch 1, batch 630, train_loss 0.728
epoch 1, batch 640, train_loss 0.717
epoch 1, batch 650, train_loss 0.720
epoch 1, batch 660, train_loss 0.725
epoch 1, batch 670, train_loss 0.724
epoch 1, batch 680, train_loss 0.719
epoch 1, batch 690, train_loss 0.726
epoch 1, batch 700, train_loss 0.716
epoch 1, batch 710, train_loss 0.718
epoch 1, batch 720, train_loss 0.715
epoch 1, batch 730, train_loss 0.717
epoch 1, batch 740, train_loss 0.719
epoch 1, batch 750, train_loss 0.728
epoch 1, batch 760, train_loss 0.725
epoch 1, batch 770, train_loss 0.715
epoch 1, batch 780, train_loss 0.725
epoch 1, batch 790, train_loss 0.721
epoch 1, batch 800, train_loss 0.717
epoch 1, batch 810, train_loss 0.716
epoch 1, batch 820, train_loss 0.716
epoch 1, batch 830, train_loss 0.729
epoch 1, batch 840, train_loss 0.707
epoch 1, batch 850, train_loss 0.722
epoch 1, batch 860, train_loss 0.710
epoch 1, batch 870, train_loss 0.714
epoch 1, batch 880, train_loss 0.728
epoch 1, batch 890, train_loss 0.720
epoch 1, batch 900, train_loss 0.724
epoch 1, batch 910, train_loss 0.716
epoch 1, batch 920, train_loss 0.723
epoch 1, batch 930, train_loss 0.717
epoch 1, batch 940, train_loss 0.708
epoch 1, batch 950, train_loss 0.725
epoch 1, batch 960, train_loss 0.715
epoch 1, batch 970, train_loss 0.721
epoch 1, batch 980, train_loss 0.714
epoch 1, batch 990, train_loss 0.726
epoch 1, batch 1000, train_loss 0.725
epoch 1, batch 1010, train_loss 0.711
epoch 1, batch 1020, train_loss 0.715
epoch 1, batch 1030, train_loss 0.716
epoch 1, batch 1040, train_loss 0.724
epoch 1, batch 1050, train_loss 0.716
epoch 1, batch 1060, train_loss 0.723
epoch 1, batch 1070, train_loss 0.729
epoch 1, batch 1080, train_loss 0.718
epoch 1, batch 1090, train_loss 0.713
epoch 1, batch 1100, train_loss 0.718
epoch 1, batch 1110, train_loss 0.718
epoch 1, batch 1120, train_loss 0.723
epoch 1, batch 1130, train_loss 0.726
epoch 1, batch 1140, train_loss 0.721
epoch 1, batch 1150, train_loss 0.708
epoch 1, batch 1160, train_loss 0.722
epoch 1, batch 1170, train_loss 0.719
epoch 1, batch 1180, train_loss 0.719
epoch 1, batch 1190, train_loss 0.718
epoch 1, train_loss 0.719, valid_loss 0.732, train_accuracy  68.81%, valid_accuracy  68.10%
model saved with highest valid accuracy:  68.10%
epoch 2, batch 0, train_loss 0.717
epoch 2, batch 10, train_loss 0.720
epoch 2, batch 20, train_loss 0.724
epoch 2, batch 30, train_loss 0.720
epoch 2, batch 40, train_loss 0.725
epoch 2, batch 50, train_loss 0.716
epoch 2, batch 60, train_loss 0.720
epoch 2, batch 70, train_loss 0.720
epoch 2, batch 80, train_loss 0.715
epoch 2, batch 90, train_loss 0.712
epoch 2, batch 100, train_loss 0.717
epoch 2, batch 110, train_loss 0.721
epoch 2, batch 120, train_loss 0.717
epoch 2, batch 130, train_loss 0.724
epoch 2, batch 140, train_loss 0.718
epoch 2, batch 150, train_loss 0.713
epoch 2, batch 160, train_loss 0.709
epoch 2, batch 170, train_loss 0.721
epoch 2, batch 180, train_loss 0.715
epoch 2, batch 190, train_loss 0.718
epoch 2, batch 200, train_loss 0.712
epoch 2, batch 210, train_loss 0.725
epoch 2, batch 220, train_loss 0.720
epoch 2, batch 230, train_loss 0.716
epoch 2, batch 240, train_loss 0.711
epoch 2, batch 250, train_loss 0.719
epoch 2, batch 260, train_loss 0.723
epoch 2, batch 270, train_loss 0.711
epoch 2, batch 280, train_loss 0.715
epoch 2, batch 290, train_loss 0.709
epoch 2, batch 300, train_loss 0.712
epoch 2, batch 310, train_loss 0.719
epoch 2, batch 320, train_loss 0.710
epoch 2, batch 330, train_loss 0.717
epoch 2, batch 340, train_loss 0.710
epoch 2, batch 350, train_loss 0.717
epoch 2, batch 360, train_loss 0.723
epoch 2, batch 370, train_loss 0.720
epoch 2, batch 380, train_loss 0.712
epoch 2, batch 390, train_loss 0.712
epoch 2, batch 400, train_loss 0.710
epoch 2, batch 410, train_loss 0.717
epoch 2, batch 420, train_loss 0.713
epoch 2, batch 430, train_loss 0.720
epoch 2, batch 440, train_loss 0.716
epoch 2, batch 450, train_loss 0.718
epoch 2, batch 460, train_loss 0.706
epoch 2, batch 470, train_loss 0.705
epoch 2, batch 480, train_loss 0.715
epoch 2, batch 490, train_loss 0.715
epoch 2, batch 500, train_loss 0.707
epoch 2, batch 510, train_loss 0.705
epoch 2, batch 520, train_loss 0.718
epoch 2, batch 530, train_loss 0.708
epoch 2, batch 540, train_loss 0.723
epoch 2, batch 550, train_loss 0.717
epoch 2, batch 560, train_loss 0.707
epoch 2, batch 570, train_loss 0.724
epoch 2, batch 580, train_loss 0.717
epoch 2, batch 590, train_loss 0.716
epoch 2, batch 600, train_loss 0.718
epoch 2, batch 610, train_loss 0.715
epoch 2, batch 620, train_loss 0.713
epoch 2, batch 630, train_loss 0.726
epoch 2, batch 640, train_loss 0.714
epoch 2, batch 650, train_loss 0.725
epoch 2, batch 660, train_loss 0.719
epoch 2, batch 670, train_loss 0.721
epoch 2, batch 680, train_loss 0.725
epoch 2, batch 690, train_loss 0.719
epoch 2, batch 700, train_loss 0.714
epoch 2, batch 710, train_loss 0.709
epoch 2, batch 720, train_loss 0.711
epoch 2, batch 730, train_loss 0.713
epoch 2, batch 740, train_loss 0.708
epoch 2, batch 750, train_loss 0.721
epoch 2, batch 760, train_loss 0.718
epoch 2, batch 770, train_loss 0.712
epoch 2, batch 780, train_loss 0.716
epoch 2, batch 790, train_loss 0.716
epoch 2, batch 800, train_loss 0.699
epoch 2, batch 810, train_loss 0.716
epoch 2, batch 820, train_loss 0.730
epoch 2, batch 830, train_loss 0.713
epoch 2, batch 840, train_loss 0.719
epoch 2, batch 850, train_loss 0.720
epoch 2, batch 860, train_loss 0.718
epoch 2, batch 870, train_loss 0.719
epoch 2, batch 880, train_loss 0.714
epoch 2, batch 890, train_loss 0.717
epoch 2, batch 900, train_loss 0.725
epoch 2, batch 910, train_loss 0.710
epoch 2, batch 920, train_loss 0.717
epoch 2, batch 930, train_loss 0.714
epoch 2, batch 940, train_loss 0.712
epoch 2, batch 950, train_loss 0.721
epoch 2, batch 960, train_loss 0.718
epoch 2, batch 970, train_loss 0.720
epoch 2, batch 980, train_loss 0.715
epoch 2, batch 990, train_loss 0.722
epoch 2, batch 1000, train_loss 0.713
epoch 2, batch 1010, train_loss 0.711
epoch 2, batch 1020, train_loss 0.705
epoch 2, batch 1030, train_loss 0.721
epoch 2, batch 1040, train_loss 0.722
epoch 2, batch 1050, train_loss 0.716
epoch 2, batch 1060, train_loss 0.718
epoch 2, batch 1070, train_loss 0.711
epoch 2, batch 1080, train_loss 0.713
epoch 2, batch 1090, train_loss 0.726
epoch 2, batch 1100, train_loss 0.711
epoch 2, batch 1110, train_loss 0.713
epoch 2, batch 1120, train_loss 0.723
epoch 2, batch 1130, train_loss 0.713
epoch 2, batch 1140, train_loss 0.698
epoch 2, batch 1150, train_loss 0.718
epoch 2, batch 1160, train_loss 0.713
epoch 2, batch 1170, train_loss 0.710
epoch 2, batch 1180, train_loss 0.713
epoch 2, batch 1190, train_loss 0.717
epoch 2, train_loss 0.712, valid_loss 0.727, train_accuracy  69.18%, valid_accuracy  68.42%
model saved with highest valid accuracy:  68.42%
epoch 3, batch 0, train_loss 0.718
epoch 3, batch 10, train_loss 0.716
epoch 3, batch 20, train_loss 0.706
epoch 3, batch 30, train_loss 0.701
epoch 3, batch 40, train_loss 0.709
epoch 3, batch 50, train_loss 0.711
epoch 3, batch 60, train_loss 0.720
epoch 3, batch 70, train_loss 0.717
epoch 3, batch 80, train_loss 0.714
epoch 3, batch 90, train_loss 0.706
epoch 3, batch 100, train_loss 0.711
epoch 3, batch 110, train_loss 0.706
epoch 3, batch 120, train_loss 0.719
epoch 3, batch 130, train_loss 0.714
epoch 3, batch 140, train_loss 0.713
epoch 3, batch 150, train_loss 0.711
epoch 3, batch 160, train_loss 0.709
epoch 3, batch 170, train_loss 0.710
epoch 3, batch 180, train_loss 0.706
epoch 3, batch 190, train_loss 0.709
epoch 3, batch 200, train_loss 0.706
epoch 3, batch 210, train_loss 0.717
epoch 3, batch 220, train_loss 0.709
epoch 3, batch 230, train_loss 0.714
epoch 3, batch 240, train_loss 0.718
epoch 3, batch 250, train_loss 0.708
epoch 3, batch 260, train_loss 0.708
epoch 3, batch 270, train_loss 0.708
epoch 3, batch 280, train_loss 0.706
epoch 3, batch 290, train_loss 0.717
epoch 3, batch 300, train_loss 0.708
epoch 3, batch 310, train_loss 0.705
epoch 3, batch 320, train_loss 0.710
epoch 3, batch 330, train_loss 0.711
epoch 3, batch 340, train_loss 0.705
epoch 3, batch 350, train_loss 0.709
epoch 3, batch 360, train_loss 0.711
epoch 3, batch 370, train_loss 0.710
epoch 3, batch 380, train_loss 0.709
epoch 3, batch 390, train_loss 0.713
epoch 3, batch 400, train_loss 0.710
epoch 3, batch 410, train_loss 0.716
epoch 3, batch 420, train_loss 0.710
epoch 3, batch 430, train_loss 0.709
epoch 3, batch 440, train_loss 0.714
epoch 3, batch 450, train_loss 0.718
epoch 3, batch 460, train_loss 0.702
epoch 3, batch 470, train_loss 0.704
epoch 3, batch 480, train_loss 0.704
epoch 3, batch 490, train_loss 0.716
epoch 3, batch 500, train_loss 0.704
epoch 3, batch 510, train_loss 0.704
epoch 3, batch 520, train_loss 0.707
epoch 3, batch 530, train_loss 0.721
epoch 3, batch 540, train_loss 0.713
epoch 3, batch 550, train_loss 0.704
epoch 3, batch 560, train_loss 0.721
epoch 3, batch 570, train_loss 0.705
epoch 3, batch 580, train_loss 0.713
epoch 3, batch 590, train_loss 0.707
epoch 3, batch 600, train_loss 0.713
epoch 3, batch 610, train_loss 0.717
epoch 3, batch 620, train_loss 0.702
epoch 3, batch 630, train_loss 0.713
epoch 3, batch 640, train_loss 0.710
epoch 3, batch 650, train_loss 0.715
epoch 3, batch 660, train_loss 0.711
epoch 3, batch 670, train_loss 0.701
epoch 3, batch 680, train_loss 0.705
epoch 3, batch 690, train_loss 0.708
epoch 3, batch 700, train_loss 0.707
epoch 3, batch 710, train_loss 0.709
epoch 3, batch 720, train_loss 0.711
epoch 3, batch 730, train_loss 0.708
epoch 3, batch 740, train_loss 0.710
epoch 3, batch 750, train_loss 0.709
epoch 3, batch 760, train_loss 0.701
epoch 3, batch 770, train_loss 0.712
epoch 3, batch 780, train_loss 0.711
epoch 3, batch 790, train_loss 0.709
epoch 3, batch 800, train_loss 0.721
epoch 3, batch 810, train_loss 0.714
epoch 3, batch 820, train_loss 0.720
epoch 3, batch 830, train_loss 0.711
epoch 3, batch 840, train_loss 0.711
epoch 3, batch 850, train_loss 0.707
epoch 3, batch 860, train_loss 0.716
epoch 3, batch 870, train_loss 0.710
epoch 3, batch 880, train_loss 0.716
epoch 3, batch 890, train_loss 0.715
epoch 3, batch 900, train_loss 0.709
epoch 3, batch 910, train_loss 0.710
epoch 3, batch 920, train_loss 0.705
epoch 3, batch 930, train_loss 0.712
epoch 3, batch 940, train_loss 0.707
epoch 3, batch 950, train_loss 0.711
epoch 3, batch 960, train_loss 0.709
epoch 3, batch 970, train_loss 0.708
epoch 3, batch 980, train_loss 0.709
epoch 3, batch 990, train_loss 0.715
epoch 3, batch 1000, train_loss 0.715
epoch 3, batch 1010, train_loss 0.717
epoch 3, batch 1020, train_loss 0.715
epoch 3, batch 1030, train_loss 0.707
epoch 3, batch 1040, train_loss 0.716
epoch 3, batch 1050, train_loss 0.715
epoch 3, batch 1060, train_loss 0.710
epoch 3, batch 1070, train_loss 0.711
epoch 3, batch 1080, train_loss 0.711
epoch 3, batch 1090, train_loss 0.718
epoch 3, batch 1100, train_loss 0.706
epoch 3, batch 1110, train_loss 0.711
epoch 3, batch 1120, train_loss 0.703
epoch 3, batch 1130, train_loss 0.707
epoch 3, batch 1140, train_loss 0.721
epoch 3, batch 1150, train_loss 0.700
epoch 3, batch 1160, train_loss 0.708
epoch 3, batch 1170, train_loss 0.712
epoch 3, batch 1180, train_loss 0.704
epoch 3, batch 1190, train_loss 0.704
epoch 3, train_loss 0.709, valid_loss 0.725, train_accuracy  69.34%, valid_accuracy  68.49%
model saved with highest valid accuracy:  68.49%
epoch 4, batch 0, train_loss 0.705
epoch 4, batch 10, train_loss 0.713
epoch 4, batch 20, train_loss 0.706
epoch 4, batch 30, train_loss 0.713
epoch 4, batch 40, train_loss 0.713
epoch 4, batch 50, train_loss 0.700
epoch 4, batch 60, train_loss 0.709
epoch 4, batch 70, train_loss 0.711
epoch 4, batch 80, train_loss 0.705
epoch 4, batch 90, train_loss 0.713
epoch 4, batch 100, train_loss 0.714
epoch 4, batch 110, train_loss 0.706
epoch 4, batch 120, train_loss 0.711
epoch 4, batch 130, train_loss 0.707
epoch 4, batch 140, train_loss 0.705
epoch 4, batch 150, train_loss 0.709
epoch 4, batch 160, train_loss 0.707
epoch 4, batch 170, train_loss 0.702
epoch 4, batch 180, train_loss 0.713
epoch 4, batch 190, train_loss 0.711
epoch 4, batch 200, train_loss 0.717
epoch 4, batch 210, train_loss 0.709
epoch 4, batch 220, train_loss 0.708
epoch 4, batch 230, train_loss 0.708
epoch 4, batch 240, train_loss 0.709
epoch 4, batch 250, train_loss 0.707
epoch 4, batch 260, train_loss 0.711
epoch 4, batch 270, train_loss 0.705
epoch 4, batch 280, train_loss 0.712
epoch 4, batch 290, train_loss 0.697
epoch 4, batch 300, train_loss 0.696
epoch 4, batch 310, train_loss 0.712
epoch 4, batch 320, train_loss 0.704
epoch 4, batch 330, train_loss 0.709
epoch 4, batch 340, train_loss 0.701
epoch 4, batch 350, train_loss 0.699
epoch 4, batch 360, train_loss 0.708
epoch 4, batch 370, train_loss 0.709
epoch 4, batch 380, train_loss 0.710
epoch 4, batch 390, train_loss 0.706
epoch 4, batch 400, train_loss 0.722
epoch 4, batch 410, train_loss 0.709
epoch 4, batch 420, train_loss 0.701
epoch 4, batch 430, train_loss 0.706
epoch 4, batch 440, train_loss 0.718
epoch 4, batch 450, train_loss 0.708
epoch 4, batch 460, train_loss 0.713
epoch 4, batch 470, train_loss 0.716
epoch 4, batch 480, train_loss 0.714
epoch 4, batch 490, train_loss 0.701
epoch 4, batch 500, train_loss 0.701
epoch 4, batch 510, train_loss 0.721
epoch 4, batch 520, train_loss 0.700
epoch 4, batch 530, train_loss 0.713
epoch 4, batch 540, train_loss 0.701
epoch 4, batch 550, train_loss 0.704
epoch 4, batch 560, train_loss 0.703
epoch 4, batch 570, train_loss 0.710
epoch 4, batch 580, train_loss 0.705
epoch 4, batch 590, train_loss 0.711
epoch 4, batch 600, train_loss 0.707
epoch 4, batch 610, train_loss 0.717
epoch 4, batch 620, train_loss 0.710
epoch 4, batch 630, train_loss 0.715
epoch 4, batch 640, train_loss 0.711
epoch 4, batch 650, train_loss 0.699
epoch 4, batch 660, train_loss 0.711
epoch 4, batch 670, train_loss 0.706
epoch 4, batch 680, train_loss 0.706
epoch 4, batch 690, train_loss 0.711
epoch 4, batch 700, train_loss 0.708
epoch 4, batch 710, train_loss 0.709
epoch 4, batch 720, train_loss 0.704
epoch 4, batch 730, train_loss 0.705
epoch 4, batch 740, train_loss 0.701
epoch 4, batch 750, train_loss 0.711
epoch 4, batch 760, train_loss 0.706
epoch 4, batch 770, train_loss 0.712
epoch 4, batch 780, train_loss 0.708
epoch 4, batch 790, train_loss 0.711
epoch 4, batch 800, train_loss 0.704
epoch 4, batch 810, train_loss 0.695
epoch 4, batch 820, train_loss 0.703
epoch 4, batch 830, train_loss 0.707
epoch 4, batch 840, train_loss 0.709
epoch 4, batch 850, train_loss 0.703
epoch 4, batch 860, train_loss 0.710
epoch 4, batch 870, train_loss 0.708
epoch 4, batch 880, train_loss 0.705
epoch 4, batch 890, train_loss 0.704
epoch 4, batch 900, train_loss 0.718
epoch 4, batch 910, train_loss 0.713
epoch 4, batch 920, train_loss 0.705
epoch 4, batch 930, train_loss 0.705
epoch 4, batch 940, train_loss 0.713
epoch 4, batch 950, train_loss 0.697
epoch 4, batch 960, train_loss 0.711
epoch 4, batch 970, train_loss 0.713
epoch 4, batch 980, train_loss 0.710
epoch 4, batch 990, train_loss 0.710
epoch 4, batch 1000, train_loss 0.708
epoch 4, batch 1010, train_loss 0.704
epoch 4, batch 1020, train_loss 0.716
epoch 4, batch 1030, train_loss 0.702
epoch 4, batch 1040, train_loss 0.709
epoch 4, batch 1050, train_loss 0.713
epoch 4, batch 1060, train_loss 0.706
epoch 4, batch 1070, train_loss 0.707
epoch 4, batch 1080, train_loss 0.714
epoch 4, batch 1090, train_loss 0.712
epoch 4, batch 1100, train_loss 0.714
epoch 4, batch 1110, train_loss 0.700
epoch 4, batch 1120, train_loss 0.693
epoch 4, batch 1130, train_loss 0.704
epoch 4, batch 1140, train_loss 0.699
epoch 4, batch 1150, train_loss 0.717
epoch 4, batch 1160, train_loss 0.709
epoch 4, batch 1170, train_loss 0.701
epoch 4, batch 1180, train_loss 0.714
epoch 4, batch 1190, train_loss 0.710
epoch 4, train_loss 0.707, valid_loss 0.724, train_accuracy  69.43%, valid_accuracy  68.52%
model saved with highest valid accuracy:  68.52%
epoch 5, batch 0, train_loss 0.697
epoch 5, batch 10, train_loss 0.705
epoch 5, batch 20, train_loss 0.710
epoch 5, batch 30, train_loss 0.715
epoch 5, batch 40, train_loss 0.718
epoch 5, batch 50, train_loss 0.710
epoch 5, batch 60, train_loss 0.712
epoch 5, batch 70, train_loss 0.714
epoch 5, batch 80, train_loss 0.706
epoch 5, batch 90, train_loss 0.716
epoch 5, batch 100, train_loss 0.703
epoch 5, batch 110, train_loss 0.709
epoch 5, batch 120, train_loss 0.712
epoch 5, batch 130, train_loss 0.710
epoch 5, batch 140, train_loss 0.716
epoch 5, batch 150, train_loss 0.708
epoch 5, batch 160, train_loss 0.704
epoch 5, batch 170, train_loss 0.703
epoch 5, batch 180, train_loss 0.712
epoch 5, batch 190, train_loss 0.706
epoch 5, batch 200, train_loss 0.703
epoch 5, batch 210, train_loss 0.714
epoch 5, batch 220, train_loss 0.703
epoch 5, batch 230, train_loss 0.705
epoch 5, batch 240, train_loss 0.716
epoch 5, batch 250, train_loss 0.716
epoch 5, batch 260, train_loss 0.706
epoch 5, batch 270, train_loss 0.713
epoch 5, batch 280, train_loss 0.702
epoch 5, batch 290, train_loss 0.714
epoch 5, batch 300, train_loss 0.709
epoch 5, batch 310, train_loss 0.709
epoch 5, batch 320, train_loss 0.708
epoch 5, batch 330, train_loss 0.700
epoch 5, batch 340, train_loss 0.708
epoch 5, batch 350, train_loss 0.713
epoch 5, batch 360, train_loss 0.716
epoch 5, batch 370, train_loss 0.707
epoch 5, batch 380, train_loss 0.711
epoch 5, batch 390, train_loss 0.697
epoch 5, batch 400, train_loss 0.710
epoch 5, batch 410, train_loss 0.711
epoch 5, batch 420, train_loss 0.708
epoch 5, batch 430, train_loss 0.707
epoch 5, batch 440, train_loss 0.708
epoch 5, batch 450, train_loss 0.712
epoch 5, batch 460, train_loss 0.710
epoch 5, batch 470, train_loss 0.694
epoch 5, batch 480, train_loss 0.704
epoch 5, batch 490, train_loss 0.703
epoch 5, batch 500, train_loss 0.706
epoch 5, batch 510, train_loss 0.694
epoch 5, batch 520, train_loss 0.721
epoch 5, batch 530, train_loss 0.710
epoch 5, batch 540, train_loss 0.706
epoch 5, batch 550, train_loss 0.705
epoch 5, batch 560, train_loss 0.695
epoch 5, batch 570, train_loss 0.712
epoch 5, batch 580, train_loss 0.703
epoch 5, batch 590, train_loss 0.703
epoch 5, batch 600, train_loss 0.706
epoch 5, batch 610, train_loss 0.705
epoch 5, batch 620, train_loss 0.720
epoch 5, batch 630, train_loss 0.707
epoch 5, batch 640, train_loss 0.703
epoch 5, batch 650, train_loss 0.714
epoch 5, batch 660, train_loss 0.702
epoch 5, batch 670, train_loss 0.701
epoch 5, batch 680, train_loss 0.703
epoch 5, batch 690, train_loss 0.715
epoch 5, batch 700, train_loss 0.698
epoch 5, batch 710, train_loss 0.704
epoch 5, batch 720, train_loss 0.706
epoch 5, batch 730, train_loss 0.713
epoch 5, batch 740, train_loss 0.702
epoch 5, batch 750, train_loss 0.710
epoch 5, batch 760, train_loss 0.715
epoch 5, batch 770, train_loss 0.707
epoch 5, batch 780, train_loss 0.702
epoch 5, batch 790, train_loss 0.706
epoch 5, batch 800, train_loss 0.708
epoch 5, batch 810, train_loss 0.704
epoch 5, batch 820, train_loss 0.716
epoch 5, batch 830, train_loss 0.705
epoch 5, batch 840, train_loss 0.712
epoch 5, batch 850, train_loss 0.718
epoch 5, batch 860, train_loss 0.695
epoch 5, batch 870, train_loss 0.706
epoch 5, batch 880, train_loss 0.707
epoch 5, batch 890, train_loss 0.711
epoch 5, batch 900, train_loss 0.714
epoch 5, batch 910, train_loss 0.697
epoch 5, batch 920, train_loss 0.705
epoch 5, batch 930, train_loss 0.707
epoch 5, batch 940, train_loss 0.712
epoch 5, batch 950, train_loss 0.699
epoch 5, batch 960, train_loss 0.709
epoch 5, batch 970, train_loss 0.710
epoch 5, batch 980, train_loss 0.712
epoch 5, batch 990, train_loss 0.713
epoch 5, batch 1000, train_loss 0.713
epoch 5, batch 1010, train_loss 0.701
epoch 5, batch 1020, train_loss 0.708
epoch 5, batch 1030, train_loss 0.698
epoch 5, batch 1040, train_loss 0.713
epoch 5, batch 1050, train_loss 0.699
epoch 5, batch 1060, train_loss 0.707
epoch 5, batch 1070, train_loss 0.703
epoch 5, batch 1080, train_loss 0.709
epoch 5, batch 1090, train_loss 0.704
epoch 5, batch 1100, train_loss 0.715
epoch 5, batch 1110, train_loss 0.706
epoch 5, batch 1120, train_loss 0.710
epoch 5, batch 1130, train_loss 0.703
epoch 5, batch 1140, train_loss 0.707
epoch 5, batch 1150, train_loss 0.709
epoch 5, batch 1160, train_loss 0.704
epoch 5, batch 1170, train_loss 0.699
epoch 5, batch 1180, train_loss 0.702
epoch 5, batch 1190, train_loss 0.703
epoch 5, train_loss 0.706, valid_loss 0.724, train_accuracy  69.48%, valid_accuracy  68.51%
epoch 6, batch 0, train_loss 0.704
epoch 6, batch 10, train_loss 0.713
epoch 6, batch 20, train_loss 0.708
epoch 6, batch 30, train_loss 0.701
epoch 6, batch 40, train_loss 0.702
epoch 6, batch 50, train_loss 0.708
epoch 6, batch 60, train_loss 0.699
epoch 6, batch 70, train_loss 0.703
epoch 6, batch 80, train_loss 0.704
epoch 6, batch 90, train_loss 0.704
epoch 6, batch 100, train_loss 0.704
epoch 6, batch 110, train_loss 0.708
epoch 6, batch 120, train_loss 0.709
epoch 6, batch 130, train_loss 0.700
epoch 6, batch 140, train_loss 0.707
epoch 6, batch 150, train_loss 0.707
epoch 6, batch 160, train_loss 0.709
epoch 6, batch 170, train_loss 0.703
epoch 6, batch 180, train_loss 0.706
epoch 6, batch 190, train_loss 0.706
epoch 6, batch 200, train_loss 0.710
epoch 6, batch 210, train_loss 0.698
epoch 6, batch 220, train_loss 0.705
epoch 6, batch 230, train_loss 0.709
epoch 6, batch 240, train_loss 0.707
epoch 6, batch 250, train_loss 0.701
epoch 6, batch 260, train_loss 0.703
epoch 6, batch 270, train_loss 0.711
epoch 6, batch 280, train_loss 0.710
epoch 6, batch 290, train_loss 0.709
epoch 6, batch 300, train_loss 0.700
epoch 6, batch 310, train_loss 0.710
epoch 6, batch 320, train_loss 0.702
epoch 6, batch 330, train_loss 0.712
epoch 6, batch 340, train_loss 0.713
epoch 6, batch 350, train_loss 0.697
epoch 6, batch 360, train_loss 0.708
epoch 6, batch 370, train_loss 0.713
epoch 6, batch 380, train_loss 0.705
epoch 6, batch 390, train_loss 0.708
epoch 6, batch 400, train_loss 0.715
epoch 6, batch 410, train_loss 0.710
epoch 6, batch 420, train_loss 0.707
epoch 6, batch 430, train_loss 0.703
epoch 6, batch 440, train_loss 0.708
epoch 6, batch 450, train_loss 0.707
epoch 6, batch 460, train_loss 0.704
epoch 6, batch 470, train_loss 0.705
epoch 6, batch 480, train_loss 0.691
epoch 6, batch 490, train_loss 0.708
epoch 6, batch 500, train_loss 0.704
epoch 6, batch 510, train_loss 0.701
epoch 6, batch 520, train_loss 0.710
epoch 6, batch 530, train_loss 0.697
epoch 6, batch 540, train_loss 0.701
epoch 6, batch 550, train_loss 0.705
epoch 6, batch 560, train_loss 0.706
epoch 6, batch 570, train_loss 0.703
epoch 6, batch 580, train_loss 0.709
epoch 6, batch 590, train_loss 0.700
epoch 6, batch 600, train_loss 0.717
epoch 6, batch 610, train_loss 0.714
epoch 6, batch 620, train_loss 0.705
epoch 6, batch 630, train_loss 0.711
epoch 6, batch 640, train_loss 0.715
epoch 6, batch 650, train_loss 0.699
epoch 6, batch 660, train_loss 0.707
epoch 6, batch 670, train_loss 0.705
epoch 6, batch 680, train_loss 0.701
epoch 6, batch 690, train_loss 0.712
epoch 6, batch 700, train_loss 0.705
epoch 6, batch 710, train_loss 0.711
epoch 6, batch 720, train_loss 0.716
epoch 6, batch 730, train_loss 0.701
epoch 6, batch 740, train_loss 0.707
epoch 6, batch 750, train_loss 0.697
epoch 6, batch 760, train_loss 0.715
epoch 6, batch 770, train_loss 0.697
epoch 6, batch 780, train_loss 0.709
epoch 6, batch 790, train_loss 0.704
epoch 6, batch 800, train_loss 0.700
epoch 6, batch 810, train_loss 0.715
epoch 6, batch 820, train_loss 0.709
epoch 6, batch 830, train_loss 0.696
epoch 6, batch 840, train_loss 0.706
epoch 6, batch 850, train_loss 0.701
epoch 6, batch 860, train_loss 0.703
epoch 6, batch 870, train_loss 0.702
epoch 6, batch 880, train_loss 0.698
epoch 6, batch 890, train_loss 0.703
epoch 6, batch 900, train_loss 0.705
epoch 6, batch 910, train_loss 0.704
epoch 6, batch 920, train_loss 0.703
epoch 6, batch 930, train_loss 0.713
epoch 6, batch 940, train_loss 0.694
epoch 6, batch 950, train_loss 0.703
epoch 6, batch 960, train_loss 0.712
epoch 6, batch 970, train_loss 0.712
epoch 6, batch 980, train_loss 0.714
epoch 6, batch 990, train_loss 0.711
epoch 6, batch 1000, train_loss 0.698
epoch 6, batch 1010, train_loss 0.706
epoch 6, batch 1020, train_loss 0.713
epoch 6, batch 1030, train_loss 0.693
epoch 6, batch 1040, train_loss 0.705
epoch 6, batch 1050, train_loss 0.691
epoch 6, batch 1060, train_loss 0.697
epoch 6, batch 1070, train_loss 0.698
epoch 6, batch 1080, train_loss 0.699
epoch 6, batch 1090, train_loss 0.692
epoch 6, batch 1100, train_loss 0.698
epoch 6, batch 1110, train_loss 0.701
epoch 6, batch 1120, train_loss 0.703
epoch 6, batch 1130, train_loss 0.711
epoch 6, batch 1140, train_loss 0.699
epoch 6, batch 1150, train_loss 0.709
epoch 6, batch 1160, train_loss 0.702
epoch 6, batch 1170, train_loss 0.699
epoch 6, batch 1180, train_loss 0.704
epoch 6, batch 1190, train_loss 0.698
epoch 6, train_loss 0.704, valid_loss 0.723, train_accuracy  69.57%, valid_accuracy  68.53%
model saved with highest valid accuracy:  68.53%
epoch 7, batch 0, train_loss 0.700
epoch 7, batch 10, train_loss 0.703
epoch 7, batch 20, train_loss 0.708
epoch 7, batch 30, train_loss 0.712
epoch 7, batch 40, train_loss 0.708
epoch 7, batch 50, train_loss 0.705
epoch 7, batch 60, train_loss 0.699
epoch 7, batch 70, train_loss 0.706
epoch 7, batch 80, train_loss 0.709
epoch 7, batch 90, train_loss 0.702
epoch 7, batch 100, train_loss 0.708
epoch 7, batch 110, train_loss 0.697
epoch 7, batch 120, train_loss 0.712
epoch 7, batch 130, train_loss 0.714
epoch 7, batch 140, train_loss 0.702
epoch 7, batch 150, train_loss 0.697
epoch 7, batch 160, train_loss 0.708
epoch 7, batch 170, train_loss 0.705
epoch 7, batch 180, train_loss 0.702
epoch 7, batch 190, train_loss 0.706
epoch 7, batch 200, train_loss 0.698
epoch 7, batch 210, train_loss 0.707
epoch 7, batch 220, train_loss 0.705
epoch 7, batch 230, train_loss 0.699
epoch 7, batch 240, train_loss 0.696
epoch 7, batch 250, train_loss 0.705
epoch 7, batch 260, train_loss 0.701
epoch 7, batch 270, train_loss 0.702
epoch 7, batch 280, train_loss 0.700
epoch 7, batch 290, train_loss 0.704
epoch 7, batch 300, train_loss 0.705
epoch 7, batch 310, train_loss 0.696
epoch 7, batch 320, train_loss 0.706
epoch 7, batch 330, train_loss 0.700
epoch 7, batch 340, train_loss 0.698
epoch 7, batch 350, train_loss 0.713
epoch 7, batch 360, train_loss 0.712
epoch 7, batch 370, train_loss 0.701
epoch 7, batch 380, train_loss 0.700
epoch 7, batch 390, train_loss 0.705
epoch 7, batch 400, train_loss 0.706
epoch 7, batch 410, train_loss 0.706
epoch 7, batch 420, train_loss 0.710
epoch 7, batch 430, train_loss 0.705
epoch 7, batch 440, train_loss 0.704
epoch 7, batch 450, train_loss 0.707
epoch 7, batch 460, train_loss 0.700
epoch 7, batch 470, train_loss 0.707
epoch 7, batch 480, train_loss 0.698
epoch 7, batch 490, train_loss 0.705
epoch 7, batch 500, train_loss 0.703
epoch 7, batch 510, train_loss 0.706
epoch 7, batch 520, train_loss 0.709
epoch 7, batch 530, train_loss 0.702
epoch 7, batch 540, train_loss 0.702
epoch 7, batch 550, train_loss 0.706
epoch 7, batch 560, train_loss 0.697
epoch 7, batch 570, train_loss 0.710
epoch 7, batch 580, train_loss 0.700
epoch 7, batch 590, train_loss 0.707
epoch 7, batch 600, train_loss 0.701
epoch 7, batch 610, train_loss 0.715
epoch 7, batch 620, train_loss 0.705
epoch 7, batch 630, train_loss 0.700
epoch 7, batch 640, train_loss 0.697
epoch 7, batch 650, train_loss 0.703
epoch 7, batch 660, train_loss 0.703
epoch 7, batch 670, train_loss 0.695
epoch 7, batch 680, train_loss 0.705
epoch 7, batch 690, train_loss 0.701
epoch 7, batch 700, train_loss 0.700
epoch 7, batch 710, train_loss 0.709
epoch 7, batch 720, train_loss 0.705
epoch 7, batch 730, train_loss 0.699
epoch 7, batch 740, train_loss 0.696
epoch 7, batch 750, train_loss 0.693
epoch 7, batch 760, train_loss 0.705
epoch 7, batch 770, train_loss 0.702
epoch 7, batch 780, train_loss 0.705
epoch 7, batch 790, train_loss 0.707
epoch 7, batch 800, train_loss 0.706
epoch 7, batch 810, train_loss 0.701
epoch 7, batch 820, train_loss 0.711
epoch 7, batch 830, train_loss 0.704
epoch 7, batch 840, train_loss 0.703
epoch 7, batch 850, train_loss 0.704
epoch 7, batch 860, train_loss 0.709
epoch 7, batch 870, train_loss 0.703
epoch 7, batch 880, train_loss 0.705
epoch 7, batch 890, train_loss 0.706
epoch 7, batch 900, train_loss 0.704
epoch 7, batch 910, train_loss 0.705
epoch 7, batch 920, train_loss 0.700
epoch 7, batch 930, train_loss 0.702
epoch 7, batch 940, train_loss 0.708
epoch 7, batch 950, train_loss 0.702
epoch 7, batch 960, train_loss 0.701
epoch 7, batch 970, train_loss 0.701
epoch 7, batch 980, train_loss 0.705
epoch 7, batch 990, train_loss 0.706
epoch 7, batch 1000, train_loss 0.704
epoch 7, batch 1010, train_loss 0.707
epoch 7, batch 1020, train_loss 0.707
epoch 7, batch 1030, train_loss 0.706
epoch 7, batch 1040, train_loss 0.695
epoch 7, batch 1050, train_loss 0.698
epoch 7, batch 1060, train_loss 0.706
epoch 7, batch 1070, train_loss 0.700
epoch 7, batch 1080, train_loss 0.716
epoch 7, batch 1090, train_loss 0.699
epoch 7, batch 1100, train_loss 0.707
epoch 7, batch 1110, train_loss 0.698
epoch 7, batch 1120, train_loss 0.703
epoch 7, batch 1130, train_loss 0.699
epoch 7, batch 1140, train_loss 0.698
epoch 7, batch 1150, train_loss 0.715
epoch 7, batch 1160, train_loss 0.699
epoch 7, batch 1170, train_loss 0.702
epoch 7, batch 1180, train_loss 0.703
epoch 7, batch 1190, train_loss 0.708
epoch 7, train_loss 0.702, valid_loss 0.722, train_accuracy  69.67%, valid_accuracy  68.58%
model saved with highest valid accuracy:  68.58%
epoch 8, batch 0, train_loss 0.710
epoch 8, batch 10, train_loss 0.708
epoch 8, batch 20, train_loss 0.704
epoch 8, batch 30, train_loss 0.704
epoch 8, batch 40, train_loss 0.700
epoch 8, batch 50, train_loss 0.700
epoch 8, batch 60, train_loss 0.704
epoch 8, batch 70, train_loss 0.706
epoch 8, batch 80, train_loss 0.701
epoch 8, batch 90, train_loss 0.708
epoch 8, batch 100, train_loss 0.705
epoch 8, batch 110, train_loss 0.695
epoch 8, batch 120, train_loss 0.696
epoch 8, batch 130, train_loss 0.702
epoch 8, batch 140, train_loss 0.699
epoch 8, batch 150, train_loss 0.707
epoch 8, batch 160, train_loss 0.704
epoch 8, batch 170, train_loss 0.713
epoch 8, batch 180, train_loss 0.706
epoch 8, batch 190, train_loss 0.705
epoch 8, batch 200, train_loss 0.698
epoch 8, batch 210, train_loss 0.702
epoch 8, batch 220, train_loss 0.707
epoch 8, batch 230, train_loss 0.710
epoch 8, batch 240, train_loss 0.704
epoch 8, batch 250, train_loss 0.699
epoch 8, batch 260, train_loss 0.708
epoch 8, batch 270, train_loss 0.697
epoch 8, batch 280, train_loss 0.708
epoch 8, batch 290, train_loss 0.706
epoch 8, batch 300, train_loss 0.695
epoch 8, batch 310, train_loss 0.700
epoch 8, batch 320, train_loss 0.699
epoch 8, batch 330, train_loss 0.707
epoch 8, batch 340, train_loss 0.706
epoch 8, batch 350, train_loss 0.693
epoch 8, batch 360, train_loss 0.695
epoch 8, batch 370, train_loss 0.693
epoch 8, batch 380, train_loss 0.711
epoch 8, batch 390, train_loss 0.712
epoch 8, batch 400, train_loss 0.709
epoch 8, batch 410, train_loss 0.706
epoch 8, batch 420, train_loss 0.706
epoch 8, batch 430, train_loss 0.685
epoch 8, batch 440, train_loss 0.708
epoch 8, batch 450, train_loss 0.715
epoch 8, batch 460, train_loss 0.703
epoch 8, batch 470, train_loss 0.700
epoch 8, batch 480, train_loss 0.716
epoch 8, batch 490, train_loss 0.714
epoch 8, batch 500, train_loss 0.701
epoch 8, batch 510, train_loss 0.698
epoch 8, batch 520, train_loss 0.700
epoch 8, batch 530, train_loss 0.701
epoch 8, batch 540, train_loss 0.709
epoch 8, batch 550, train_loss 0.713
epoch 8, batch 560, train_loss 0.703
epoch 8, batch 570, train_loss 0.696
epoch 8, batch 580, train_loss 0.711
epoch 8, batch 590, train_loss 0.708
epoch 8, batch 600, train_loss 0.705
epoch 8, batch 610, train_loss 0.705
epoch 8, batch 620, train_loss 0.703
epoch 8, batch 630, train_loss 0.699
epoch 8, batch 640, train_loss 0.702
epoch 8, batch 650, train_loss 0.709
epoch 8, batch 660, train_loss 0.708
epoch 8, batch 670, train_loss 0.698
epoch 8, batch 680, train_loss 0.706
epoch 8, batch 690, train_loss 0.702
epoch 8, batch 700, train_loss 0.702
epoch 8, batch 710, train_loss 0.684
epoch 8, batch 720, train_loss 0.703
epoch 8, batch 730, train_loss 0.703
epoch 8, batch 740, train_loss 0.711
epoch 8, batch 750, train_loss 0.696
epoch 8, batch 760, train_loss 0.706
epoch 8, batch 770, train_loss 0.699
epoch 8, batch 780, train_loss 0.707
epoch 8, batch 790, train_loss 0.703
epoch 8, batch 800, train_loss 0.699
epoch 8, batch 810, train_loss 0.710
epoch 8, batch 820, train_loss 0.701
epoch 8, batch 830, train_loss 0.702
epoch 8, batch 840, train_loss 0.718
epoch 8, batch 850, train_loss 0.698
epoch 8, batch 860, train_loss 0.701
epoch 8, batch 870, train_loss 0.700
epoch 8, batch 880, train_loss 0.702
epoch 8, batch 890, train_loss 0.700
epoch 8, batch 900, train_loss 0.708
epoch 8, batch 910, train_loss 0.705
epoch 8, batch 920, train_loss 0.695
epoch 8, batch 930, train_loss 0.701
epoch 8, batch 940, train_loss 0.706
epoch 8, batch 950, train_loss 0.701
epoch 8, batch 960, train_loss 0.697
epoch 8, batch 970, train_loss 0.712
epoch 8, batch 980, train_loss 0.700
epoch 8, batch 990, train_loss 0.696
epoch 8, batch 1000, train_loss 0.702
epoch 8, batch 1010, train_loss 0.703
epoch 8, batch 1020, train_loss 0.709
epoch 8, batch 1030, train_loss 0.702
epoch 8, batch 1040, train_loss 0.685
epoch 8, batch 1050, train_loss 0.694
epoch 8, batch 1060, train_loss 0.699
epoch 8, batch 1070, train_loss 0.709
epoch 8, batch 1080, train_loss 0.698
epoch 8, batch 1090, train_loss 0.698
epoch 8, batch 1100, train_loss 0.705
epoch 8, batch 1110, train_loss 0.705
epoch 8, batch 1120, train_loss 0.703
epoch 8, batch 1130, train_loss 0.708
epoch 8, batch 1140, train_loss 0.703
epoch 8, batch 1150, train_loss 0.692
epoch 8, batch 1160, train_loss 0.705
epoch 8, batch 1170, train_loss 0.706
epoch 8, batch 1180, train_loss 0.696
epoch 8, batch 1190, train_loss 0.710
epoch 8, train_loss 0.702, valid_loss 0.722, train_accuracy  69.70%, valid_accuracy  68.59%
model saved with highest valid accuracy:  68.59%
epoch 9, batch 0, train_loss 0.713
epoch 9, batch 10, train_loss 0.706
epoch 9, batch 20, train_loss 0.702
epoch 9, batch 30, train_loss 0.699
epoch 9, batch 40, train_loss 0.694
epoch 9, batch 50, train_loss 0.701
epoch 9, batch 60, train_loss 0.703
epoch 9, batch 70, train_loss 0.691
epoch 9, batch 80, train_loss 0.696
epoch 9, batch 90, train_loss 0.711
epoch 9, batch 100, train_loss 0.694
epoch 9, batch 110, train_loss 0.708
epoch 9, batch 120, train_loss 0.705
epoch 9, batch 130, train_loss 0.698
epoch 9, batch 140, train_loss 0.702
epoch 9, batch 150, train_loss 0.705
epoch 9, batch 160, train_loss 0.704
epoch 9, batch 170, train_loss 0.705
epoch 9, batch 180, train_loss 0.709
epoch 9, batch 190, train_loss 0.702
epoch 9, batch 200, train_loss 0.701
epoch 9, batch 210, train_loss 0.696
epoch 9, batch 220, train_loss 0.696
epoch 9, batch 230, train_loss 0.708
epoch 9, batch 240, train_loss 0.710
epoch 9, batch 250, train_loss 0.709
epoch 9, batch 260, train_loss 0.685
epoch 9, batch 270, train_loss 0.707
epoch 9, batch 280, train_loss 0.694
epoch 9, batch 290, train_loss 0.710
epoch 9, batch 300, train_loss 0.697
epoch 9, batch 310, train_loss 0.710
epoch 9, batch 320, train_loss 0.708
epoch 9, batch 330, train_loss 0.704
epoch 9, batch 340, train_loss 0.707
epoch 9, batch 350, train_loss 0.710
epoch 9, batch 360, train_loss 0.700
epoch 9, batch 370, train_loss 0.697
epoch 9, batch 380, train_loss 0.695
epoch 9, batch 390, train_loss 0.702
epoch 9, batch 400, train_loss 0.689
epoch 9, batch 410, train_loss 0.715
epoch 9, batch 420, train_loss 0.710
epoch 9, batch 430, train_loss 0.703
epoch 9, batch 440, train_loss 0.706
epoch 9, batch 450, train_loss 0.708
epoch 9, batch 460, train_loss 0.701
epoch 9, batch 470, train_loss 0.692
epoch 9, batch 480, train_loss 0.694
epoch 9, batch 490, train_loss 0.712
epoch 9, batch 500, train_loss 0.702
epoch 9, batch 510, train_loss 0.706
epoch 9, batch 520, train_loss 0.691
epoch 9, batch 530, train_loss 0.700
epoch 9, batch 540, train_loss 0.709
epoch 9, batch 550, train_loss 0.707
epoch 9, batch 560, train_loss 0.704
epoch 9, batch 570, train_loss 0.693
epoch 9, batch 580, train_loss 0.702
epoch 9, batch 590, train_loss 0.694
epoch 9, batch 600, train_loss 0.709
epoch 9, batch 610, train_loss 0.699
epoch 9, batch 620, train_loss 0.698
epoch 9, batch 630, train_loss 0.710
epoch 9, batch 640, train_loss 0.705
epoch 9, batch 650, train_loss 0.707
epoch 9, batch 660, train_loss 0.703
epoch 9, batch 670, train_loss 0.704
epoch 9, batch 680, train_loss 0.707
epoch 9, batch 690, train_loss 0.700
epoch 9, batch 700, train_loss 0.698
epoch 9, batch 710, train_loss 0.704
epoch 9, batch 720, train_loss 0.703
epoch 9, batch 730, train_loss 0.706
epoch 9, batch 740, train_loss 0.694
epoch 9, batch 750, train_loss 0.702
epoch 9, batch 760, train_loss 0.705
epoch 9, batch 770, train_loss 0.705
epoch 9, batch 780, train_loss 0.699
epoch 9, batch 790, train_loss 0.702
epoch 9, batch 800, train_loss 0.704
epoch 9, batch 810, train_loss 0.697
epoch 9, batch 820, train_loss 0.704
epoch 9, batch 830, train_loss 0.708
epoch 9, batch 840, train_loss 0.703
epoch 9, batch 850, train_loss 0.696
epoch 9, batch 860, train_loss 0.698
epoch 9, batch 870, train_loss 0.704
epoch 9, batch 880, train_loss 0.699
epoch 9, batch 890, train_loss 0.708
epoch 9, batch 900, train_loss 0.701
epoch 9, batch 910, train_loss 0.704
epoch 9, batch 920, train_loss 0.706
epoch 9, batch 930, train_loss 0.706
epoch 9, batch 940, train_loss 0.703
epoch 9, batch 950, train_loss 0.708
epoch 9, batch 960, train_loss 0.702
epoch 9, batch 970, train_loss 0.700
epoch 9, batch 980, train_loss 0.696
epoch 9, batch 990, train_loss 0.697
epoch 9, batch 1000, train_loss 0.704
epoch 9, batch 1010, train_loss 0.705
epoch 9, batch 1020, train_loss 0.696
epoch 9, batch 1030, train_loss 0.694
epoch 9, batch 1040, train_loss 0.701
epoch 9, batch 1050, train_loss 0.699
epoch 9, batch 1060, train_loss 0.694
epoch 9, batch 1070, train_loss 0.699
epoch 9, batch 1080, train_loss 0.706
epoch 9, batch 1090, train_loss 0.698
epoch 9, batch 1100, train_loss 0.706
epoch 9, batch 1110, train_loss 0.699
epoch 9, batch 1120, train_loss 0.704
epoch 9, batch 1130, train_loss 0.709
epoch 9, batch 1140, train_loss 0.706
epoch 9, batch 1150, train_loss 0.698
epoch 9, batch 1160, train_loss 0.701
epoch 9, batch 1170, train_loss 0.704
epoch 9, batch 1180, train_loss 0.702
epoch 9, batch 1190, train_loss 0.691
epoch 9, train_loss 0.701, valid_loss 0.722, train_accuracy  69.74%, valid_accuracy  68.61%
model saved with highest valid accuracy:  68.61%
epoch 10, batch 0, train_loss 0.696
epoch 10, batch 10, train_loss 0.699
epoch 10, batch 20, train_loss 0.695
epoch 10, batch 30, train_loss 0.699
epoch 10, batch 40, train_loss 0.698
epoch 10, batch 50, train_loss 0.694
epoch 10, batch 60, train_loss 0.712
epoch 10, batch 70, train_loss 0.708
epoch 10, batch 80, train_loss 0.702
epoch 10, batch 90, train_loss 0.692
epoch 10, batch 100, train_loss 0.709
epoch 10, batch 110, train_loss 0.705
epoch 10, batch 120, train_loss 0.706
epoch 10, batch 130, train_loss 0.696
epoch 10, batch 140, train_loss 0.705
epoch 10, batch 150, train_loss 0.699
epoch 10, batch 160, train_loss 0.703
epoch 10, batch 170, train_loss 0.706
epoch 10, batch 180, train_loss 0.704
epoch 10, batch 190, train_loss 0.702
epoch 10, batch 200, train_loss 0.695
epoch 10, batch 210, train_loss 0.690
epoch 10, batch 220, train_loss 0.706
epoch 10, batch 230, train_loss 0.703
epoch 10, batch 240, train_loss 0.706
epoch 10, batch 250, train_loss 0.699
epoch 10, batch 260, train_loss 0.704
epoch 10, batch 270, train_loss 0.704
epoch 10, batch 280, train_loss 0.703
epoch 10, batch 290, train_loss 0.700
epoch 10, batch 300, train_loss 0.696
epoch 10, batch 310, train_loss 0.712
epoch 10, batch 320, train_loss 0.698
epoch 10, batch 330, train_loss 0.704
epoch 10, batch 340, train_loss 0.704
epoch 10, batch 350, train_loss 0.708
epoch 10, batch 360, train_loss 0.701
epoch 10, batch 370, train_loss 0.707
epoch 10, batch 380, train_loss 0.705
epoch 10, batch 390, train_loss 0.685
epoch 10, batch 400, train_loss 0.709
epoch 10, batch 410, train_loss 0.703
epoch 10, batch 420, train_loss 0.690
epoch 10, batch 430, train_loss 0.698
epoch 10, batch 440, train_loss 0.700
epoch 10, batch 450, train_loss 0.705
epoch 10, batch 460, train_loss 0.702
epoch 10, batch 470, train_loss 0.705
epoch 10, batch 480, train_loss 0.704
epoch 10, batch 490, train_loss 0.703
epoch 10, batch 500, train_loss 0.711
epoch 10, batch 510, train_loss 0.705
epoch 10, batch 520, train_loss 0.693
epoch 10, batch 530, train_loss 0.699
epoch 10, batch 540, train_loss 0.698
epoch 10, batch 550, train_loss 0.703
epoch 10, batch 560, train_loss 0.697
epoch 10, batch 570, train_loss 0.706
epoch 10, batch 580, train_loss 0.703
epoch 10, batch 590, train_loss 0.709
epoch 10, batch 600, train_loss 0.699
epoch 10, batch 610, train_loss 0.696
epoch 10, batch 620, train_loss 0.705
epoch 10, batch 630, train_loss 0.708
epoch 10, batch 640, train_loss 0.698
epoch 10, batch 650, train_loss 0.703
epoch 10, batch 660, train_loss 0.708
epoch 10, batch 670, train_loss 0.702
epoch 10, batch 680, train_loss 0.707
epoch 10, batch 690, train_loss 0.700
epoch 10, batch 700, train_loss 0.704
epoch 10, batch 710, train_loss 0.692
epoch 10, batch 720, train_loss 0.694
epoch 10, batch 730, train_loss 0.702
epoch 10, batch 740, train_loss 0.701
epoch 10, batch 750, train_loss 0.697
epoch 10, batch 760, train_loss 0.708
epoch 10, batch 770, train_loss 0.695
epoch 10, batch 780, train_loss 0.693
epoch 10, batch 790, train_loss 0.699
epoch 10, batch 800, train_loss 0.696
epoch 10, batch 810, train_loss 0.693
epoch 10, batch 820, train_loss 0.701
epoch 10, batch 830, train_loss 0.713
epoch 10, batch 840, train_loss 0.704
epoch 10, batch 850, train_loss 0.703
epoch 10, batch 860, train_loss 0.702
epoch 10, batch 870, train_loss 0.699
epoch 10, batch 880, train_loss 0.710
epoch 10, batch 890, train_loss 0.698
epoch 10, batch 900, train_loss 0.707
epoch 10, batch 910, train_loss 0.698
epoch 10, batch 920, train_loss 0.697
epoch 10, batch 930, train_loss 0.701
epoch 10, batch 940, train_loss 0.702
epoch 10, batch 950, train_loss 0.698
epoch 10, batch 960, train_loss 0.703
epoch 10, batch 970, train_loss 0.699
epoch 10, batch 980, train_loss 0.693
epoch 10, batch 990, train_loss 0.699
epoch 10, batch 1000, train_loss 0.696
epoch 10, batch 1010, train_loss 0.704
epoch 10, batch 1020, train_loss 0.697
epoch 10, batch 1030, train_loss 0.696
epoch 10, batch 1040, train_loss 0.694
epoch 10, batch 1050, train_loss 0.704
epoch 10, batch 1060, train_loss 0.702
epoch 10, batch 1070, train_loss 0.703
epoch 10, batch 1080, train_loss 0.702
epoch 10, batch 1090, train_loss 0.703
epoch 10, batch 1100, train_loss 0.705
epoch 10, batch 1110, train_loss 0.708
epoch 10, batch 1120, train_loss 0.702
epoch 10, batch 1130, train_loss 0.707
epoch 10, batch 1140, train_loss 0.700
epoch 10, batch 1150, train_loss 0.694
epoch 10, batch 1160, train_loss 0.701
epoch 10, batch 1170, train_loss 0.704
epoch 10, batch 1180, train_loss 0.703
epoch 10, batch 1190, train_loss 0.705
epoch 10, train_loss 0.699, valid_loss 0.722, train_accuracy  69.83%, valid_accuracy  68.62%
model saved with highest valid accuracy:  68.62%
epoch 11, batch 0, train_loss 0.689
epoch 11, batch 10, train_loss 0.701
epoch 11, batch 20, train_loss 0.709
epoch 11, batch 30, train_loss 0.693
epoch 11, batch 40, train_loss 0.702
epoch 11, batch 50, train_loss 0.704
epoch 11, batch 60, train_loss 0.687
epoch 11, batch 70, train_loss 0.696
epoch 11, batch 80, train_loss 0.694
epoch 11, batch 90, train_loss 0.705
epoch 11, batch 100, train_loss 0.689
epoch 11, batch 110, train_loss 0.698
epoch 11, batch 120, train_loss 0.698
epoch 11, batch 130, train_loss 0.705
epoch 11, batch 140, train_loss 0.710
epoch 11, batch 150, train_loss 0.703
epoch 11, batch 160, train_loss 0.699
epoch 11, batch 170, train_loss 0.701
epoch 11, batch 180, train_loss 0.704
epoch 11, batch 190, train_loss 0.705
epoch 11, batch 200, train_loss 0.707
epoch 11, batch 210, train_loss 0.699
epoch 11, batch 220, train_loss 0.707
epoch 11, batch 230, train_loss 0.710
epoch 11, batch 240, train_loss 0.697
epoch 11, batch 250, train_loss 0.701
epoch 11, batch 260, train_loss 0.697
epoch 11, batch 270, train_loss 0.699
epoch 11, batch 280, train_loss 0.712
epoch 11, batch 290, train_loss 0.693
epoch 11, batch 300, train_loss 0.708
epoch 11, batch 310, train_loss 0.699
epoch 11, batch 320, train_loss 0.703
epoch 11, batch 330, train_loss 0.701
epoch 11, batch 340, train_loss 0.705
epoch 11, batch 350, train_loss 0.696
epoch 11, batch 360, train_loss 0.702
epoch 11, batch 370, train_loss 0.709
epoch 11, batch 380, train_loss 0.706
epoch 11, batch 390, train_loss 0.701
epoch 11, batch 400, train_loss 0.699
epoch 11, batch 410, train_loss 0.699
epoch 11, batch 420, train_loss 0.699
epoch 11, batch 430, train_loss 0.701
epoch 11, batch 440, train_loss 0.699
epoch 11, batch 450, train_loss 0.701
epoch 11, batch 460, train_loss 0.695
epoch 11, batch 470, train_loss 0.701
epoch 11, batch 480, train_loss 0.690
epoch 11, batch 490, train_loss 0.703
epoch 11, batch 500, train_loss 0.702
epoch 11, batch 510, train_loss 0.707
epoch 11, batch 520, train_loss 0.694
epoch 11, batch 530, train_loss 0.713
epoch 11, batch 540, train_loss 0.713
epoch 11, batch 550, train_loss 0.693
epoch 11, batch 560, train_loss 0.709
epoch 11, batch 570, train_loss 0.696
epoch 11, batch 580, train_loss 0.697
epoch 11, batch 590, train_loss 0.693
epoch 11, batch 600, train_loss 0.704
epoch 11, batch 610, train_loss 0.700
epoch 11, batch 620, train_loss 0.701
epoch 11, batch 630, train_loss 0.708
epoch 11, batch 640, train_loss 0.701
epoch 11, batch 650, train_loss 0.704
epoch 11, batch 660, train_loss 0.695
epoch 11, batch 670, train_loss 0.700
epoch 11, batch 680, train_loss 0.697
epoch 11, batch 690, train_loss 0.696
epoch 11, batch 700, train_loss 0.710
epoch 11, batch 710, train_loss 0.691
epoch 11, batch 720, train_loss 0.697
epoch 11, batch 730, train_loss 0.701
epoch 11, batch 740, train_loss 0.707
epoch 11, batch 750, train_loss 0.711
epoch 11, batch 760, train_loss 0.700
epoch 11, batch 770, train_loss 0.699
epoch 11, batch 780, train_loss 0.697
epoch 11, batch 790, train_loss 0.699
epoch 11, batch 800, train_loss 0.706
epoch 11, batch 810, train_loss 0.710
epoch 11, batch 820, train_loss 0.709
epoch 11, batch 830, train_loss 0.702
epoch 11, batch 840, train_loss 0.706
epoch 11, batch 850, train_loss 0.696
epoch 11, batch 860, train_loss 0.712
epoch 11, batch 870, train_loss 0.707
epoch 11, batch 880, train_loss 0.712
epoch 11, batch 890, train_loss 0.696
epoch 11, batch 900, train_loss 0.690
epoch 11, batch 910, train_loss 0.692
epoch 11, batch 920, train_loss 0.695
epoch 11, batch 930, train_loss 0.691
epoch 11, batch 940, train_loss 0.696
epoch 11, batch 950, train_loss 0.695
epoch 11, batch 960, train_loss 0.698
epoch 11, batch 970, train_loss 0.702
epoch 11, batch 980, train_loss 0.698
epoch 11, batch 990, train_loss 0.698
epoch 11, batch 1000, train_loss 0.708
epoch 11, batch 1010, train_loss 0.707
epoch 11, batch 1020, train_loss 0.712
epoch 11, batch 1030, train_loss 0.692
epoch 11, batch 1040, train_loss 0.695
epoch 11, batch 1050, train_loss 0.697
epoch 11, batch 1060, train_loss 0.705
epoch 11, batch 1070, train_loss 0.705
epoch 11, batch 1080, train_loss 0.703
epoch 11, batch 1090, train_loss 0.705
epoch 11, batch 1100, train_loss 0.697
epoch 11, batch 1110, train_loss 0.696
epoch 11, batch 1120, train_loss 0.702
epoch 11, batch 1130, train_loss 0.704
epoch 11, batch 1140, train_loss 0.693
epoch 11, batch 1150, train_loss 0.713
epoch 11, batch 1160, train_loss 0.706
epoch 11, batch 1170, train_loss 0.700
epoch 11, batch 1180, train_loss 0.705
epoch 11, batch 1190, train_loss 0.704
epoch 11, train_loss 0.699, valid_loss 0.723, train_accuracy  69.85%, valid_accuracy  68.57%
epoch 12, batch 0, train_loss 0.696
epoch 12, batch 10, train_loss 0.692
epoch 12, batch 20, train_loss 0.693
epoch 12, batch 30, train_loss 0.705
epoch 12, batch 40, train_loss 0.694
epoch 12, batch 50, train_loss 0.706
epoch 12, batch 60, train_loss 0.703
epoch 12, batch 70, train_loss 0.707
epoch 12, batch 80, train_loss 0.699
epoch 12, batch 90, train_loss 0.702
epoch 12, batch 100, train_loss 0.699
epoch 12, batch 110, train_loss 0.704
epoch 12, batch 120, train_loss 0.696
epoch 12, batch 130, train_loss 0.696
epoch 12, batch 140, train_loss 0.695
epoch 12, batch 150, train_loss 0.700
epoch 12, batch 160, train_loss 0.695
epoch 12, batch 170, train_loss 0.702
epoch 12, batch 180, train_loss 0.698
epoch 12, batch 190, train_loss 0.696
epoch 12, batch 200, train_loss 0.706
epoch 12, batch 210, train_loss 0.706
epoch 12, batch 220, train_loss 0.692
epoch 12, batch 230, train_loss 0.702
epoch 12, batch 240, train_loss 0.697
epoch 12, batch 250, train_loss 0.700
epoch 12, batch 260, train_loss 0.694
epoch 12, batch 270, train_loss 0.695
epoch 12, batch 280, train_loss 0.698
epoch 12, batch 290, train_loss 0.696
epoch 12, batch 300, train_loss 0.703
epoch 12, batch 310, train_loss 0.693
epoch 12, batch 320, train_loss 0.697
epoch 12, batch 330, train_loss 0.696
epoch 12, batch 340, train_loss 0.688
epoch 12, batch 350, train_loss 0.703
epoch 12, batch 360, train_loss 0.695
epoch 12, batch 370, train_loss 0.699
epoch 12, batch 380, train_loss 0.699
epoch 12, batch 390, train_loss 0.693
epoch 12, batch 400, train_loss 0.698
epoch 12, batch 410, train_loss 0.702
epoch 12, batch 420, train_loss 0.695
epoch 12, batch 430, train_loss 0.700
epoch 12, batch 440, train_loss 0.701
epoch 12, batch 450, train_loss 0.688
epoch 12, batch 460, train_loss 0.704
epoch 12, batch 470, train_loss 0.696
epoch 12, batch 480, train_loss 0.693
epoch 12, batch 490, train_loss 0.697
epoch 12, batch 500, train_loss 0.696
epoch 12, batch 510, train_loss 0.702
epoch 12, batch 520, train_loss 0.697
epoch 12, batch 530, train_loss 0.711
epoch 12, batch 540, train_loss 0.702
epoch 12, batch 550, train_loss 0.695
epoch 12, batch 560, train_loss 0.700
epoch 12, batch 570, train_loss 0.702
epoch 12, batch 580, train_loss 0.701
epoch 12, batch 590, train_loss 0.702
epoch 12, batch 600, train_loss 0.696
epoch 12, batch 610, train_loss 0.703
epoch 12, batch 620, train_loss 0.700
epoch 12, batch 630, train_loss 0.691
epoch 12, batch 640, train_loss 0.705
epoch 12, batch 650, train_loss 0.702
epoch 12, batch 660, train_loss 0.695
epoch 12, batch 670, train_loss 0.696
epoch 12, batch 680, train_loss 0.713
epoch 12, batch 690, train_loss 0.702
epoch 12, batch 700, train_loss 0.703
epoch 12, batch 710, train_loss 0.690
epoch 12, batch 720, train_loss 0.700
epoch 12, batch 730, train_loss 0.698
epoch 12, batch 740, train_loss 0.708
epoch 12, batch 750, train_loss 0.707
epoch 12, batch 760, train_loss 0.703
epoch 12, batch 770, train_loss 0.698
epoch 12, batch 780, train_loss 0.701
epoch 12, batch 790, train_loss 0.703
epoch 12, batch 800, train_loss 0.704
epoch 12, batch 810, train_loss 0.701
epoch 12, batch 820, train_loss 0.703
epoch 12, batch 830, train_loss 0.686
epoch 12, batch 840, train_loss 0.707
epoch 12, batch 850, train_loss 0.701
epoch 12, batch 860, train_loss 0.693
epoch 12, batch 870, train_loss 0.711
epoch 12, batch 880, train_loss 0.700
epoch 12, batch 890, train_loss 0.695
epoch 12, batch 900, train_loss 0.700
epoch 12, batch 910, train_loss 0.697
epoch 12, batch 920, train_loss 0.693
epoch 12, batch 930, train_loss 0.704
epoch 12, batch 940, train_loss 0.694
epoch 12, batch 950, train_loss 0.698
epoch 12, batch 960, train_loss 0.708
epoch 12, batch 970, train_loss 0.701
epoch 12, batch 980, train_loss 0.702
epoch 12, batch 990, train_loss 0.706
epoch 12, batch 1000, train_loss 0.706
epoch 12, batch 1010, train_loss 0.704
epoch 12, batch 1020, train_loss 0.696
epoch 12, batch 1030, train_loss 0.704
epoch 12, batch 1040, train_loss 0.691
epoch 12, batch 1050, train_loss 0.692
epoch 12, batch 1060, train_loss 0.691
epoch 12, batch 1070, train_loss 0.694
epoch 12, batch 1080, train_loss 0.693
epoch 12, batch 1090, train_loss 0.693
epoch 12, batch 1100, train_loss 0.692
epoch 12, batch 1110, train_loss 0.705
epoch 12, batch 1120, train_loss 0.701
epoch 12, batch 1130, train_loss 0.694
epoch 12, batch 1140, train_loss 0.697
epoch 12, batch 1150, train_loss 0.710
epoch 12, batch 1160, train_loss 0.697
epoch 12, batch 1170, train_loss 0.690
epoch 12, batch 1180, train_loss 0.705
epoch 12, batch 1190, train_loss 0.695
epoch 12, train_loss 0.699, valid_loss 0.722, train_accuracy  69.86%, valid_accuracy  68.56%
epoch 13, batch 0, train_loss 0.702
epoch 13, batch 10, train_loss 0.689
epoch 13, batch 20, train_loss 0.700
epoch 13, batch 30, train_loss 0.695
epoch 13, batch 40, train_loss 0.696
epoch 13, batch 50, train_loss 0.700
epoch 13, batch 60, train_loss 0.693
epoch 13, batch 70, train_loss 0.703
epoch 13, batch 80, train_loss 0.692
epoch 13, batch 90, train_loss 0.683
epoch 13, batch 100, train_loss 0.705
epoch 13, batch 110, train_loss 0.695
epoch 13, batch 120, train_loss 0.695
epoch 13, batch 130, train_loss 0.703
epoch 13, batch 140, train_loss 0.694
epoch 13, batch 150, train_loss 0.707
epoch 13, batch 160, train_loss 0.695
epoch 13, batch 170, train_loss 0.703
epoch 13, batch 180, train_loss 0.701
epoch 13, batch 190, train_loss 0.715
epoch 13, batch 200, train_loss 0.702
epoch 13, batch 210, train_loss 0.694
epoch 13, batch 220, train_loss 0.709
epoch 13, batch 230, train_loss 0.698
epoch 13, batch 240, train_loss 0.700
epoch 13, batch 250, train_loss 0.706
epoch 13, batch 260, train_loss 0.689
epoch 13, batch 270, train_loss 0.702
epoch 13, batch 280, train_loss 0.704
epoch 13, batch 290, train_loss 0.691
epoch 13, batch 300, train_loss 0.699
epoch 13, batch 310, train_loss 0.702
epoch 13, batch 320, train_loss 0.706
epoch 13, batch 330, train_loss 0.690
epoch 13, batch 340, train_loss 0.703
epoch 13, batch 350, train_loss 0.717
epoch 13, batch 360, train_loss 0.704
epoch 13, batch 370, train_loss 0.698
epoch 13, batch 380, train_loss 0.694
epoch 13, batch 390, train_loss 0.709
epoch 13, batch 400, train_loss 0.697
epoch 13, batch 410, train_loss 0.698
epoch 13, batch 420, train_loss 0.693
epoch 13, batch 430, train_loss 0.701
epoch 13, batch 440, train_loss 0.703
epoch 13, batch 450, train_loss 0.690
epoch 13, batch 460, train_loss 0.712
epoch 13, batch 470, train_loss 0.696
epoch 13, batch 480, train_loss 0.698
epoch 13, batch 490, train_loss 0.701
epoch 13, batch 500, train_loss 0.702
epoch 13, batch 510, train_loss 0.702
epoch 13, batch 520, train_loss 0.699
epoch 13, batch 530, train_loss 0.702
epoch 13, batch 540, train_loss 0.693
epoch 13, batch 550, train_loss 0.701
epoch 13, batch 560, train_loss 0.700
epoch 13, batch 570, train_loss 0.704
epoch 13, batch 580, train_loss 0.697
epoch 13, batch 590, train_loss 0.705
epoch 13, batch 600, train_loss 0.692
epoch 13, batch 610, train_loss 0.695
epoch 13, batch 620, train_loss 0.699
epoch 13, batch 630, train_loss 0.709
epoch 13, batch 640, train_loss 0.700
epoch 13, batch 650, train_loss 0.710
epoch 13, batch 660, train_loss 0.704
epoch 13, batch 670, train_loss 0.694
epoch 13, batch 680, train_loss 0.694
epoch 13, batch 690, train_loss 0.691
epoch 13, batch 700, train_loss 0.699
epoch 13, batch 710, train_loss 0.702
epoch 13, batch 720, train_loss 0.702
epoch 13, batch 730, train_loss 0.707
epoch 13, batch 740, train_loss 0.695
epoch 13, batch 750, train_loss 0.703
epoch 13, batch 760, train_loss 0.699
epoch 13, batch 770, train_loss 0.688
epoch 13, batch 780, train_loss 0.705
epoch 13, batch 790, train_loss 0.697
epoch 13, batch 800, train_loss 0.695
epoch 13, batch 810, train_loss 0.700
epoch 13, batch 820, train_loss 0.696
epoch 13, batch 830, train_loss 0.703
epoch 13, batch 840, train_loss 0.706
epoch 13, batch 850, train_loss 0.703
epoch 13, batch 860, train_loss 0.706
epoch 13, batch 870, train_loss 0.702
epoch 13, batch 880, train_loss 0.700
epoch 13, batch 890, train_loss 0.704
epoch 13, batch 900, train_loss 0.705
epoch 13, batch 910, train_loss 0.698
epoch 13, batch 920, train_loss 0.694
epoch 13, batch 930, train_loss 0.688
epoch 13, batch 940, train_loss 0.699
epoch 13, batch 950, train_loss 0.698
epoch 13, batch 960, train_loss 0.689
epoch 13, batch 970, train_loss 0.693
epoch 13, batch 980, train_loss 0.686
epoch 13, batch 990, train_loss 0.700
epoch 13, batch 1000, train_loss 0.701
epoch 13, batch 1010, train_loss 0.703
epoch 13, batch 1020, train_loss 0.692
epoch 13, batch 1030, train_loss 0.695
epoch 13, batch 1040, train_loss 0.705
epoch 13, batch 1050, train_loss 0.702
epoch 13, batch 1060, train_loss 0.697
epoch 13, batch 1070, train_loss 0.704
epoch 13, batch 1080, train_loss 0.699
epoch 13, batch 1090, train_loss 0.710
epoch 13, batch 1100, train_loss 0.695
epoch 13, batch 1110, train_loss 0.697
epoch 13, batch 1120, train_loss 0.696
epoch 13, batch 1130, train_loss 0.695
epoch 13, batch 1140, train_loss 0.696
epoch 13, batch 1150, train_loss 0.706
epoch 13, batch 1160, train_loss 0.712
epoch 13, batch 1170, train_loss 0.703
epoch 13, batch 1180, train_loss 0.690
epoch 13, batch 1190, train_loss 0.703
epoch 13, train_loss 0.698, valid_loss 0.722, train_accuracy  69.93%, valid_accuracy  68.63%
model saved with highest valid accuracy:  68.63%
epoch 14, batch 0, train_loss 0.691
epoch 14, batch 10, train_loss 0.696
epoch 14, batch 20, train_loss 0.701
epoch 14, batch 30, train_loss 0.697
epoch 14, batch 40, train_loss 0.697
epoch 14, batch 50, train_loss 0.695
epoch 14, batch 60, train_loss 0.701
epoch 14, batch 70, train_loss 0.700
epoch 14, batch 80, train_loss 0.702
epoch 14, batch 90, train_loss 0.706
epoch 14, batch 100, train_loss 0.703
epoch 14, batch 110, train_loss 0.687
epoch 14, batch 120, train_loss 0.682
epoch 14, batch 130, train_loss 0.694
epoch 14, batch 140, train_loss 0.705
epoch 14, batch 150, train_loss 0.700
epoch 14, batch 160, train_loss 0.699
epoch 14, batch 170, train_loss 0.695
epoch 14, batch 180, train_loss 0.697
epoch 14, batch 190, train_loss 0.690
epoch 14, batch 200, train_loss 0.696
epoch 14, batch 210, train_loss 0.696
epoch 14, batch 220, train_loss 0.701
epoch 14, batch 230, train_loss 0.708
epoch 14, batch 240, train_loss 0.695
epoch 14, batch 250, train_loss 0.692
epoch 14, batch 260, train_loss 0.703
epoch 14, batch 270, train_loss 0.699
epoch 14, batch 280, train_loss 0.706
epoch 14, batch 290, train_loss 0.695
epoch 14, batch 300, train_loss 0.715
epoch 14, batch 310, train_loss 0.697
epoch 14, batch 320, train_loss 0.696
epoch 14, batch 330, train_loss 0.698
epoch 14, batch 340, train_loss 0.711
epoch 14, batch 350, train_loss 0.700
epoch 14, batch 360, train_loss 0.699
epoch 14, batch 370, train_loss 0.693
epoch 14, batch 380, train_loss 0.709
epoch 14, batch 390, train_loss 0.708
epoch 14, batch 400, train_loss 0.697
epoch 14, batch 410, train_loss 0.708
epoch 14, batch 420, train_loss 0.695
epoch 14, batch 430, train_loss 0.686
epoch 14, batch 440, train_loss 0.709
epoch 14, batch 450, train_loss 0.704
epoch 14, batch 460, train_loss 0.700
epoch 14, batch 470, train_loss 0.707
epoch 14, batch 480, train_loss 0.699
epoch 14, batch 490, train_loss 0.693
epoch 14, batch 500, train_loss 0.699
epoch 14, batch 510, train_loss 0.698
epoch 14, batch 520, train_loss 0.701
epoch 14, batch 530, train_loss 0.703
epoch 14, batch 540, train_loss 0.696
epoch 14, batch 550, train_loss 0.715
epoch 14, batch 560, train_loss 0.707
epoch 14, batch 570, train_loss 0.697
epoch 14, batch 580, train_loss 0.690
epoch 14, batch 590, train_loss 0.704
epoch 14, batch 600, train_loss 0.698
epoch 14, batch 610, train_loss 0.702
epoch 14, batch 620, train_loss 0.693
epoch 14, batch 630, train_loss 0.701
epoch 14, batch 640, train_loss 0.704
epoch 14, batch 650, train_loss 0.706
epoch 14, batch 660, train_loss 0.713
epoch 14, batch 670, train_loss 0.704
epoch 14, batch 680, train_loss 0.690
epoch 14, batch 690, train_loss 0.699
epoch 14, batch 700, train_loss 0.693
epoch 14, batch 710, train_loss 0.702
epoch 14, batch 720, train_loss 0.696
epoch 14, batch 730, train_loss 0.694
epoch 14, batch 740, train_loss 0.705
epoch 14, batch 750, train_loss 0.706
epoch 14, batch 760, train_loss 0.699
epoch 14, batch 770, train_loss 0.692
epoch 14, batch 780, train_loss 0.704
epoch 14, batch 790, train_loss 0.703
epoch 14, batch 800, train_loss 0.698
epoch 14, batch 810, train_loss 0.697
epoch 14, batch 820, train_loss 0.700
epoch 14, batch 830, train_loss 0.704
epoch 14, batch 840, train_loss 0.682
epoch 14, batch 850, train_loss 0.702
epoch 14, batch 860, train_loss 0.701
epoch 14, batch 870, train_loss 0.700
epoch 14, batch 880, train_loss 0.699
epoch 14, batch 890, train_loss 0.702
epoch 14, batch 900, train_loss 0.701
epoch 14, batch 910, train_loss 0.705
epoch 14, batch 920, train_loss 0.708
epoch 14, batch 930, train_loss 0.701
epoch 14, batch 940, train_loss 0.699
epoch 14, batch 950, train_loss 0.705
epoch 14, batch 960, train_loss 0.704
epoch 14, batch 970, train_loss 0.701
epoch 14, batch 980, train_loss 0.706
epoch 14, batch 990, train_loss 0.690
epoch 14, batch 1000, train_loss 0.696
epoch 14, batch 1010, train_loss 0.698
epoch 14, batch 1020, train_loss 0.689
epoch 14, batch 1030, train_loss 0.699
epoch 14, batch 1040, train_loss 0.697
epoch 14, batch 1050, train_loss 0.700
epoch 14, batch 1060, train_loss 0.703
epoch 14, batch 1070, train_loss 0.692
epoch 14, batch 1080, train_loss 0.691
epoch 14, batch 1090, train_loss 0.698
epoch 14, batch 1100, train_loss 0.686
epoch 14, batch 1110, train_loss 0.704
epoch 14, batch 1120, train_loss 0.696
epoch 14, batch 1130, train_loss 0.701
epoch 14, batch 1140, train_loss 0.690
epoch 14, batch 1150, train_loss 0.706
epoch 14, batch 1160, train_loss 0.696
epoch 14, batch 1170, train_loss 0.697
epoch 14, batch 1180, train_loss 0.698
epoch 14, batch 1190, train_loss 0.714
epoch 14, train_loss 0.697, valid_loss 0.721, train_accuracy  69.97%, valid_accuracy  68.60%
epoch 15, batch 0, train_loss 0.695
epoch 15, batch 10, train_loss 0.705
epoch 15, batch 20, train_loss 0.691
epoch 15, batch 30, train_loss 0.694
epoch 15, batch 40, train_loss 0.709
epoch 15, batch 50, train_loss 0.696
epoch 15, batch 60, train_loss 0.689
epoch 15, batch 70, train_loss 0.701
epoch 15, batch 80, train_loss 0.698
epoch 15, batch 90, train_loss 0.695
epoch 15, batch 100, train_loss 0.707
epoch 15, batch 110, train_loss 0.700
epoch 15, batch 120, train_loss 0.697
epoch 15, batch 130, train_loss 0.705
epoch 15, batch 140, train_loss 0.697
epoch 15, batch 150, train_loss 0.704
epoch 15, batch 160, train_loss 0.702
epoch 15, batch 170, train_loss 0.694
epoch 15, batch 180, train_loss 0.699
epoch 15, batch 190, train_loss 0.691
epoch 15, batch 200, train_loss 0.711
epoch 15, batch 210, train_loss 0.700
epoch 15, batch 220, train_loss 0.694
epoch 15, batch 230, train_loss 0.695
epoch 15, batch 240, train_loss 0.697
epoch 15, batch 250, train_loss 0.701
epoch 15, batch 260, train_loss 0.704
epoch 15, batch 270, train_loss 0.694
epoch 15, batch 280, train_loss 0.703
epoch 15, batch 290, train_loss 0.696
epoch 15, batch 300, train_loss 0.700
epoch 15, batch 310, train_loss 0.693
epoch 15, batch 320, train_loss 0.706
epoch 15, batch 330, train_loss 0.689
epoch 15, batch 340, train_loss 0.695
epoch 15, batch 350, train_loss 0.696
epoch 15, batch 360, train_loss 0.702
epoch 15, batch 370, train_loss 0.694
epoch 15, batch 380, train_loss 0.696
epoch 15, batch 390, train_loss 0.690
epoch 15, batch 400, train_loss 0.697
epoch 15, batch 410, train_loss 0.699
epoch 15, batch 420, train_loss 0.700
epoch 15, batch 430, train_loss 0.695
epoch 15, batch 440, train_loss 0.702
epoch 15, batch 450, train_loss 0.697
epoch 15, batch 460, train_loss 0.698
epoch 15, batch 470, train_loss 0.703
epoch 15, batch 480, train_loss 0.703
epoch 15, batch 490, train_loss 0.702
epoch 15, batch 500, train_loss 0.700
epoch 15, batch 510, train_loss 0.698
epoch 15, batch 520, train_loss 0.686
epoch 15, batch 530, train_loss 0.692
epoch 15, batch 540, train_loss 0.696
epoch 15, batch 550, train_loss 0.700
epoch 15, batch 560, train_loss 0.697
epoch 15, batch 570, train_loss 0.706
epoch 15, batch 580, train_loss 0.703
epoch 15, batch 590, train_loss 0.702
epoch 15, batch 600, train_loss 0.701
epoch 15, batch 610, train_loss 0.702
epoch 15, batch 620, train_loss 0.698
epoch 15, batch 630, train_loss 0.705
epoch 15, batch 640, train_loss 0.691
epoch 15, batch 650, train_loss 0.708
epoch 15, batch 660, train_loss 0.697
epoch 15, batch 670, train_loss 0.689
epoch 15, batch 680, train_loss 0.693
epoch 15, batch 690, train_loss 0.693
epoch 15, batch 700, train_loss 0.711
epoch 15, batch 710, train_loss 0.707
epoch 15, batch 720, train_loss 0.693
epoch 15, batch 730, train_loss 0.701
epoch 15, batch 740, train_loss 0.698
epoch 15, batch 750, train_loss 0.705
epoch 15, batch 760, train_loss 0.699
epoch 15, batch 770, train_loss 0.704
epoch 15, batch 780, train_loss 0.691
epoch 15, batch 790, train_loss 0.709
epoch 15, batch 800, train_loss 0.710
epoch 15, batch 810, train_loss 0.711
epoch 15, batch 820, train_loss 0.708
epoch 15, batch 830, train_loss 0.691
epoch 15, batch 840, train_loss 0.714
epoch 15, batch 850, train_loss 0.700
epoch 15, batch 860, train_loss 0.695
epoch 15, batch 870, train_loss 0.703
epoch 15, batch 880, train_loss 0.694
epoch 15, batch 890, train_loss 0.711
epoch 15, batch 900, train_loss 0.694
epoch 15, batch 910, train_loss 0.688
epoch 15, batch 920, train_loss 0.703
epoch 15, batch 930, train_loss 0.698
epoch 15, batch 940, train_loss 0.694
epoch 15, batch 950, train_loss 0.698
epoch 15, batch 960, train_loss 0.697
epoch 15, batch 970, train_loss 0.705
epoch 15, batch 980, train_loss 0.713
epoch 15, batch 990, train_loss 0.703
epoch 15, batch 1000, train_loss 0.691
epoch 15, batch 1010, train_loss 0.692
epoch 15, batch 1020, train_loss 0.715
epoch 15, batch 1030, train_loss 0.699
epoch 15, batch 1040, train_loss 0.703
epoch 15, batch 1050, train_loss 0.699
epoch 15, batch 1060, train_loss 0.699
epoch 15, batch 1070, train_loss 0.700
epoch 15, batch 1080, train_loss 0.696
epoch 15, batch 1090, train_loss 0.693
epoch 15, batch 1100, train_loss 0.702
epoch 15, batch 1110, train_loss 0.702
epoch 15, batch 1120, train_loss 0.696
epoch 15, batch 1130, train_loss 0.699
epoch 15, batch 1140, train_loss 0.696
epoch 15, batch 1150, train_loss 0.701
epoch 15, batch 1160, train_loss 0.693
epoch 15, batch 1170, train_loss 0.700
epoch 15, batch 1180, train_loss 0.703
epoch 15, batch 1190, train_loss 0.697
epoch 15, train_loss 0.697, valid_loss 0.722, train_accuracy  69.98%, valid_accuracy  68.58%
epoch 16, batch 0, train_loss 0.702
epoch 16, batch 10, train_loss 0.694
epoch 16, batch 20, train_loss 0.692
epoch 16, batch 30, train_loss 0.697
epoch 16, batch 40, train_loss 0.707
epoch 16, batch 50, train_loss 0.695
epoch 16, batch 60, train_loss 0.691
epoch 16, batch 70, train_loss 0.689
epoch 16, batch 80, train_loss 0.708
epoch 16, batch 90, train_loss 0.703
epoch 16, batch 100, train_loss 0.696
epoch 16, batch 110, train_loss 0.698
epoch 16, batch 120, train_loss 0.699
epoch 16, batch 130, train_loss 0.695
epoch 16, batch 140, train_loss 0.690
epoch 16, batch 150, train_loss 0.694
epoch 16, batch 160, train_loss 0.696
epoch 16, batch 170, train_loss 0.699
epoch 16, batch 180, train_loss 0.691
epoch 16, batch 190, train_loss 0.690
epoch 16, batch 200, train_loss 0.694
epoch 16, batch 210, train_loss 0.691
epoch 16, batch 220, train_loss 0.710
epoch 16, batch 230, train_loss 0.689
epoch 16, batch 240, train_loss 0.699
epoch 16, batch 250, train_loss 0.707
epoch 16, batch 260, train_loss 0.695
epoch 16, batch 270, train_loss 0.683
epoch 16, batch 280, train_loss 0.699
epoch 16, batch 290, train_loss 0.693
epoch 16, batch 300, train_loss 0.696
epoch 16, batch 310, train_loss 0.706
epoch 16, batch 320, train_loss 0.704
epoch 16, batch 330, train_loss 0.697
epoch 16, batch 340, train_loss 0.697
epoch 16, batch 350, train_loss 0.676
epoch 16, batch 360, train_loss 0.696
epoch 16, batch 370, train_loss 0.695
epoch 16, batch 380, train_loss 0.698
epoch 16, batch 390, train_loss 0.702
epoch 16, batch 400, train_loss 0.696
epoch 16, batch 410, train_loss 0.692
epoch 16, batch 420, train_loss 0.693
epoch 16, batch 430, train_loss 0.689
epoch 16, batch 440, train_loss 0.702
epoch 16, batch 450, train_loss 0.692
epoch 16, batch 460, train_loss 0.705
epoch 16, batch 470, train_loss 0.703
epoch 16, batch 480, train_loss 0.692
epoch 16, batch 490, train_loss 0.699
epoch 16, batch 500, train_loss 0.699
epoch 16, batch 510, train_loss 0.699
epoch 16, batch 520, train_loss 0.702
epoch 16, batch 530, train_loss 0.703
epoch 16, batch 540, train_loss 0.698
epoch 16, batch 550, train_loss 0.691
epoch 16, batch 560, train_loss 0.694
epoch 16, batch 570, train_loss 0.689
epoch 16, batch 580, train_loss 0.704
epoch 16, batch 590, train_loss 0.702
epoch 16, batch 600, train_loss 0.702
epoch 16, batch 610, train_loss 0.693
epoch 16, batch 620, train_loss 0.696
epoch 16, batch 630, train_loss 0.702
epoch 16, batch 640, train_loss 0.690
epoch 16, batch 650, train_loss 0.695
epoch 16, batch 660, train_loss 0.710
epoch 16, batch 670, train_loss 0.704
epoch 16, batch 680, train_loss 0.692
epoch 16, batch 690, train_loss 0.693
epoch 16, batch 700, train_loss 0.693
epoch 16, batch 710, train_loss 0.711
epoch 16, batch 720, train_loss 0.699
epoch 16, batch 730, train_loss 0.700
epoch 16, batch 740, train_loss 0.703
epoch 16, batch 750, train_loss 0.698
epoch 16, batch 760, train_loss 0.698
epoch 16, batch 770, train_loss 0.703
epoch 16, batch 780, train_loss 0.696
epoch 16, batch 790, train_loss 0.702
epoch 16, batch 800, train_loss 0.699
epoch 16, batch 810, train_loss 0.689
epoch 16, batch 820, train_loss 0.694
epoch 16, batch 830, train_loss 0.694
epoch 16, batch 840, train_loss 0.708
epoch 16, batch 850, train_loss 0.699
epoch 16, batch 860, train_loss 0.690
epoch 16, batch 870, train_loss 0.690
epoch 16, batch 880, train_loss 0.692
epoch 16, batch 890, train_loss 0.703
epoch 16, batch 900, train_loss 0.701
epoch 16, batch 910, train_loss 0.697
epoch 16, batch 920, train_loss 0.707
epoch 16, batch 930, train_loss 0.687
epoch 16, batch 940, train_loss 0.697
epoch 16, batch 950, train_loss 0.702
epoch 16, batch 960, train_loss 0.696
epoch 16, batch 970, train_loss 0.707
epoch 16, batch 980, train_loss 0.698
epoch 16, batch 990, train_loss 0.694
epoch 16, batch 1000, train_loss 0.703
epoch 16, batch 1010, train_loss 0.682
epoch 16, batch 1020, train_loss 0.707
epoch 16, batch 1030, train_loss 0.697
epoch 16, batch 1040, train_loss 0.701
epoch 16, batch 1050, train_loss 0.698
epoch 16, batch 1060, train_loss 0.696
epoch 16, batch 1070, train_loss 0.688
epoch 16, batch 1080, train_loss 0.698
epoch 16, batch 1090, train_loss 0.700
epoch 16, batch 1100, train_loss 0.694
epoch 16, batch 1110, train_loss 0.703
epoch 16, batch 1120, train_loss 0.695
epoch 16, batch 1130, train_loss 0.699
epoch 16, batch 1140, train_loss 0.692
epoch 16, batch 1150, train_loss 0.694
epoch 16, batch 1160, train_loss 0.701
epoch 16, batch 1170, train_loss 0.695
epoch 16, batch 1180, train_loss 0.701
epoch 16, batch 1190, train_loss 0.697
epoch 16, train_loss 0.697, valid_loss 0.722, train_accuracy  70.00%, valid_accuracy  68.57%
epoch 17, batch 0, train_loss 0.697
epoch 17, batch 10, train_loss 0.691
epoch 17, batch 20, train_loss 0.698
epoch 17, batch 30, train_loss 0.693
epoch 17, batch 40, train_loss 0.701
epoch 17, batch 50, train_loss 0.695
epoch 17, batch 60, train_loss 0.695
epoch 17, batch 70, train_loss 0.694
epoch 17, batch 80, train_loss 0.698
epoch 17, batch 90, train_loss 0.696
epoch 17, batch 100, train_loss 0.701
epoch 17, batch 110, train_loss 0.696
epoch 17, batch 120, train_loss 0.695
epoch 17, batch 130, train_loss 0.698
epoch 17, batch 140, train_loss 0.697
epoch 17, batch 150, train_loss 0.697
epoch 17, batch 160, train_loss 0.699
epoch 17, batch 170, train_loss 0.705
epoch 17, batch 180, train_loss 0.701
epoch 17, batch 190, train_loss 0.697
epoch 17, batch 200, train_loss 0.697
epoch 17, batch 210, train_loss 0.699
epoch 17, batch 220, train_loss 0.700
epoch 17, batch 230, train_loss 0.695
epoch 17, batch 240, train_loss 0.702
epoch 17, batch 250, train_loss 0.701
epoch 17, batch 260, train_loss 0.699
epoch 17, batch 270, train_loss 0.694
epoch 17, batch 280, train_loss 0.697
epoch 17, batch 290, train_loss 0.698
epoch 17, batch 300, train_loss 0.704
epoch 17, batch 310, train_loss 0.707
epoch 17, batch 320, train_loss 0.687
epoch 17, batch 330, train_loss 0.697
epoch 17, batch 340, train_loss 0.696
epoch 17, batch 350, train_loss 0.698
epoch 17, batch 360, train_loss 0.696
epoch 17, batch 370, train_loss 0.693
epoch 17, batch 380, train_loss 0.696
epoch 17, batch 390, train_loss 0.705
epoch 17, batch 400, train_loss 0.693
epoch 17, batch 410, train_loss 0.700
epoch 17, batch 420, train_loss 0.694
epoch 17, batch 430, train_loss 0.697
epoch 17, batch 440, train_loss 0.705
epoch 17, batch 450, train_loss 0.695
epoch 17, batch 460, train_loss 0.707
epoch 17, batch 470, train_loss 0.692
epoch 17, batch 480, train_loss 0.704
epoch 17, batch 490, train_loss 0.702
epoch 17, batch 500, train_loss 0.693
epoch 17, batch 510, train_loss 0.693
epoch 17, batch 520, train_loss 0.697
epoch 17, batch 530, train_loss 0.696
epoch 17, batch 540, train_loss 0.691
epoch 17, batch 550, train_loss 0.697
epoch 17, batch 560, train_loss 0.696
epoch 17, batch 570, train_loss 0.698
epoch 17, batch 580, train_loss 0.697
epoch 17, batch 590, train_loss 0.692
epoch 17, batch 600, train_loss 0.690
epoch 17, batch 610, train_loss 0.694
epoch 17, batch 620, train_loss 0.695
epoch 17, batch 630, train_loss 0.692
epoch 17, batch 640, train_loss 0.695
epoch 17, batch 650, train_loss 0.697
epoch 17, batch 660, train_loss 0.692
epoch 17, batch 670, train_loss 0.692
epoch 17, batch 680, train_loss 0.708
epoch 17, batch 690, train_loss 0.706
epoch 17, batch 700, train_loss 0.708
epoch 17, batch 710, train_loss 0.696
epoch 17, batch 720, train_loss 0.702
epoch 17, batch 730, train_loss 0.696
epoch 17, batch 740, train_loss 0.704
epoch 17, batch 750, train_loss 0.696
epoch 17, batch 760, train_loss 0.691
epoch 17, batch 770, train_loss 0.696
epoch 17, batch 780, train_loss 0.699
epoch 17, batch 790, train_loss 0.700
epoch 17, batch 800, train_loss 0.700
epoch 17, batch 810, train_loss 0.702
epoch 17, batch 820, train_loss 0.695
epoch 17, batch 830, train_loss 0.701
epoch 17, batch 840, train_loss 0.696
epoch 17, batch 850, train_loss 0.697
epoch 17, batch 860, train_loss 0.695
epoch 17, batch 870, train_loss 0.699
epoch 17, batch 880, train_loss 0.703
epoch 17, batch 890, train_loss 0.698
epoch 17, batch 900, train_loss 0.688
epoch 17, batch 910, train_loss 0.697
epoch 17, batch 920, train_loss 0.700
epoch 17, batch 930, train_loss 0.698
epoch 17, batch 940, train_loss 0.690
epoch 17, batch 950, train_loss 0.688
epoch 17, batch 960, train_loss 0.693
epoch 17, batch 970, train_loss 0.707
epoch 17, batch 980, train_loss 0.702
epoch 17, batch 990, train_loss 0.697
epoch 17, batch 1000, train_loss 0.704
epoch 17, batch 1010, train_loss 0.695
epoch 17, batch 1020, train_loss 0.683
epoch 17, batch 1030, train_loss 0.700
epoch 17, batch 1040, train_loss 0.705
epoch 17, batch 1050, train_loss 0.698
epoch 17, batch 1060, train_loss 0.698
epoch 17, batch 1070, train_loss 0.698
epoch 17, batch 1080, train_loss 0.695
epoch 17, batch 1090, train_loss 0.702
epoch 17, batch 1100, train_loss 0.696
epoch 17, batch 1110, train_loss 0.697
epoch 17, batch 1120, train_loss 0.705
epoch 17, batch 1130, train_loss 0.695
epoch 17, batch 1140, train_loss 0.701
epoch 17, batch 1150, train_loss 0.686
epoch 17, batch 1160, train_loss 0.703
epoch 17, batch 1170, train_loss 0.698
epoch 17, batch 1180, train_loss 0.694
epoch 17, batch 1190, train_loss 0.701
epoch 17, train_loss 0.696, valid_loss 0.722, train_accuracy  70.01%, valid_accuracy  68.59%
epoch 18, batch 0, train_loss 0.697
epoch 18, batch 10, train_loss 0.693
epoch 18, batch 20, train_loss 0.691
epoch 18, batch 30, train_loss 0.706
epoch 18, batch 40, train_loss 0.702
epoch 18, batch 50, train_loss 0.699
epoch 18, batch 60, train_loss 0.704
epoch 18, batch 70, train_loss 0.700
epoch 18, batch 80, train_loss 0.700
epoch 18, batch 90, train_loss 0.701
epoch 18, batch 100, train_loss 0.698
epoch 18, batch 110, train_loss 0.699
epoch 18, batch 120, train_loss 0.701
epoch 18, batch 130, train_loss 0.700
epoch 18, batch 140, train_loss 0.699
epoch 18, batch 150, train_loss 0.694
epoch 18, batch 160, train_loss 0.708
epoch 18, batch 170, train_loss 0.685
epoch 18, batch 180, train_loss 0.700
epoch 18, batch 190, train_loss 0.692
epoch 18, batch 200, train_loss 0.693
epoch 18, batch 210, train_loss 0.701
epoch 18, batch 220, train_loss 0.705
epoch 18, batch 230, train_loss 0.701
epoch 18, batch 240, train_loss 0.697
epoch 18, batch 250, train_loss 0.699
epoch 18, batch 260, train_loss 0.706
epoch 18, batch 270, train_loss 0.693
epoch 18, batch 280, train_loss 0.693
epoch 18, batch 290, train_loss 0.690
epoch 18, batch 300, train_loss 0.708
epoch 18, batch 310, train_loss 0.697
epoch 18, batch 320, train_loss 0.706
epoch 18, batch 330, train_loss 0.706
epoch 18, batch 340, train_loss 0.709
epoch 18, batch 350, train_loss 0.700
epoch 18, batch 360, train_loss 0.702
epoch 18, batch 370, train_loss 0.698
epoch 18, batch 380, train_loss 0.693
epoch 18, batch 390, train_loss 0.696
epoch 18, batch 400, train_loss 0.694
epoch 18, batch 410, train_loss 0.692
epoch 18, batch 420, train_loss 0.691
epoch 18, batch 430, train_loss 0.693
epoch 18, batch 440, train_loss 0.697
epoch 18, batch 450, train_loss 0.699
epoch 18, batch 460, train_loss 0.696
epoch 18, batch 470, train_loss 0.688
epoch 18, batch 480, train_loss 0.694
epoch 18, batch 490, train_loss 0.696
epoch 18, batch 500, train_loss 0.703
epoch 18, batch 510, train_loss 0.707
epoch 18, batch 520, train_loss 0.704
epoch 18, batch 530, train_loss 0.705
epoch 18, batch 540, train_loss 0.696
epoch 18, batch 550, train_loss 0.696
epoch 18, batch 560, train_loss 0.692
epoch 18, batch 570, train_loss 0.703
epoch 18, batch 580, train_loss 0.699
epoch 18, batch 590, train_loss 0.701
epoch 18, batch 600, train_loss 0.709
epoch 18, batch 610, train_loss 0.690
epoch 18, batch 620, train_loss 0.691
epoch 18, batch 630, train_loss 0.686
epoch 18, batch 640, train_loss 0.697
epoch 18, batch 650, train_loss 0.703
epoch 18, batch 660, train_loss 0.693
epoch 18, batch 670, train_loss 0.694
epoch 18, batch 680, train_loss 0.704
epoch 18, batch 690, train_loss 0.697
epoch 18, batch 700, train_loss 0.691
epoch 18, batch 710, train_loss 0.703
epoch 18, batch 720, train_loss 0.694
epoch 18, batch 730, train_loss 0.700
epoch 18, batch 740, train_loss 0.694
epoch 18, batch 750, train_loss 0.709
epoch 18, batch 760, train_loss 0.698
epoch 18, batch 770, train_loss 0.705
epoch 18, batch 780, train_loss 0.689
epoch 18, batch 790, train_loss 0.689
epoch 18, batch 800, train_loss 0.687
epoch 18, batch 810, train_loss 0.696
epoch 18, batch 820, train_loss 0.704
epoch 18, batch 830, train_loss 0.698
epoch 18, batch 840, train_loss 0.701
epoch 18, batch 850, train_loss 0.703
epoch 18, batch 860, train_loss 0.693
epoch 18, batch 870, train_loss 0.686
epoch 18, batch 880, train_loss 0.697
epoch 18, batch 890, train_loss 0.695
epoch 18, batch 900, train_loss 0.695
epoch 18, batch 910, train_loss 0.693
epoch 18, batch 920, train_loss 0.699
epoch 18, batch 930, train_loss 0.699
epoch 18, batch 940, train_loss 0.700
epoch 18, batch 950, train_loss 0.699
epoch 18, batch 960, train_loss 0.693
epoch 18, batch 970, train_loss 0.697
epoch 18, batch 980, train_loss 0.688
epoch 18, batch 990, train_loss 0.697
epoch 18, batch 1000, train_loss 0.698
epoch 18, batch 1010, train_loss 0.698
epoch 18, batch 1020, train_loss 0.690
epoch 18, batch 1030, train_loss 0.689
epoch 18, batch 1040, train_loss 0.706
epoch 18, batch 1050, train_loss 0.697
epoch 18, batch 1060, train_loss 0.685
epoch 18, batch 1070, train_loss 0.703
epoch 18, batch 1080, train_loss 0.699
epoch 18, batch 1090, train_loss 0.698
epoch 18, batch 1100, train_loss 0.697
epoch 18, batch 1110, train_loss 0.696
epoch 18, batch 1120, train_loss 0.691
epoch 18, batch 1130, train_loss 0.703
epoch 18, batch 1140, train_loss 0.694
epoch 18, batch 1150, train_loss 0.692
epoch 18, batch 1160, train_loss 0.701
epoch 18, batch 1170, train_loss 0.700
epoch 18, batch 1180, train_loss 0.692
epoch 18, batch 1190, train_loss 0.690
epoch 18, train_loss 0.696, valid_loss 0.722, train_accuracy  70.04%, valid_accuracy  68.56%
epoch 19, batch 0, train_loss 0.702
epoch 19, batch 10, train_loss 0.696
epoch 19, batch 20, train_loss 0.691
epoch 19, batch 30, train_loss 0.691
epoch 19, batch 40, train_loss 0.689
epoch 19, batch 50, train_loss 0.690
epoch 19, batch 60, train_loss 0.690
epoch 19, batch 70, train_loss 0.694
epoch 19, batch 80, train_loss 0.707
epoch 19, batch 90, train_loss 0.705
epoch 19, batch 100, train_loss 0.699
epoch 19, batch 110, train_loss 0.692
epoch 19, batch 120, train_loss 0.695
epoch 19, batch 130, train_loss 0.692
epoch 19, batch 140, train_loss 0.701
epoch 19, batch 150, train_loss 0.686
epoch 19, batch 160, train_loss 0.695
epoch 19, batch 170, train_loss 0.689
epoch 19, batch 180, train_loss 0.702
epoch 19, batch 190, train_loss 0.698
epoch 19, batch 200, train_loss 0.694
epoch 19, batch 210, train_loss 0.697
epoch 19, batch 220, train_loss 0.704
epoch 19, batch 230, train_loss 0.696
epoch 19, batch 240, train_loss 0.684
epoch 19, batch 250, train_loss 0.692
epoch 19, batch 260, train_loss 0.693
epoch 19, batch 270, train_loss 0.708
epoch 19, batch 280, train_loss 0.702
epoch 19, batch 290, train_loss 0.697
epoch 19, batch 300, train_loss 0.700
epoch 19, batch 310, train_loss 0.688
epoch 19, batch 320, train_loss 0.698
epoch 19, batch 330, train_loss 0.700
epoch 19, batch 340, train_loss 0.695
epoch 19, batch 350, train_loss 0.697
epoch 19, batch 360, train_loss 0.702
epoch 19, batch 370, train_loss 0.705
epoch 19, batch 380, train_loss 0.702
epoch 19, batch 390, train_loss 0.702
epoch 19, batch 400, train_loss 0.697
epoch 19, batch 410, train_loss 0.705
epoch 19, batch 420, train_loss 0.706
epoch 19, batch 430, train_loss 0.695
epoch 19, batch 440, train_loss 0.708
epoch 19, batch 450, train_loss 0.697
epoch 19, batch 460, train_loss 0.698
epoch 19, batch 470, train_loss 0.693
epoch 19, batch 480, train_loss 0.695
epoch 19, batch 490, train_loss 0.690
epoch 19, batch 500, train_loss 0.696
epoch 19, batch 510, train_loss 0.695
epoch 19, batch 520, train_loss 0.701
epoch 19, batch 530, train_loss 0.690
epoch 19, batch 540, train_loss 0.710
epoch 19, batch 550, train_loss 0.696
epoch 19, batch 560, train_loss 0.694
epoch 19, batch 570, train_loss 0.704
epoch 19, batch 580, train_loss 0.699
epoch 19, batch 590, train_loss 0.693
epoch 19, batch 600, train_loss 0.694
epoch 19, batch 610, train_loss 0.698
epoch 19, batch 620, train_loss 0.704
epoch 19, batch 630, train_loss 0.694
epoch 19, batch 640, train_loss 0.697
epoch 19, batch 650, train_loss 0.704
epoch 19, batch 660, train_loss 0.695
epoch 19, batch 670, train_loss 0.692
epoch 19, batch 680, train_loss 0.705
epoch 19, batch 690, train_loss 0.698
epoch 19, batch 700, train_loss 0.699
epoch 19, batch 710, train_loss 0.704
epoch 19, batch 720, train_loss 0.700
epoch 19, batch 730, train_loss 0.693
epoch 19, batch 740, train_loss 0.695
epoch 19, batch 750, train_loss 0.695
epoch 19, batch 760, train_loss 0.696
epoch 19, batch 770, train_loss 0.687
epoch 19, batch 780, train_loss 0.691
epoch 19, batch 790, train_loss 0.697
epoch 19, batch 800, train_loss 0.686
epoch 19, batch 810, train_loss 0.702
epoch 19, batch 820, train_loss 0.692
epoch 19, batch 830, train_loss 0.695
epoch 19, batch 840, train_loss 0.689
epoch 19, batch 850, train_loss 0.704
epoch 19, batch 860, train_loss 0.703
epoch 19, batch 870, train_loss 0.692
epoch 19, batch 880, train_loss 0.709
epoch 19, batch 890, train_loss 0.699
epoch 19, batch 900, train_loss 0.699
epoch 19, batch 910, train_loss 0.692
epoch 19, batch 920, train_loss 0.697
epoch 19, batch 930, train_loss 0.696
epoch 19, batch 940, train_loss 0.702
epoch 19, batch 950, train_loss 0.695
epoch 19, batch 960, train_loss 0.690
epoch 19, batch 970, train_loss 0.703
epoch 19, batch 980, train_loss 0.693
epoch 19, batch 990, train_loss 0.696
epoch 19, batch 1000, train_loss 0.695
epoch 19, batch 1010, train_loss 0.681
epoch 19, batch 1020, train_loss 0.707
epoch 19, batch 1030, train_loss 0.700
epoch 19, batch 1040, train_loss 0.694
epoch 19, batch 1050, train_loss 0.702
epoch 19, batch 1060, train_loss 0.707
epoch 19, batch 1070, train_loss 0.695
epoch 19, batch 1080, train_loss 0.693
epoch 19, batch 1090, train_loss 0.698
epoch 19, batch 1100, train_loss 0.690
epoch 19, batch 1110, train_loss 0.687
epoch 19, batch 1120, train_loss 0.691
epoch 19, batch 1130, train_loss 0.693
epoch 19, batch 1140, train_loss 0.692
epoch 19, batch 1150, train_loss 0.698
epoch 19, batch 1160, train_loss 0.701
epoch 19, batch 1170, train_loss 0.699
epoch 19, batch 1180, train_loss 0.693
epoch 19, batch 1190, train_loss 0.702
epoch 19, train_loss 0.696, valid_loss 0.722, train_accuracy  70.04%, valid_accuracy  68.59%
epoch 20, batch 0, train_loss 0.685
epoch 20, batch 10, train_loss 0.699
epoch 20, batch 20, train_loss 0.691
epoch 20, batch 30, train_loss 0.693
epoch 20, batch 40, train_loss 0.701
epoch 20, batch 50, train_loss 0.689
epoch 20, batch 60, train_loss 0.693
epoch 20, batch 70, train_loss 0.699
epoch 20, batch 80, train_loss 0.711
epoch 20, batch 90, train_loss 0.696
epoch 20, batch 100, train_loss 0.697
epoch 20, batch 110, train_loss 0.691
epoch 20, batch 120, train_loss 0.690
epoch 20, batch 130, train_loss 0.696
epoch 20, batch 140, train_loss 0.689
epoch 20, batch 150, train_loss 0.692
epoch 20, batch 160, train_loss 0.691
epoch 20, batch 170, train_loss 0.705
epoch 20, batch 180, train_loss 0.693
epoch 20, batch 190, train_loss 0.696
epoch 20, batch 200, train_loss 0.691
epoch 20, batch 210, train_loss 0.695
epoch 20, batch 220, train_loss 0.698
epoch 20, batch 230, train_loss 0.706
epoch 20, batch 240, train_loss 0.694
epoch 20, batch 250, train_loss 0.694
epoch 20, batch 260, train_loss 0.700
epoch 20, batch 270, train_loss 0.693
epoch 20, batch 280, train_loss 0.700
epoch 20, batch 290, train_loss 0.690
epoch 20, batch 300, train_loss 0.691
epoch 20, batch 310, train_loss 0.701
epoch 20, batch 320, train_loss 0.700
epoch 20, batch 330, train_loss 0.696
epoch 20, batch 340, train_loss 0.699
epoch 20, batch 350, train_loss 0.700
epoch 20, batch 360, train_loss 0.692
epoch 20, batch 370, train_loss 0.692
epoch 20, batch 380, train_loss 0.696
epoch 20, batch 390, train_loss 0.700
epoch 20, batch 400, train_loss 0.700
epoch 20, batch 410, train_loss 0.704
epoch 20, batch 420, train_loss 0.702
epoch 20, batch 430, train_loss 0.700
epoch 20, batch 440, train_loss 0.693
epoch 20, batch 450, train_loss 0.708
epoch 20, batch 460, train_loss 0.703
epoch 20, batch 470, train_loss 0.702
epoch 20, batch 480, train_loss 0.694
epoch 20, batch 490, train_loss 0.704
epoch 20, batch 500, train_loss 0.698
epoch 20, batch 510, train_loss 0.690
epoch 20, batch 520, train_loss 0.705
epoch 20, batch 530, train_loss 0.697
epoch 20, batch 540, train_loss 0.700
epoch 20, batch 550, train_loss 0.685
epoch 20, batch 560, train_loss 0.702
epoch 20, batch 570, train_loss 0.701
epoch 20, batch 580, train_loss 0.697
epoch 20, batch 590, train_loss 0.693
epoch 20, batch 600, train_loss 0.694
epoch 20, batch 610, train_loss 0.705
epoch 20, batch 620, train_loss 0.691
epoch 20, batch 630, train_loss 0.705
epoch 20, batch 640, train_loss 0.700
epoch 20, batch 650, train_loss 0.689
epoch 20, batch 660, train_loss 0.697
epoch 20, batch 670, train_loss 0.694
epoch 20, batch 680, train_loss 0.697
epoch 20, batch 690, train_loss 0.691
epoch 20, batch 700, train_loss 0.705
epoch 20, batch 710, train_loss 0.688
epoch 20, batch 720, train_loss 0.687
epoch 20, batch 730, train_loss 0.697
epoch 20, batch 740, train_loss 0.698
epoch 20, batch 750, train_loss 0.693
epoch 20, batch 760, train_loss 0.707
epoch 20, batch 770, train_loss 0.690
epoch 20, batch 780, train_loss 0.701
epoch 20, batch 790, train_loss 0.697
epoch 20, batch 800, train_loss 0.685
epoch 20, batch 810, train_loss 0.698
epoch 20, batch 820, train_loss 0.702
epoch 20, batch 830, train_loss 0.697
epoch 20, batch 840, train_loss 0.701
epoch 20, batch 850, train_loss 0.697
epoch 20, batch 860, train_loss 0.691
epoch 20, batch 870, train_loss 0.684
epoch 20, batch 880, train_loss 0.702
epoch 20, batch 890, train_loss 0.702
epoch 20, batch 900, train_loss 0.701
epoch 20, batch 910, train_loss 0.704
epoch 20, batch 920, train_loss 0.695
epoch 20, batch 930, train_loss 0.693
epoch 20, batch 940, train_loss 0.692
epoch 20, batch 950, train_loss 0.696
epoch 20, batch 960, train_loss 0.700
epoch 20, batch 970, train_loss 0.703
epoch 20, batch 980, train_loss 0.695
epoch 20, batch 990, train_loss 0.691
epoch 20, batch 1000, train_loss 0.701
epoch 20, batch 1010, train_loss 0.694
epoch 20, batch 1020, train_loss 0.699
epoch 20, batch 1030, train_loss 0.698
epoch 20, batch 1040, train_loss 0.688
epoch 20, batch 1050, train_loss 0.688
epoch 20, batch 1060, train_loss 0.700
epoch 20, batch 1070, train_loss 0.694
epoch 20, batch 1080, train_loss 0.700
epoch 20, batch 1090, train_loss 0.693
epoch 20, batch 1100, train_loss 0.696
epoch 20, batch 1110, train_loss 0.701
epoch 20, batch 1120, train_loss 0.695
epoch 20, batch 1130, train_loss 0.699
epoch 20, batch 1140, train_loss 0.696
epoch 20, batch 1150, train_loss 0.695
epoch 20, batch 1160, train_loss 0.700
epoch 20, batch 1170, train_loss 0.693
epoch 20, batch 1180, train_loss 0.693
epoch 20, batch 1190, train_loss 0.709
epoch 20, train_loss 0.695, valid_loss 0.723, train_accuracy  70.08%, valid_accuracy  68.56%
epoch 21, batch 0, train_loss 0.701
epoch 21, batch 10, train_loss 0.695
epoch 21, batch 20, train_loss 0.690
epoch 21, batch 30, train_loss 0.697
epoch 21, batch 40, train_loss 0.697
epoch 21, batch 50, train_loss 0.691
epoch 21, batch 60, train_loss 0.700
epoch 21, batch 70, train_loss 0.691
epoch 21, batch 80, train_loss 0.698
epoch 21, batch 90, train_loss 0.690
epoch 21, batch 100, train_loss 0.699
epoch 21, batch 110, train_loss 0.695
epoch 21, batch 120, train_loss 0.698
epoch 21, batch 130, train_loss 0.687
epoch 21, batch 140, train_loss 0.699
epoch 21, batch 150, train_loss 0.696
epoch 21, batch 160, train_loss 0.700
epoch 21, batch 170, train_loss 0.695
epoch 21, batch 180, train_loss 0.694
epoch 21, batch 190, train_loss 0.708
epoch 21, batch 200, train_loss 0.703
epoch 21, batch 210, train_loss 0.700
epoch 21, batch 220, train_loss 0.702
epoch 21, batch 230, train_loss 0.707
epoch 21, batch 240, train_loss 0.692
epoch 21, batch 250, train_loss 0.700
epoch 21, batch 260, train_loss 0.705
epoch 21, batch 270, train_loss 0.701
epoch 21, batch 280, train_loss 0.703
epoch 21, batch 290, train_loss 0.694
epoch 21, batch 300, train_loss 0.703
epoch 21, batch 310, train_loss 0.700
epoch 21, batch 320, train_loss 0.702
epoch 21, batch 330, train_loss 0.697
epoch 21, batch 340, train_loss 0.696
epoch 21, batch 350, train_loss 0.695
epoch 21, batch 360, train_loss 0.699
epoch 21, batch 370, train_loss 0.692
epoch 21, batch 380, train_loss 0.691
epoch 21, batch 390, train_loss 0.705
epoch 21, batch 400, train_loss 0.700
epoch 21, batch 410, train_loss 0.690
epoch 21, batch 420, train_loss 0.691
epoch 21, batch 430, train_loss 0.694
epoch 21, batch 440, train_loss 0.704
epoch 21, batch 450, train_loss 0.693
epoch 21, batch 460, train_loss 0.696
epoch 21, batch 470, train_loss 0.702
epoch 21, batch 480, train_loss 0.690
epoch 21, batch 490, train_loss 0.684
epoch 21, batch 500, train_loss 0.694
epoch 21, batch 510, train_loss 0.693
epoch 21, batch 520, train_loss 0.690
epoch 21, batch 530, train_loss 0.701
epoch 21, batch 540, train_loss 0.706
epoch 21, batch 550, train_loss 0.699
epoch 21, batch 560, train_loss 0.697
epoch 21, batch 570, train_loss 0.695
epoch 21, batch 580, train_loss 0.698
epoch 21, batch 590, train_loss 0.700
epoch 21, batch 600, train_loss 0.693
epoch 21, batch 610, train_loss 0.700
epoch 21, batch 620, train_loss 0.693
epoch 21, batch 630, train_loss 0.699
epoch 21, batch 640, train_loss 0.704
epoch 21, batch 650, train_loss 0.701
epoch 21, batch 660, train_loss 0.694
epoch 21, batch 670, train_loss 0.689
epoch 21, batch 680, train_loss 0.697
epoch 21, batch 690, train_loss 0.701
epoch 21, batch 700, train_loss 0.688
epoch 21, batch 710, train_loss 0.707
epoch 21, batch 720, train_loss 0.696
epoch 21, batch 730, train_loss 0.698
epoch 21, batch 740, train_loss 0.689
epoch 21, batch 750, train_loss 0.696
epoch 21, batch 760, train_loss 0.695
epoch 21, batch 770, train_loss 0.694
epoch 21, batch 780, train_loss 0.697
epoch 21, batch 790, train_loss 0.697
epoch 21, batch 800, train_loss 0.697
epoch 21, batch 810, train_loss 0.693
epoch 21, batch 820, train_loss 0.691
epoch 21, batch 830, train_loss 0.703
epoch 21, batch 840, train_loss 0.689
epoch 21, batch 850, train_loss 0.685
epoch 21, batch 860, train_loss 0.704
epoch 21, batch 870, train_loss 0.696
epoch 21, batch 880, train_loss 0.699
epoch 21, batch 890, train_loss 0.695
epoch 21, batch 900, train_loss 0.694
epoch 21, batch 910, train_loss 0.699
epoch 21, batch 920, train_loss 0.696
epoch 21, batch 930, train_loss 0.695
epoch 21, batch 940, train_loss 0.698
epoch 21, batch 950, train_loss 0.694
epoch 21, batch 960, train_loss 0.698
epoch 21, batch 970, train_loss 0.702
epoch 21, batch 980, train_loss 0.697
epoch 21, batch 990, train_loss 0.700
epoch 21, batch 1000, train_loss 0.699
epoch 21, batch 1010, train_loss 0.691
epoch 21, batch 1020, train_loss 0.686
epoch 21, batch 1030, train_loss 0.697
epoch 21, batch 1040, train_loss 0.706
epoch 21, batch 1050, train_loss 0.691
epoch 21, batch 1060, train_loss 0.682
epoch 21, batch 1070, train_loss 0.688
epoch 21, batch 1080, train_loss 0.701
epoch 21, batch 1090, train_loss 0.693
epoch 21, batch 1100, train_loss 0.694
epoch 21, batch 1110, train_loss 0.694
epoch 21, batch 1120, train_loss 0.697
epoch 21, batch 1130, train_loss 0.692
epoch 21, batch 1140, train_loss 0.695
epoch 21, batch 1150, train_loss 0.697
epoch 21, batch 1160, train_loss 0.702
epoch 21, batch 1170, train_loss 0.704
epoch 21, batch 1180, train_loss 0.695
epoch 21, batch 1190, train_loss 0.697
epoch 21, train_loss 0.695, valid_loss 0.722, train_accuracy  70.10%, valid_accuracy  68.60%
epoch 22, batch 0, train_loss 0.696
epoch 22, batch 10, train_loss 0.695
epoch 22, batch 20, train_loss 0.696
epoch 22, batch 30, train_loss 0.696
epoch 22, batch 40, train_loss 0.695
epoch 22, batch 50, train_loss 0.697
epoch 22, batch 60, train_loss 0.700
epoch 22, batch 70, train_loss 0.697
epoch 22, batch 80, train_loss 0.696
epoch 22, batch 90, train_loss 0.701
epoch 22, batch 100, train_loss 0.699
epoch 22, batch 110, train_loss 0.696
epoch 22, batch 120, train_loss 0.692
epoch 22, batch 130, train_loss 0.691
epoch 22, batch 140, train_loss 0.695
epoch 22, batch 150, train_loss 0.703
epoch 22, batch 160, train_loss 0.696
epoch 22, batch 170, train_loss 0.696
epoch 22, batch 180, train_loss 0.700
epoch 22, batch 190, train_loss 0.696
epoch 22, batch 200, train_loss 0.704
epoch 22, batch 210, train_loss 0.703
epoch 22, batch 220, train_loss 0.693
epoch 22, batch 230, train_loss 0.695
epoch 22, batch 240, train_loss 0.694
epoch 22, batch 250, train_loss 0.701
epoch 22, batch 260, train_loss 0.689
epoch 22, batch 270, train_loss 0.694
epoch 22, batch 280, train_loss 0.693
epoch 22, batch 290, train_loss 0.700
epoch 22, batch 300, train_loss 0.692
epoch 22, batch 310, train_loss 0.698
epoch 22, batch 320, train_loss 0.701
epoch 22, batch 330, train_loss 0.691
epoch 22, batch 340, train_loss 0.693
epoch 22, batch 350, train_loss 0.701
epoch 22, batch 360, train_loss 0.688
epoch 22, batch 370, train_loss 0.705
epoch 22, batch 380, train_loss 0.700
epoch 22, batch 390, train_loss 0.700
epoch 22, batch 400, train_loss 0.710
epoch 22, batch 410, train_loss 0.701
epoch 22, batch 420, train_loss 0.687
epoch 22, batch 430, train_loss 0.697
epoch 22, batch 440, train_loss 0.689
epoch 22, batch 450, train_loss 0.700
epoch 22, batch 460, train_loss 0.685
epoch 22, batch 470, train_loss 0.702
epoch 22, batch 480, train_loss 0.698
epoch 22, batch 490, train_loss 0.702
epoch 22, batch 500, train_loss 0.699
epoch 22, batch 510, train_loss 0.686
epoch 22, batch 520, train_loss 0.693
epoch 22, batch 530, train_loss 0.705
epoch 22, batch 540, train_loss 0.696
epoch 22, batch 550, train_loss 0.694
epoch 22, batch 560, train_loss 0.688
epoch 22, batch 570, train_loss 0.689
epoch 22, batch 580, train_loss 0.696
epoch 22, batch 590, train_loss 0.697
epoch 22, batch 600, train_loss 0.695
epoch 22, batch 610, train_loss 0.698
epoch 22, batch 620, train_loss 0.699
epoch 22, batch 630, train_loss 0.693
epoch 22, batch 640, train_loss 0.684
epoch 22, batch 650, train_loss 0.696
epoch 22, batch 660, train_loss 0.696
epoch 22, batch 670, train_loss 0.694
epoch 22, batch 680, train_loss 0.699
epoch 22, batch 690, train_loss 0.682
epoch 22, batch 700, train_loss 0.695
epoch 22, batch 710, train_loss 0.687
epoch 22, batch 720, train_loss 0.695
epoch 22, batch 730, train_loss 0.694
epoch 22, batch 740, train_loss 0.691
epoch 22, batch 750, train_loss 0.687
epoch 22, batch 760, train_loss 0.698
epoch 22, batch 770, train_loss 0.701
epoch 22, batch 780, train_loss 0.701
epoch 22, batch 790, train_loss 0.692
epoch 22, batch 800, train_loss 0.704
epoch 22, batch 810, train_loss 0.699
epoch 22, batch 820, train_loss 0.690
epoch 22, batch 830, train_loss 0.686
epoch 22, batch 840, train_loss 0.694
epoch 22, batch 850, train_loss 0.687
epoch 22, batch 860, train_loss 0.699
epoch 22, batch 870, train_loss 0.690
epoch 22, batch 880, train_loss 0.697
epoch 22, batch 890, train_loss 0.694
epoch 22, batch 900, train_loss 0.706
epoch 22, batch 910, train_loss 0.699
epoch 22, batch 920, train_loss 0.696
epoch 22, batch 930, train_loss 0.698
epoch 22, batch 940, train_loss 0.696
epoch 22, batch 950, train_loss 0.678
epoch 22, batch 960, train_loss 0.693
epoch 22, batch 970, train_loss 0.683
epoch 22, batch 980, train_loss 0.701
epoch 22, batch 990, train_loss 0.698
epoch 22, batch 1000, train_loss 0.693
epoch 22, batch 1010, train_loss 0.697
epoch 22, batch 1020, train_loss 0.699
epoch 22, batch 1030, train_loss 0.699
epoch 22, batch 1040, train_loss 0.693
epoch 22, batch 1050, train_loss 0.695
epoch 22, batch 1060, train_loss 0.695
epoch 22, batch 1070, train_loss 0.693
epoch 22, batch 1080, train_loss 0.701
epoch 22, batch 1090, train_loss 0.690
epoch 22, batch 1100, train_loss 0.697
epoch 22, batch 1110, train_loss 0.702
epoch 22, batch 1120, train_loss 0.695
epoch 22, batch 1130, train_loss 0.689
epoch 22, batch 1140, train_loss 0.696
epoch 22, batch 1150, train_loss 0.694
epoch 22, batch 1160, train_loss 0.705
epoch 22, batch 1170, train_loss 0.695
epoch 22, batch 1180, train_loss 0.692
epoch 22, batch 1190, train_loss 0.694
epoch 22, train_loss 0.695, valid_loss 0.723, train_accuracy  70.09%, valid_accuracy  68.56%
epoch 23, batch 0, train_loss 0.694
epoch 23, batch 10, train_loss 0.697
epoch 23, batch 20, train_loss 0.689
epoch 23, batch 30, train_loss 0.691
epoch 23, batch 40, train_loss 0.698
epoch 23, batch 50, train_loss 0.699
epoch 23, batch 60, train_loss 0.694
epoch 23, batch 70, train_loss 0.686
epoch 23, batch 80, train_loss 0.694
epoch 23, batch 90, train_loss 0.692
epoch 23, batch 100, train_loss 0.692
epoch 23, batch 110, train_loss 0.704
epoch 23, batch 120, train_loss 0.701
epoch 23, batch 130, train_loss 0.693
epoch 23, batch 140, train_loss 0.691
epoch 23, batch 150, train_loss 0.691
epoch 23, batch 160, train_loss 0.691
epoch 23, batch 170, train_loss 0.697
epoch 23, batch 180, train_loss 0.694
epoch 23, batch 190, train_loss 0.696
epoch 23, batch 200, train_loss 0.694
epoch 23, batch 210, train_loss 0.697
epoch 23, batch 220, train_loss 0.693
epoch 23, batch 230, train_loss 0.694
epoch 23, batch 240, train_loss 0.698
epoch 23, batch 250, train_loss 0.692
epoch 23, batch 260, train_loss 0.692
epoch 23, batch 270, train_loss 0.698
epoch 23, batch 280, train_loss 0.687
epoch 23, batch 290, train_loss 0.694
epoch 23, batch 300, train_loss 0.702
epoch 23, batch 310, train_loss 0.691
epoch 23, batch 320, train_loss 0.702
epoch 23, batch 330, train_loss 0.688
epoch 23, batch 340, train_loss 0.692
epoch 23, batch 350, train_loss 0.698
epoch 23, batch 360, train_loss 0.694
epoch 23, batch 370, train_loss 0.690
epoch 23, batch 380, train_loss 0.696
epoch 23, batch 390, train_loss 0.698
epoch 23, batch 400, train_loss 0.693
epoch 23, batch 410, train_loss 0.687
epoch 23, batch 420, train_loss 0.697
epoch 23, batch 430, train_loss 0.700
epoch 23, batch 440, train_loss 0.697
epoch 23, batch 450, train_loss 0.701
epoch 23, batch 460, train_loss 0.696
epoch 23, batch 470, train_loss 0.691
epoch 23, batch 480, train_loss 0.694
epoch 23, batch 490, train_loss 0.700
epoch 23, batch 500, train_loss 0.702
epoch 23, batch 510, train_loss 0.701
epoch 23, batch 520, train_loss 0.696
epoch 23, batch 530, train_loss 0.705
epoch 23, batch 540, train_loss 0.685
epoch 23, batch 550, train_loss 0.701
epoch 23, batch 560, train_loss 0.693
epoch 23, batch 570, train_loss 0.707
epoch 23, batch 580, train_loss 0.695
epoch 23, batch 590, train_loss 0.694
epoch 23, batch 600, train_loss 0.697
epoch 23, batch 610, train_loss 0.696
epoch 23, batch 620, train_loss 0.694
epoch 23, batch 630, train_loss 0.696
epoch 23, batch 640, train_loss 0.701
epoch 23, batch 650, train_loss 0.690
epoch 23, batch 660, train_loss 0.690
epoch 23, batch 670, train_loss 0.696
epoch 23, batch 680, train_loss 0.699
epoch 23, batch 690, train_loss 0.702
epoch 23, batch 700, train_loss 0.700
epoch 23, batch 710, train_loss 0.697
epoch 23, batch 720, train_loss 0.693
epoch 23, batch 730, train_loss 0.683
epoch 23, batch 740, train_loss 0.697
epoch 23, batch 750, train_loss 0.686
epoch 23, batch 760, train_loss 0.696
epoch 23, batch 770, train_loss 0.694
epoch 23, batch 780, train_loss 0.689
epoch 23, batch 790, train_loss 0.699
epoch 23, batch 800, train_loss 0.695
epoch 23, batch 810, train_loss 0.700
epoch 23, batch 820, train_loss 0.702
epoch 23, batch 830, train_loss 0.690
epoch 23, batch 840, train_loss 0.702
epoch 23, batch 850, train_loss 0.697
epoch 23, batch 860, train_loss 0.687
epoch 23, batch 870, train_loss 0.696
epoch 23, batch 880, train_loss 0.693
epoch 23, batch 890, train_loss 0.690
epoch 23, batch 900, train_loss 0.697
epoch 23, batch 910, train_loss 0.700
epoch 23, batch 920, train_loss 0.706
epoch 23, batch 930, train_loss 0.700
epoch 23, batch 940, train_loss 0.696
epoch 23, batch 950, train_loss 0.696
epoch 23, batch 960, train_loss 0.701
epoch 23, batch 970, train_loss 0.696
epoch 23, batch 980, train_loss 0.703
epoch 23, batch 990, train_loss 0.687
epoch 23, batch 1000, train_loss 0.697
epoch 23, batch 1010, train_loss 0.683
epoch 23, batch 1020, train_loss 0.702
epoch 23, batch 1030, train_loss 0.694
epoch 23, batch 1040, train_loss 0.686
epoch 23, batch 1050, train_loss 0.691
epoch 23, batch 1060, train_loss 0.698
epoch 23, batch 1070, train_loss 0.697
epoch 23, batch 1080, train_loss 0.695
epoch 23, batch 1090, train_loss 0.693
epoch 23, batch 1100, train_loss 0.690
epoch 23, batch 1110, train_loss 0.698
epoch 23, batch 1120, train_loss 0.700
epoch 23, batch 1130, train_loss 0.695
epoch 23, batch 1140, train_loss 0.681
epoch 23, batch 1150, train_loss 0.692
epoch 23, batch 1160, train_loss 0.697
epoch 23, batch 1170, train_loss 0.696
epoch 23, batch 1180, train_loss 0.695
epoch 23, batch 1190, train_loss 0.707
epoch 23, train_loss 0.695, valid_loss 0.723, train_accuracy  70.08%, valid_accuracy  68.53%
epoch 24, batch 0, train_loss 0.697
epoch 24, batch 10, train_loss 0.703
epoch 24, batch 20, train_loss 0.689
epoch 24, batch 30, train_loss 0.694
epoch 24, batch 40, train_loss 0.686
epoch 24, batch 50, train_loss 0.692
epoch 24, batch 60, train_loss 0.699
epoch 24, batch 70, train_loss 0.690
epoch 24, batch 80, train_loss 0.695
epoch 24, batch 90, train_loss 0.694
epoch 24, batch 100, train_loss 0.702
epoch 24, batch 110, train_loss 0.693
epoch 24, batch 120, train_loss 0.692
epoch 24, batch 130, train_loss 0.693
epoch 24, batch 140, train_loss 0.690
epoch 24, batch 150, train_loss 0.698
epoch 24, batch 160, train_loss 0.688
epoch 24, batch 170, train_loss 0.687
epoch 24, batch 180, train_loss 0.698
epoch 24, batch 190, train_loss 0.703
epoch 24, batch 200, train_loss 0.692
epoch 24, batch 210, train_loss 0.698
epoch 24, batch 220, train_loss 0.699
epoch 24, batch 230, train_loss 0.684
epoch 24, batch 240, train_loss 0.697
epoch 24, batch 250, train_loss 0.696
epoch 24, batch 260, train_loss 0.698
epoch 24, batch 270, train_loss 0.695
epoch 24, batch 280, train_loss 0.700
epoch 24, batch 290, train_loss 0.697
epoch 24, batch 300, train_loss 0.704
epoch 24, batch 310, train_loss 0.699
epoch 24, batch 320, train_loss 0.692
epoch 24, batch 330, train_loss 0.698
epoch 24, batch 340, train_loss 0.701
epoch 24, batch 350, train_loss 0.696
epoch 24, batch 360, train_loss 0.705
epoch 24, batch 370, train_loss 0.702
epoch 24, batch 380, train_loss 0.695
epoch 24, batch 390, train_loss 0.698
epoch 24, batch 400, train_loss 0.691
epoch 24, batch 410, train_loss 0.695
epoch 24, batch 420, train_loss 0.689
epoch 24, batch 430, train_loss 0.697
epoch 24, batch 440, train_loss 0.696
epoch 24, batch 450, train_loss 0.698
epoch 24, batch 460, train_loss 0.696
epoch 24, batch 470, train_loss 0.700
epoch 24, batch 480, train_loss 0.698
epoch 24, batch 490, train_loss 0.700
epoch 24, batch 500, train_loss 0.690
epoch 24, batch 510, train_loss 0.695
epoch 24, batch 520, train_loss 0.689
epoch 24, batch 530, train_loss 0.693
epoch 24, batch 540, train_loss 0.692
epoch 24, batch 550, train_loss 0.702
epoch 24, batch 560, train_loss 0.701
epoch 24, batch 570, train_loss 0.694
epoch 24, batch 580, train_loss 0.686
epoch 24, batch 590, train_loss 0.682
epoch 24, batch 600, train_loss 0.698
epoch 24, batch 610, train_loss 0.695
epoch 24, batch 620, train_loss 0.694
epoch 24, batch 630, train_loss 0.691
epoch 24, batch 640, train_loss 0.694
epoch 24, batch 650, train_loss 0.701
epoch 24, batch 660, train_loss 0.695
epoch 24, batch 670, train_loss 0.695
epoch 24, batch 680, train_loss 0.697
epoch 24, batch 690, train_loss 0.702
epoch 24, batch 700, train_loss 0.690
epoch 24, batch 710, train_loss 0.693
epoch 24, batch 720, train_loss 0.691
epoch 24, batch 730, train_loss 0.698
epoch 24, batch 740, train_loss 0.701
epoch 24, batch 750, train_loss 0.702
epoch 24, batch 760, train_loss 0.693
epoch 24, batch 770, train_loss 0.694
epoch 24, batch 780, train_loss 0.700
epoch 24, batch 790, train_loss 0.698
epoch 24, batch 800, train_loss 0.695
epoch 24, batch 810, train_loss 0.700
epoch 24, batch 820, train_loss 0.711
epoch 24, batch 830, train_loss 0.691
epoch 24, batch 840, train_loss 0.692
epoch 24, batch 850, train_loss 0.695
epoch 24, batch 860, train_loss 0.704
epoch 24, batch 870, train_loss 0.691
epoch 24, batch 880, train_loss 0.701
epoch 24, batch 890, train_loss 0.697
epoch 24, batch 900, train_loss 0.705
epoch 24, batch 910, train_loss 0.696
epoch 24, batch 920, train_loss 0.695
epoch 24, batch 930, train_loss 0.697
epoch 24, batch 940, train_loss 0.691
epoch 24, batch 950, train_loss 0.696
epoch 24, batch 960, train_loss 0.697
epoch 24, batch 970, train_loss 0.698
epoch 24, batch 980, train_loss 0.684
epoch 24, batch 990, train_loss 0.695
epoch 24, batch 1000, train_loss 0.701
epoch 24, batch 1010, train_loss 0.701
epoch 24, batch 1020, train_loss 0.692
epoch 24, batch 1030, train_loss 0.693
epoch 24, batch 1040, train_loss 0.698
epoch 24, batch 1050, train_loss 0.693
epoch 24, batch 1060, train_loss 0.703
epoch 24, batch 1070, train_loss 0.695
epoch 24, batch 1080, train_loss 0.707
epoch 24, batch 1090, train_loss 0.690
epoch 24, batch 1100, train_loss 0.689
epoch 24, batch 1110, train_loss 0.701
epoch 24, batch 1120, train_loss 0.682
epoch 24, batch 1130, train_loss 0.693
epoch 24, batch 1140, train_loss 0.692
epoch 24, batch 1150, train_loss 0.687
epoch 24, batch 1160, train_loss 0.694
epoch 24, batch 1170, train_loss 0.694
epoch 24, batch 1180, train_loss 0.698
epoch 24, batch 1190, train_loss 0.695
epoch 24, train_loss 0.694, valid_loss 0.722, train_accuracy  70.13%, valid_accuracy  68.58%
epoch 25, batch 0, train_loss 0.675
epoch 25, batch 10, train_loss 0.693
epoch 25, batch 20, train_loss 0.701
epoch 25, batch 30, train_loss 0.688
epoch 25, batch 40, train_loss 0.696
epoch 25, batch 50, train_loss 0.694
epoch 25, batch 60, train_loss 0.690
epoch 25, batch 70, train_loss 0.698
epoch 25, batch 80, train_loss 0.705
epoch 25, batch 90, train_loss 0.697
epoch 25, batch 100, train_loss 0.689
epoch 25, batch 110, train_loss 0.691
epoch 25, batch 120, train_loss 0.682
epoch 25, batch 130, train_loss 0.690
epoch 25, batch 140, train_loss 0.695
epoch 25, batch 150, train_loss 0.687
epoch 25, batch 160, train_loss 0.695
epoch 25, batch 170, train_loss 0.694
epoch 25, batch 180, train_loss 0.696
epoch 25, batch 190, train_loss 0.694
epoch 25, batch 200, train_loss 0.688
epoch 25, batch 210, train_loss 0.700
epoch 25, batch 220, train_loss 0.695
epoch 25, batch 230, train_loss 0.693
epoch 25, batch 240, train_loss 0.689
epoch 25, batch 250, train_loss 0.691
epoch 25, batch 260, train_loss 0.699
epoch 25, batch 270, train_loss 0.690
epoch 25, batch 280, train_loss 0.685
epoch 25, batch 290, train_loss 0.692
epoch 25, batch 300, train_loss 0.686
epoch 25, batch 310, train_loss 0.694
epoch 25, batch 320, train_loss 0.700
epoch 25, batch 330, train_loss 0.696
epoch 25, batch 340, train_loss 0.701
epoch 25, batch 350, train_loss 0.693
epoch 25, batch 360, train_loss 0.689
epoch 25, batch 370, train_loss 0.701
epoch 25, batch 380, train_loss 0.694
epoch 25, batch 390, train_loss 0.697
epoch 25, batch 400, train_loss 0.705
epoch 25, batch 410, train_loss 0.692
epoch 25, batch 420, train_loss 0.699
epoch 25, batch 430, train_loss 0.695
epoch 25, batch 440, train_loss 0.695
epoch 25, batch 450, train_loss 0.700
epoch 25, batch 460, train_loss 0.704
epoch 25, batch 470, train_loss 0.701
epoch 25, batch 480, train_loss 0.690
epoch 25, batch 490, train_loss 0.697
epoch 25, batch 500, train_loss 0.695
epoch 25, batch 510, train_loss 0.694
epoch 25, batch 520, train_loss 0.707
epoch 25, batch 530, train_loss 0.701
epoch 25, batch 540, train_loss 0.702
epoch 25, batch 550, train_loss 0.696
epoch 25, batch 560, train_loss 0.693
epoch 25, batch 570, train_loss 0.691
epoch 25, batch 580, train_loss 0.687
epoch 25, batch 590, train_loss 0.698
epoch 25, batch 600, train_loss 0.696
epoch 25, batch 610, train_loss 0.701
epoch 25, batch 620, train_loss 0.695
epoch 25, batch 630, train_loss 0.693
epoch 25, batch 640, train_loss 0.706
epoch 25, batch 650, train_loss 0.700
epoch 25, batch 660, train_loss 0.700
epoch 25, batch 670, train_loss 0.703
epoch 25, batch 680, train_loss 0.703
epoch 25, batch 690, train_loss 0.700
epoch 25, batch 700, train_loss 0.701
epoch 25, batch 710, train_loss 0.706
epoch 25, batch 720, train_loss 0.701
epoch 25, batch 730, train_loss 0.700
epoch 25, batch 740, train_loss 0.688
epoch 25, batch 750, train_loss 0.698
epoch 25, batch 760, train_loss 0.700
epoch 25, batch 770, train_loss 0.689
epoch 25, batch 780, train_loss 0.695
epoch 25, batch 790, train_loss 0.700
epoch 25, batch 800, train_loss 0.697
epoch 25, batch 810, train_loss 0.694
epoch 25, batch 820, train_loss 0.693
epoch 25, batch 830, train_loss 0.692
epoch 25, batch 840, train_loss 0.698
epoch 25, batch 850, train_loss 0.691
epoch 25, batch 860, train_loss 0.687
epoch 25, batch 870, train_loss 0.700
epoch 25, batch 880, train_loss 0.696
epoch 25, batch 890, train_loss 0.696
epoch 25, batch 900, train_loss 0.701
epoch 25, batch 910, train_loss 0.694
epoch 25, batch 920, train_loss 0.704
epoch 25, batch 930, train_loss 0.708
epoch 25, batch 940, train_loss 0.694
epoch 25, batch 950, train_loss 0.698
epoch 25, batch 960, train_loss 0.692
epoch 25, batch 970, train_loss 0.695
epoch 25, batch 980, train_loss 0.690
epoch 25, batch 990, train_loss 0.694
epoch 25, batch 1000, train_loss 0.690
epoch 25, batch 1010, train_loss 0.689
epoch 25, batch 1020, train_loss 0.689
epoch 25, batch 1030, train_loss 0.688
epoch 25, batch 1040, train_loss 0.688
epoch 25, batch 1050, train_loss 0.699
epoch 25, batch 1060, train_loss 0.697
epoch 25, batch 1070, train_loss 0.690
epoch 25, batch 1080, train_loss 0.694
epoch 25, batch 1090, train_loss 0.691
epoch 25, batch 1100, train_loss 0.689
epoch 25, batch 1110, train_loss 0.696
epoch 25, batch 1120, train_loss 0.690
epoch 25, batch 1130, train_loss 0.697
epoch 25, batch 1140, train_loss 0.698
epoch 25, batch 1150, train_loss 0.701
epoch 25, batch 1160, train_loss 0.688
epoch 25, batch 1170, train_loss 0.691
epoch 25, batch 1180, train_loss 0.701
epoch 25, batch 1190, train_loss 0.700
epoch 25, train_loss 0.694, valid_loss 0.722, train_accuracy  70.16%, valid_accuracy  68.59%
epoch 26, batch 0, train_loss 0.702
epoch 26, batch 10, train_loss 0.696
epoch 26, batch 20, train_loss 0.691
epoch 26, batch 30, train_loss 0.692
epoch 26, batch 40, train_loss 0.695
epoch 26, batch 50, train_loss 0.694
epoch 26, batch 60, train_loss 0.699
epoch 26, batch 70, train_loss 0.692
epoch 26, batch 80, train_loss 0.702
epoch 26, batch 90, train_loss 0.698
epoch 26, batch 100, train_loss 0.687
epoch 26, batch 110, train_loss 0.693
epoch 26, batch 120, train_loss 0.696
epoch 26, batch 130, train_loss 0.696
epoch 26, batch 140, train_loss 0.706
epoch 26, batch 150, train_loss 0.694
epoch 26, batch 160, train_loss 0.690
epoch 26, batch 170, train_loss 0.696
epoch 26, batch 180, train_loss 0.686
epoch 26, batch 190, train_loss 0.698
epoch 26, batch 200, train_loss 0.689
epoch 26, batch 210, train_loss 0.696
epoch 26, batch 220, train_loss 0.695
epoch 26, batch 230, train_loss 0.691
epoch 26, batch 240, train_loss 0.692
epoch 26, batch 250, train_loss 0.701
epoch 26, batch 260, train_loss 0.701
epoch 26, batch 270, train_loss 0.693
epoch 26, batch 280, train_loss 0.700
epoch 26, batch 290, train_loss 0.694
epoch 26, batch 300, train_loss 0.700
epoch 26, batch 310, train_loss 0.691
epoch 26, batch 320, train_loss 0.699
epoch 26, batch 330, train_loss 0.691
epoch 26, batch 340, train_loss 0.698
epoch 26, batch 350, train_loss 0.696
epoch 26, batch 360, train_loss 0.695
epoch 26, batch 370, train_loss 0.692
epoch 26, batch 380, train_loss 0.692
epoch 26, batch 390, train_loss 0.700
epoch 26, batch 400, train_loss 0.695
epoch 26, batch 410, train_loss 0.708
epoch 26, batch 420, train_loss 0.700
epoch 26, batch 430, train_loss 0.694
epoch 26, batch 440, train_loss 0.696
epoch 26, batch 450, train_loss 0.698
epoch 26, batch 460, train_loss 0.699
epoch 26, batch 470, train_loss 0.703
epoch 26, batch 480, train_loss 0.702
epoch 26, batch 490, train_loss 0.692
epoch 26, batch 500, train_loss 0.693
epoch 26, batch 510, train_loss 0.694
epoch 26, batch 520, train_loss 0.680
epoch 26, batch 530, train_loss 0.688
epoch 26, batch 540, train_loss 0.692
epoch 26, batch 550, train_loss 0.698
epoch 26, batch 560, train_loss 0.696
epoch 26, batch 570, train_loss 0.693
epoch 26, batch 580, train_loss 0.684
epoch 26, batch 590, train_loss 0.702
epoch 26, batch 600, train_loss 0.691
epoch 26, batch 610, train_loss 0.694
epoch 26, batch 620, train_loss 0.692
epoch 26, batch 630, train_loss 0.697
epoch 26, batch 640, train_loss 0.695
epoch 26, batch 650, train_loss 0.689
epoch 26, batch 660, train_loss 0.687
epoch 26, batch 670, train_loss 0.698
epoch 26, batch 680, train_loss 0.698
epoch 26, batch 690, train_loss 0.697
epoch 26, batch 700, train_loss 0.691
epoch 26, batch 710, train_loss 0.697
epoch 26, batch 720, train_loss 0.696
epoch 26, batch 730, train_loss 0.692
epoch 26, batch 740, train_loss 0.692
epoch 26, batch 750, train_loss 0.700
epoch 26, batch 760, train_loss 0.697
epoch 26, batch 770, train_loss 0.694
epoch 26, batch 780, train_loss 0.704
epoch 26, batch 790, train_loss 0.689
epoch 26, batch 800, train_loss 0.691
epoch 26, batch 810, train_loss 0.698
epoch 26, batch 820, train_loss 0.694
epoch 26, batch 830, train_loss 0.689
epoch 26, batch 840, train_loss 0.698
epoch 26, batch 850, train_loss 0.700
epoch 26, batch 860, train_loss 0.696
epoch 26, batch 870, train_loss 0.701
epoch 26, batch 880, train_loss 0.697
epoch 26, batch 890, train_loss 0.692
epoch 26, batch 900, train_loss 0.696
epoch 26, batch 910, train_loss 0.695
epoch 26, batch 920, train_loss 0.690
epoch 26, batch 930, train_loss 0.695
epoch 26, batch 940, train_loss 0.690
epoch 26, batch 950, train_loss 0.697
epoch 26, batch 960, train_loss 0.699
epoch 26, batch 970, train_loss 0.704
epoch 26, batch 980, train_loss 0.689
epoch 26, batch 990, train_loss 0.700
epoch 26, batch 1000, train_loss 0.710
epoch 26, batch 1010, train_loss 0.686
epoch 26, batch 1020, train_loss 0.699
epoch 26, batch 1030, train_loss 0.689
epoch 26, batch 1040, train_loss 0.690
epoch 26, batch 1050, train_loss 0.695
epoch 26, batch 1060, train_loss 0.689
epoch 26, batch 1070, train_loss 0.688
epoch 26, batch 1080, train_loss 0.699
epoch 26, batch 1090, train_loss 0.698
epoch 26, batch 1100, train_loss 0.702
epoch 26, batch 1110, train_loss 0.696
epoch 26, batch 1120, train_loss 0.689
epoch 26, batch 1130, train_loss 0.689
epoch 26, batch 1140, train_loss 0.695
epoch 26, batch 1150, train_loss 0.697
epoch 26, batch 1160, train_loss 0.690
epoch 26, batch 1170, train_loss 0.699
epoch 26, batch 1180, train_loss 0.691
epoch 26, batch 1190, train_loss 0.692
epoch 26, train_loss 0.694, valid_loss 0.722, train_accuracy  70.16%, valid_accuracy  68.60%
epoch 27, batch 0, train_loss 0.698
epoch 27, batch 10, train_loss 0.692
epoch 27, batch 20, train_loss 0.698
epoch 27, batch 30, train_loss 0.700
epoch 27, batch 40, train_loss 0.695
epoch 27, batch 50, train_loss 0.689
epoch 27, batch 60, train_loss 0.687
epoch 27, batch 70, train_loss 0.697
epoch 27, batch 80, train_loss 0.699
epoch 27, batch 90, train_loss 0.700
epoch 27, batch 100, train_loss 0.694
epoch 27, batch 110, train_loss 0.686
epoch 27, batch 120, train_loss 0.688
epoch 27, batch 130, train_loss 0.689
epoch 27, batch 140, train_loss 0.689
epoch 27, batch 150, train_loss 0.692
epoch 27, batch 160, train_loss 0.694
epoch 27, batch 170, train_loss 0.695
epoch 27, batch 180, train_loss 0.695
epoch 27, batch 190, train_loss 0.695
epoch 27, batch 200, train_loss 0.693
epoch 27, batch 210, train_loss 0.692
epoch 27, batch 220, train_loss 0.695
epoch 27, batch 230, train_loss 0.685
epoch 27, batch 240, train_loss 0.686
epoch 27, batch 250, train_loss 0.697
epoch 27, batch 260, train_loss 0.683
epoch 27, batch 270, train_loss 0.698
epoch 27, batch 280, train_loss 0.695
epoch 27, batch 290, train_loss 0.690
epoch 27, batch 300, train_loss 0.690
epoch 27, batch 310, train_loss 0.685
epoch 27, batch 320, train_loss 0.696
epoch 27, batch 330, train_loss 0.693
epoch 27, batch 340, train_loss 0.700
epoch 27, batch 350, train_loss 0.690
epoch 27, batch 360, train_loss 0.706
epoch 27, batch 370, train_loss 0.709
epoch 27, batch 380, train_loss 0.691
epoch 27, batch 390, train_loss 0.698
epoch 27, batch 400, train_loss 0.694
epoch 27, batch 410, train_loss 0.692
epoch 27, batch 420, train_loss 0.692
epoch 27, batch 430, train_loss 0.698
epoch 27, batch 440, train_loss 0.696
epoch 27, batch 450, train_loss 0.696
epoch 27, batch 460, train_loss 0.697
epoch 27, batch 470, train_loss 0.697
epoch 27, batch 480, train_loss 0.682
epoch 27, batch 490, train_loss 0.691
epoch 27, batch 500, train_loss 0.693
epoch 27, batch 510, train_loss 0.697
epoch 27, batch 520, train_loss 0.702
epoch 27, batch 530, train_loss 0.683
epoch 27, batch 540, train_loss 0.699
epoch 27, batch 550, train_loss 0.694
epoch 27, batch 560, train_loss 0.694
epoch 27, batch 570, train_loss 0.689
epoch 27, batch 580, train_loss 0.699
epoch 27, batch 590, train_loss 0.687
epoch 27, batch 600, train_loss 0.699
epoch 27, batch 610, train_loss 0.699
epoch 27, batch 620, train_loss 0.701
epoch 27, batch 630, train_loss 0.691
epoch 27, batch 640, train_loss 0.696
epoch 27, batch 650, train_loss 0.703
epoch 27, batch 660, train_loss 0.694
epoch 27, batch 670, train_loss 0.692
epoch 27, batch 680, train_loss 0.692
epoch 27, batch 690, train_loss 0.693
epoch 27, batch 700, train_loss 0.695
epoch 27, batch 710, train_loss 0.696
epoch 27, batch 720, train_loss 0.699
epoch 27, batch 730, train_loss 0.696
epoch 27, batch 740, train_loss 0.687
epoch 27, batch 750, train_loss 0.693
epoch 27, batch 760, train_loss 0.690
epoch 27, batch 770, train_loss 0.692
epoch 27, batch 780, train_loss 0.688
epoch 27, batch 790, train_loss 0.702
epoch 27, batch 800, train_loss 0.688
epoch 27, batch 810, train_loss 0.702
epoch 27, batch 820, train_loss 0.687
epoch 27, batch 830, train_loss 0.686
epoch 27, batch 840, train_loss 0.693
epoch 27, batch 850, train_loss 0.682
epoch 27, batch 860, train_loss 0.708
epoch 27, batch 870, train_loss 0.694
epoch 27, batch 880, train_loss 0.690
epoch 27, batch 890, train_loss 0.693
epoch 27, batch 900, train_loss 0.694
epoch 27, batch 910, train_loss 0.684
epoch 27, batch 920, train_loss 0.696
epoch 27, batch 930, train_loss 0.694
epoch 27, batch 940, train_loss 0.689
epoch 27, batch 950, train_loss 0.696
epoch 27, batch 960, train_loss 0.707
epoch 27, batch 970, train_loss 0.690
epoch 27, batch 980, train_loss 0.707
epoch 27, batch 990, train_loss 0.693
epoch 27, batch 1000, train_loss 0.695
epoch 27, batch 1010, train_loss 0.694
epoch 27, batch 1020, train_loss 0.691
epoch 27, batch 1030, train_loss 0.704
epoch 27, batch 1040, train_loss 0.698
epoch 27, batch 1050, train_loss 0.692
epoch 27, batch 1060, train_loss 0.694
epoch 27, batch 1070, train_loss 0.697
epoch 27, batch 1080, train_loss 0.703
epoch 27, batch 1090, train_loss 0.702
epoch 27, batch 1100, train_loss 0.705
epoch 27, batch 1110, train_loss 0.688
epoch 27, batch 1120, train_loss 0.702
epoch 27, batch 1130, train_loss 0.699
epoch 27, batch 1140, train_loss 0.695
epoch 27, batch 1150, train_loss 0.690
epoch 27, batch 1160, train_loss 0.692
epoch 27, batch 1170, train_loss 0.698
epoch 27, batch 1180, train_loss 0.699
epoch 27, batch 1190, train_loss 0.696
epoch 27, train_loss 0.694, valid_loss 0.722, train_accuracy  70.18%, valid_accuracy  68.61%
epoch 28, batch 0, train_loss 0.696
epoch 28, batch 10, train_loss 0.690
epoch 28, batch 20, train_loss 0.701
epoch 28, batch 30, train_loss 0.686
epoch 28, batch 40, train_loss 0.688
epoch 28, batch 50, train_loss 0.695
epoch 28, batch 60, train_loss 0.696
epoch 28, batch 70, train_loss 0.689
epoch 28, batch 80, train_loss 0.699
epoch 28, batch 90, train_loss 0.684
epoch 28, batch 100, train_loss 0.687
epoch 28, batch 110, train_loss 0.687
epoch 28, batch 120, train_loss 0.698
epoch 28, batch 130, train_loss 0.693
epoch 28, batch 140, train_loss 0.695
epoch 28, batch 150, train_loss 0.702
epoch 28, batch 160, train_loss 0.701
epoch 28, batch 170, train_loss 0.694
epoch 28, batch 180, train_loss 0.703
epoch 28, batch 190, train_loss 0.689
epoch 28, batch 200, train_loss 0.686
epoch 28, batch 210, train_loss 0.701
epoch 28, batch 220, train_loss 0.686
epoch 28, batch 230, train_loss 0.699
epoch 28, batch 240, train_loss 0.703
epoch 28, batch 250, train_loss 0.691
epoch 28, batch 260, train_loss 0.695
epoch 28, batch 270, train_loss 0.691
epoch 28, batch 280, train_loss 0.693
epoch 28, batch 290, train_loss 0.691
epoch 28, batch 300, train_loss 0.697
epoch 28, batch 310, train_loss 0.699
epoch 28, batch 320, train_loss 0.698
epoch 28, batch 330, train_loss 0.699
epoch 28, batch 340, train_loss 0.695
epoch 28, batch 350, train_loss 0.691
epoch 28, batch 360, train_loss 0.701
epoch 28, batch 370, train_loss 0.690
epoch 28, batch 380, train_loss 0.695
epoch 28, batch 390, train_loss 0.689
epoch 28, batch 400, train_loss 0.705
epoch 28, batch 410, train_loss 0.697
epoch 28, batch 420, train_loss 0.702
epoch 28, batch 430, train_loss 0.696
epoch 28, batch 440, train_loss 0.697
epoch 28, batch 450, train_loss 0.695
epoch 28, batch 460, train_loss 0.698
epoch 28, batch 470, train_loss 0.695
epoch 28, batch 480, train_loss 0.699
epoch 28, batch 490, train_loss 0.694
epoch 28, batch 500, train_loss 0.703
epoch 28, batch 510, train_loss 0.692
epoch 28, batch 520, train_loss 0.696
epoch 28, batch 530, train_loss 0.695
epoch 28, batch 540, train_loss 0.691
epoch 28, batch 550, train_loss 0.692
epoch 28, batch 560, train_loss 0.681
epoch 28, batch 570, train_loss 0.690
epoch 28, batch 580, train_loss 0.702
epoch 28, batch 590, train_loss 0.698
epoch 28, batch 600, train_loss 0.693
epoch 28, batch 610, train_loss 0.701
epoch 28, batch 620, train_loss 0.700
epoch 28, batch 630, train_loss 0.699
epoch 28, batch 640, train_loss 0.698
epoch 28, batch 650, train_loss 0.687
epoch 28, batch 660, train_loss 0.690
epoch 28, batch 670, train_loss 0.690
epoch 28, batch 680, train_loss 0.702
epoch 28, batch 690, train_loss 0.692
epoch 28, batch 700, train_loss 0.698
epoch 28, batch 710, train_loss 0.692
epoch 28, batch 720, train_loss 0.692
epoch 28, batch 730, train_loss 0.691
epoch 28, batch 740, train_loss 0.693
epoch 28, batch 750, train_loss 0.692
epoch 28, batch 760, train_loss 0.695
epoch 28, batch 770, train_loss 0.692
epoch 28, batch 780, train_loss 0.693
epoch 28, batch 790, train_loss 0.693
epoch 28, batch 800, train_loss 0.695
epoch 28, batch 810, train_loss 0.700
epoch 28, batch 820, train_loss 0.694
epoch 28, batch 830, train_loss 0.701
epoch 28, batch 840, train_loss 0.693
epoch 28, batch 850, train_loss 0.683
epoch 28, batch 860, train_loss 0.692
epoch 28, batch 870, train_loss 0.686
epoch 28, batch 880, train_loss 0.695
epoch 28, batch 890, train_loss 0.688
epoch 28, batch 900, train_loss 0.689
epoch 28, batch 910, train_loss 0.694
epoch 28, batch 920, train_loss 0.683
epoch 28, batch 930, train_loss 0.694
epoch 28, batch 940, train_loss 0.700
epoch 28, batch 950, train_loss 0.697
epoch 28, batch 960, train_loss 0.699
epoch 28, batch 970, train_loss 0.700
epoch 28, batch 980, train_loss 0.696
epoch 28, batch 990, train_loss 0.697
epoch 28, batch 1000, train_loss 0.695
epoch 28, batch 1010, train_loss 0.690
epoch 28, batch 1020, train_loss 0.690
epoch 28, batch 1030, train_loss 0.696
epoch 28, batch 1040, train_loss 0.696
epoch 28, batch 1050, train_loss 0.694
epoch 28, batch 1060, train_loss 0.690
epoch 28, batch 1070, train_loss 0.694
epoch 28, batch 1080, train_loss 0.705
epoch 28, batch 1090, train_loss 0.690
epoch 28, batch 1100, train_loss 0.696
epoch 28, batch 1110, train_loss 0.697
epoch 28, batch 1120, train_loss 0.689
epoch 28, batch 1130, train_loss 0.695
epoch 28, batch 1140, train_loss 0.689
epoch 28, batch 1150, train_loss 0.700
epoch 28, batch 1160, train_loss 0.694
epoch 28, batch 1170, train_loss 0.685
epoch 28, batch 1180, train_loss 0.697
epoch 28, batch 1190, train_loss 0.688
epoch 28, train_loss 0.694, valid_loss 0.723, train_accuracy  70.15%, valid_accuracy  68.53%
epoch 29, batch 0, train_loss 0.693
epoch 29, batch 10, train_loss 0.711
epoch 29, batch 20, train_loss 0.698
epoch 29, batch 30, train_loss 0.694
epoch 29, batch 40, train_loss 0.686
epoch 29, batch 50, train_loss 0.684
epoch 29, batch 60, train_loss 0.706
epoch 29, batch 70, train_loss 0.689
epoch 29, batch 80, train_loss 0.703
epoch 29, batch 90, train_loss 0.699
epoch 29, batch 100, train_loss 0.697
epoch 29, batch 110, train_loss 0.694
epoch 29, batch 120, train_loss 0.686
epoch 29, batch 130, train_loss 0.697
epoch 29, batch 140, train_loss 0.693
epoch 29, batch 150, train_loss 0.693
epoch 29, batch 160, train_loss 0.691
epoch 29, batch 170, train_loss 0.691
epoch 29, batch 180, train_loss 0.692
epoch 29, batch 190, train_loss 0.684
epoch 29, batch 200, train_loss 0.694
epoch 29, batch 210, train_loss 0.699
epoch 29, batch 220, train_loss 0.698
epoch 29, batch 230, train_loss 0.693
epoch 29, batch 240, train_loss 0.690
epoch 29, batch 250, train_loss 0.690
epoch 29, batch 260, train_loss 0.695
epoch 29, batch 270, train_loss 0.687
epoch 29, batch 280, train_loss 0.686
epoch 29, batch 290, train_loss 0.693
epoch 29, batch 300, train_loss 0.693
epoch 29, batch 310, train_loss 0.684
epoch 29, batch 320, train_loss 0.694
epoch 29, batch 330, train_loss 0.699
epoch 29, batch 340, train_loss 0.691
epoch 29, batch 350, train_loss 0.690
epoch 29, batch 360, train_loss 0.696
epoch 29, batch 370, train_loss 0.695
epoch 29, batch 380, train_loss 0.690
epoch 29, batch 390, train_loss 0.693
epoch 29, batch 400, train_loss 0.697
epoch 29, batch 410, train_loss 0.700
epoch 29, batch 420, train_loss 0.688
epoch 29, batch 430, train_loss 0.693
epoch 29, batch 440, train_loss 0.691
epoch 29, batch 450, train_loss 0.684
epoch 29, batch 460, train_loss 0.693
epoch 29, batch 470, train_loss 0.686
epoch 29, batch 480, train_loss 0.692
epoch 29, batch 490, train_loss 0.691
epoch 29, batch 500, train_loss 0.705
epoch 29, batch 510, train_loss 0.711
epoch 29, batch 520, train_loss 0.693
epoch 29, batch 530, train_loss 0.700
epoch 29, batch 540, train_loss 0.700
epoch 29, batch 550, train_loss 0.691
epoch 29, batch 560, train_loss 0.690
epoch 29, batch 570, train_loss 0.700
epoch 29, batch 580, train_loss 0.699
epoch 29, batch 590, train_loss 0.693
epoch 29, batch 600, train_loss 0.695
epoch 29, batch 610, train_loss 0.704
epoch 29, batch 620, train_loss 0.697
epoch 29, batch 630, train_loss 0.692
epoch 29, batch 640, train_loss 0.687
epoch 29, batch 650, train_loss 0.699
epoch 29, batch 660, train_loss 0.699
epoch 29, batch 670, train_loss 0.697
epoch 29, batch 680, train_loss 0.702
epoch 29, batch 690, train_loss 0.692
epoch 29, batch 700, train_loss 0.687
epoch 29, batch 710, train_loss 0.689
epoch 29, batch 720, train_loss 0.699
epoch 29, batch 730, train_loss 0.692
epoch 29, batch 740, train_loss 0.694
epoch 29, batch 750, train_loss 0.699
epoch 29, batch 760, train_loss 0.687
epoch 29, batch 770, train_loss 0.694
epoch 29, batch 780, train_loss 0.696
epoch 29, batch 790, train_loss 0.701
epoch 29, batch 800, train_loss 0.687
epoch 29, batch 810, train_loss 0.691
epoch 29, batch 820, train_loss 0.687
epoch 29, batch 830, train_loss 0.691
epoch 29, batch 840, train_loss 0.697
epoch 29, batch 850, train_loss 0.685
epoch 29, batch 860, train_loss 0.696
epoch 29, batch 870, train_loss 0.690
epoch 29, batch 880, train_loss 0.689
epoch 29, batch 890, train_loss 0.691
epoch 29, batch 900, train_loss 0.688
epoch 29, batch 910, train_loss 0.691
epoch 29, batch 920, train_loss 0.698
epoch 29, batch 930, train_loss 0.695
epoch 29, batch 940, train_loss 0.696
epoch 29, batch 950, train_loss 0.695
epoch 29, batch 960, train_loss 0.694
epoch 29, batch 970, train_loss 0.694
epoch 29, batch 980, train_loss 0.693
epoch 29, batch 990, train_loss 0.691
epoch 29, batch 1000, train_loss 0.698
epoch 29, batch 1010, train_loss 0.694
epoch 29, batch 1020, train_loss 0.698
epoch 29, batch 1030, train_loss 0.699
epoch 29, batch 1040, train_loss 0.692
epoch 29, batch 1050, train_loss 0.681
epoch 29, batch 1060, train_loss 0.696
epoch 29, batch 1070, train_loss 0.700
epoch 29, batch 1080, train_loss 0.691
epoch 29, batch 1090, train_loss 0.700
epoch 29, batch 1100, train_loss 0.693
epoch 29, batch 1110, train_loss 0.690
epoch 29, batch 1120, train_loss 0.695
epoch 29, batch 1130, train_loss 0.697
epoch 29, batch 1140, train_loss 0.702
epoch 29, batch 1150, train_loss 0.690
epoch 29, batch 1160, train_loss 0.696
epoch 29, batch 1170, train_loss 0.700
epoch 29, batch 1180, train_loss 0.704
epoch 29, batch 1190, train_loss 0.694
epoch 29, train_loss 0.694, valid_loss 0.723, train_accuracy  70.17%, valid_accuracy  68.60%
epoch 30, batch 0, train_loss 0.709
epoch 30, batch 10, train_loss 0.690
epoch 30, batch 20, train_loss 0.703
epoch 30, batch 30, train_loss 0.700
epoch 30, batch 40, train_loss 0.688
epoch 30, batch 50, train_loss 0.683
epoch 30, batch 60, train_loss 0.711
epoch 30, batch 70, train_loss 0.694
epoch 30, batch 80, train_loss 0.694
epoch 30, batch 90, train_loss 0.697
epoch 30, batch 100, train_loss 0.699
epoch 30, batch 110, train_loss 0.692
epoch 30, batch 120, train_loss 0.692
epoch 30, batch 130, train_loss 0.686
epoch 30, batch 140, train_loss 0.691
epoch 30, batch 150, train_loss 0.683
epoch 30, batch 160, train_loss 0.698
epoch 30, batch 170, train_loss 0.695
epoch 30, batch 180, train_loss 0.695
epoch 30, batch 190, train_loss 0.687
epoch 30, batch 200, train_loss 0.696
epoch 30, batch 210, train_loss 0.702
epoch 30, batch 220, train_loss 0.687
epoch 30, batch 230, train_loss 0.699
epoch 30, batch 240, train_loss 0.697
epoch 30, batch 250, train_loss 0.698
epoch 30, batch 260, train_loss 0.681
epoch 30, batch 270, train_loss 0.697
epoch 30, batch 280, train_loss 0.701
epoch 30, batch 290, train_loss 0.695
epoch 30, batch 300, train_loss 0.693
epoch 30, batch 310, train_loss 0.698
epoch 30, batch 320, train_loss 0.701
epoch 30, batch 330, train_loss 0.697
epoch 30, batch 340, train_loss 0.695
epoch 30, batch 350, train_loss 0.699
epoch 30, batch 360, train_loss 0.698
epoch 30, batch 370, train_loss 0.682
epoch 30, batch 380, train_loss 0.697
epoch 30, batch 390, train_loss 0.700
epoch 30, batch 400, train_loss 0.698
epoch 30, batch 410, train_loss 0.686
epoch 30, batch 420, train_loss 0.701
epoch 30, batch 430, train_loss 0.690
epoch 30, batch 440, train_loss 0.694
epoch 30, batch 450, train_loss 0.676
epoch 30, batch 460, train_loss 0.694
epoch 30, batch 470, train_loss 0.691
epoch 30, batch 480, train_loss 0.691
epoch 30, batch 490, train_loss 0.702
epoch 30, batch 500, train_loss 0.681
epoch 30, batch 510, train_loss 0.700
epoch 30, batch 520, train_loss 0.692
epoch 30, batch 530, train_loss 0.691
epoch 30, batch 540, train_loss 0.690
epoch 30, batch 550, train_loss 0.697
epoch 30, batch 560, train_loss 0.690
epoch 30, batch 570, train_loss 0.695
epoch 30, batch 580, train_loss 0.699
epoch 30, batch 590, train_loss 0.687
epoch 30, batch 600, train_loss 0.694
epoch 30, batch 610, train_loss 0.694
epoch 30, batch 620, train_loss 0.687
epoch 30, batch 630, train_loss 0.704
epoch 30, batch 640, train_loss 0.689
epoch 30, batch 650, train_loss 0.696
epoch 30, batch 660, train_loss 0.695
epoch 30, batch 670, train_loss 0.701
epoch 30, batch 680, train_loss 0.696
epoch 30, batch 690, train_loss 0.699
epoch 30, batch 700, train_loss 0.685
epoch 30, batch 710, train_loss 0.693
epoch 30, batch 720, train_loss 0.689
epoch 30, batch 730, train_loss 0.696
epoch 30, batch 740, train_loss 0.701
epoch 30, batch 750, train_loss 0.689
epoch 30, batch 760, train_loss 0.686
epoch 30, batch 770, train_loss 0.695
epoch 30, batch 780, train_loss 0.692
epoch 30, batch 790, train_loss 0.692
epoch 30, batch 800, train_loss 0.694
epoch 30, batch 810, train_loss 0.690
epoch 30, batch 820, train_loss 0.694
epoch 30, batch 830, train_loss 0.695
epoch 30, batch 840, train_loss 0.693
epoch 30, batch 850, train_loss 0.698
epoch 30, batch 860, train_loss 0.695
epoch 30, batch 870, train_loss 0.690
epoch 30, batch 880, train_loss 0.697
epoch 30, batch 890, train_loss 0.696
epoch 30, batch 900, train_loss 0.698
epoch 30, batch 910, train_loss 0.696
epoch 30, batch 920, train_loss 0.705
epoch 30, batch 930, train_loss 0.700
epoch 30, batch 940, train_loss 0.693
epoch 30, batch 950, train_loss 0.693
epoch 30, batch 960, train_loss 0.696
epoch 30, batch 970, train_loss 0.694
epoch 30, batch 980, train_loss 0.695
epoch 30, batch 990, train_loss 0.694
epoch 30, batch 1000, train_loss 0.685
epoch 30, batch 1010, train_loss 0.691
epoch 30, batch 1020, train_loss 0.701
epoch 30, batch 1030, train_loss 0.704
epoch 30, batch 1040, train_loss 0.696
epoch 30, batch 1050, train_loss 0.694
epoch 30, batch 1060, train_loss 0.683
epoch 30, batch 1070, train_loss 0.701
epoch 30, batch 1080, train_loss 0.701
epoch 30, batch 1090, train_loss 0.682
epoch 30, batch 1100, train_loss 0.699
epoch 30, batch 1110, train_loss 0.701
epoch 30, batch 1120, train_loss 0.688
epoch 30, batch 1130, train_loss 0.690
epoch 30, batch 1140, train_loss 0.706
epoch 30, batch 1150, train_loss 0.696
epoch 30, batch 1160, train_loss 0.694
epoch 30, batch 1170, train_loss 0.693
epoch 30, batch 1180, train_loss 0.690
epoch 30, batch 1190, train_loss 0.692
epoch 30, train_loss 0.693, valid_loss 0.724, train_accuracy  70.19%, valid_accuracy  68.55%
epoch 31, batch 0, train_loss 0.695
epoch 31, batch 10, train_loss 0.694
epoch 31, batch 20, train_loss 0.690
epoch 31, batch 30, train_loss 0.689
epoch 31, batch 40, train_loss 0.694
epoch 31, batch 50, train_loss 0.689
epoch 31, batch 60, train_loss 0.695
epoch 31, batch 70, train_loss 0.693
epoch 31, batch 80, train_loss 0.694
epoch 31, batch 90, train_loss 0.698
epoch 31, batch 100, train_loss 0.701
epoch 31, batch 110, train_loss 0.695
epoch 31, batch 120, train_loss 0.700
epoch 31, batch 130, train_loss 0.691
epoch 31, batch 140, train_loss 0.702
epoch 31, batch 150, train_loss 0.697
epoch 31, batch 160, train_loss 0.698
epoch 31, batch 170, train_loss 0.691
epoch 31, batch 180, train_loss 0.705
epoch 31, batch 190, train_loss 0.695
epoch 31, batch 200, train_loss 0.695
epoch 31, batch 210, train_loss 0.689
epoch 31, batch 220, train_loss 0.692
epoch 31, batch 230, train_loss 0.698
epoch 31, batch 240, train_loss 0.693
epoch 31, batch 250, train_loss 0.696
epoch 31, batch 260, train_loss 0.692
epoch 31, batch 270, train_loss 0.694
epoch 31, batch 280, train_loss 0.699
epoch 31, batch 290, train_loss 0.693
epoch 31, batch 300, train_loss 0.691
epoch 31, batch 310, train_loss 0.703
epoch 31, batch 320, train_loss 0.686
epoch 31, batch 330, train_loss 0.696
epoch 31, batch 340, train_loss 0.685
epoch 31, batch 350, train_loss 0.699
epoch 31, batch 360, train_loss 0.684
epoch 31, batch 370, train_loss 0.691
epoch 31, batch 380, train_loss 0.687
epoch 31, batch 390, train_loss 0.701
epoch 31, batch 400, train_loss 0.698
epoch 31, batch 410, train_loss 0.694
epoch 31, batch 420, train_loss 0.695
epoch 31, batch 430, train_loss 0.697
epoch 31, batch 440, train_loss 0.693
epoch 31, batch 450, train_loss 0.690
epoch 31, batch 460, train_loss 0.699
epoch 31, batch 470, train_loss 0.685
epoch 31, batch 480, train_loss 0.692
epoch 31, batch 490, train_loss 0.694
epoch 31, batch 500, train_loss 0.688
epoch 31, batch 510, train_loss 0.701
epoch 31, batch 520, train_loss 0.685
epoch 31, batch 530, train_loss 0.694
epoch 31, batch 540, train_loss 0.700
epoch 31, batch 550, train_loss 0.693
epoch 31, batch 560, train_loss 0.694
epoch 31, batch 570, train_loss 0.697
epoch 31, batch 580, train_loss 0.695
epoch 31, batch 590, train_loss 0.698
epoch 31, batch 600, train_loss 0.684
epoch 31, batch 610, train_loss 0.703
epoch 31, batch 620, train_loss 0.696
epoch 31, batch 630, train_loss 0.703
epoch 31, batch 640, train_loss 0.696
epoch 31, batch 650, train_loss 0.693
epoch 31, batch 660, train_loss 0.703
epoch 31, batch 670, train_loss 0.692
epoch 31, batch 680, train_loss 0.701
epoch 31, batch 690, train_loss 0.696
epoch 31, batch 700, train_loss 0.693
epoch 31, batch 710, train_loss 0.690
epoch 31, batch 720, train_loss 0.692
epoch 31, batch 730, train_loss 0.690
epoch 31, batch 740, train_loss 0.699
epoch 31, batch 750, train_loss 0.692
epoch 31, batch 760, train_loss 0.696
epoch 31, batch 770, train_loss 0.695
epoch 31, batch 780, train_loss 0.696
epoch 31, batch 790, train_loss 0.691
epoch 31, batch 800, train_loss 0.700
epoch 31, batch 810, train_loss 0.688
epoch 31, batch 820, train_loss 0.686
epoch 31, batch 830, train_loss 0.696
epoch 31, batch 840, train_loss 0.687
epoch 31, batch 850, train_loss 0.693
epoch 31, batch 860, train_loss 0.705
epoch 31, batch 870, train_loss 0.690
epoch 31, batch 880, train_loss 0.696
epoch 31, batch 890, train_loss 0.688
epoch 31, batch 900, train_loss 0.695
epoch 31, batch 910, train_loss 0.688
epoch 31, batch 920, train_loss 0.690
epoch 31, batch 930, train_loss 0.693
epoch 31, batch 940, train_loss 0.688
epoch 31, batch 950, train_loss 0.694
epoch 31, batch 960, train_loss 0.700
epoch 31, batch 970, train_loss 0.700
epoch 31, batch 980, train_loss 0.693
epoch 31, batch 990, train_loss 0.680
epoch 31, batch 1000, train_loss 0.697
epoch 31, batch 1010, train_loss 0.693
epoch 31, batch 1020, train_loss 0.689
epoch 31, batch 1030, train_loss 0.693
epoch 31, batch 1040, train_loss 0.697
epoch 31, batch 1050, train_loss 0.704
epoch 31, batch 1060, train_loss 0.691
epoch 31, batch 1070, train_loss 0.694
epoch 31, batch 1080, train_loss 0.694
epoch 31, batch 1090, train_loss 0.690
epoch 31, batch 1100, train_loss 0.702
epoch 31, batch 1110, train_loss 0.700
epoch 31, batch 1120, train_loss 0.685
epoch 31, batch 1130, train_loss 0.686
epoch 31, batch 1140, train_loss 0.689
epoch 31, batch 1150, train_loss 0.701
epoch 31, batch 1160, train_loss 0.694
epoch 31, batch 1170, train_loss 0.692
epoch 31, batch 1180, train_loss 0.697
epoch 31, batch 1190, train_loss 0.695
epoch 31, train_loss 0.693, valid_loss 0.723, train_accuracy  70.19%, valid_accuracy  68.57%
epoch 32, batch 0, train_loss 0.693
epoch 32, batch 10, train_loss 0.688
epoch 32, batch 20, train_loss 0.692
epoch 32, batch 30, train_loss 0.688
epoch 32, batch 40, train_loss 0.689
epoch 32, batch 50, train_loss 0.688
epoch 32, batch 60, train_loss 0.689
epoch 32, batch 70, train_loss 0.695
epoch 32, batch 80, train_loss 0.695
epoch 32, batch 90, train_loss 0.691
epoch 32, batch 100, train_loss 0.700
epoch 32, batch 110, train_loss 0.695
epoch 32, batch 120, train_loss 0.692
epoch 32, batch 130, train_loss 0.690
epoch 32, batch 140, train_loss 0.690
epoch 32, batch 150, train_loss 0.696
epoch 32, batch 160, train_loss 0.694
epoch 32, batch 170, train_loss 0.692
epoch 32, batch 180, train_loss 0.684
epoch 32, batch 190, train_loss 0.701
epoch 32, batch 200, train_loss 0.700
epoch 32, batch 210, train_loss 0.696
epoch 32, batch 220, train_loss 0.694
epoch 32, batch 230, train_loss 0.697
epoch 32, batch 240, train_loss 0.699
epoch 32, batch 250, train_loss 0.699
epoch 32, batch 260, train_loss 0.689
epoch 32, batch 270, train_loss 0.687
epoch 32, batch 280, train_loss 0.696
epoch 32, batch 290, train_loss 0.700
epoch 32, batch 300, train_loss 0.683
epoch 32, batch 310, train_loss 0.701
epoch 32, batch 320, train_loss 0.702
epoch 32, batch 330, train_loss 0.703
epoch 32, batch 340, train_loss 0.686
epoch 32, batch 350, train_loss 0.700
epoch 32, batch 360, train_loss 0.698
epoch 32, batch 370, train_loss 0.696
epoch 32, batch 380, train_loss 0.706
epoch 32, batch 390, train_loss 0.689
epoch 32, batch 400, train_loss 0.703
epoch 32, batch 410, train_loss 0.682
epoch 32, batch 420, train_loss 0.693
epoch 32, batch 430, train_loss 0.695
epoch 32, batch 440, train_loss 0.701
epoch 32, batch 450, train_loss 0.697
epoch 32, batch 460, train_loss 0.693
epoch 32, batch 470, train_loss 0.697
epoch 32, batch 480, train_loss 0.690
epoch 32, batch 490, train_loss 0.695
epoch 32, batch 500, train_loss 0.687
epoch 32, batch 510, train_loss 0.697
epoch 32, batch 520, train_loss 0.693
epoch 32, batch 530, train_loss 0.691
epoch 32, batch 540, train_loss 0.696
epoch 32, batch 550, train_loss 0.699
epoch 32, batch 560, train_loss 0.679
epoch 32, batch 570, train_loss 0.692
epoch 32, batch 580, train_loss 0.694
epoch 32, batch 590, train_loss 0.696
epoch 32, batch 600, train_loss 0.696
epoch 32, batch 610, train_loss 0.692
epoch 32, batch 620, train_loss 0.698
epoch 32, batch 630, train_loss 0.691
epoch 32, batch 640, train_loss 0.688
epoch 32, batch 650, train_loss 0.696
epoch 32, batch 660, train_loss 0.699
epoch 32, batch 670, train_loss 0.700
epoch 32, batch 680, train_loss 0.703
epoch 32, batch 690, train_loss 0.686
epoch 32, batch 700, train_loss 0.700
epoch 32, batch 710, train_loss 0.695
epoch 32, batch 720, train_loss 0.698
epoch 32, batch 730, train_loss 0.691
epoch 32, batch 740, train_loss 0.702
epoch 32, batch 750, train_loss 0.691
epoch 32, batch 760, train_loss 0.690
epoch 32, batch 770, train_loss 0.690
epoch 32, batch 780, train_loss 0.695
epoch 32, batch 790, train_loss 0.692
epoch 32, batch 800, train_loss 0.697
epoch 32, batch 810, train_loss 0.698
epoch 32, batch 820, train_loss 0.701
epoch 32, batch 830, train_loss 0.694
epoch 32, batch 840, train_loss 0.695
epoch 32, batch 850, train_loss 0.695
epoch 32, batch 860, train_loss 0.686
epoch 32, batch 870, train_loss 0.685
epoch 32, batch 880, train_loss 0.691
epoch 32, batch 890, train_loss 0.694
epoch 32, batch 900, train_loss 0.689
epoch 32, batch 910, train_loss 0.692
epoch 32, batch 920, train_loss 0.701
epoch 32, batch 930, train_loss 0.697
epoch 32, batch 940, train_loss 0.698
epoch 32, batch 950, train_loss 0.694
epoch 32, batch 960, train_loss 0.698
epoch 32, batch 970, train_loss 0.691
epoch 32, batch 980, train_loss 0.698
epoch 32, batch 990, train_loss 0.708
epoch 32, batch 1000, train_loss 0.686
epoch 32, batch 1010, train_loss 0.699
epoch 32, batch 1020, train_loss 0.700
epoch 32, batch 1030, train_loss 0.682
epoch 32, batch 1040, train_loss 0.694
epoch 32, batch 1050, train_loss 0.694
epoch 32, batch 1060, train_loss 0.685
epoch 32, batch 1070, train_loss 0.692
epoch 32, batch 1080, train_loss 0.689
epoch 32, batch 1090, train_loss 0.699
epoch 32, batch 1100, train_loss 0.690
epoch 32, batch 1110, train_loss 0.688
epoch 32, batch 1120, train_loss 0.695
epoch 32, batch 1130, train_loss 0.694
epoch 32, batch 1140, train_loss 0.700
epoch 32, batch 1150, train_loss 0.704
epoch 32, batch 1160, train_loss 0.703
epoch 32, batch 1170, train_loss 0.698
epoch 32, batch 1180, train_loss 0.688
epoch 32, batch 1190, train_loss 0.697
epoch 32, train_loss 0.693, valid_loss 0.723, train_accuracy  70.18%, valid_accuracy  68.57%
epoch 33, batch 0, train_loss 0.691
epoch 33, batch 10, train_loss 0.687
epoch 33, batch 20, train_loss 0.695
epoch 33, batch 30, train_loss 0.693
epoch 33, batch 40, train_loss 0.686
epoch 33, batch 50, train_loss 0.699
epoch 33, batch 60, train_loss 0.693
epoch 33, batch 70, train_loss 0.695
epoch 33, batch 80, train_loss 0.695
epoch 33, batch 90, train_loss 0.691
epoch 33, batch 100, train_loss 0.693
epoch 33, batch 110, train_loss 0.685
epoch 33, batch 120, train_loss 0.697
epoch 33, batch 130, train_loss 0.693
epoch 33, batch 140, train_loss 0.688
epoch 33, batch 150, train_loss 0.692
epoch 33, batch 160, train_loss 0.698
epoch 33, batch 170, train_loss 0.693
epoch 33, batch 180, train_loss 0.687
epoch 33, batch 190, train_loss 0.692
epoch 33, batch 200, train_loss 0.689
epoch 33, batch 210, train_loss 0.692
epoch 33, batch 220, train_loss 0.687
epoch 33, batch 230, train_loss 0.687
epoch 33, batch 240, train_loss 0.696
epoch 33, batch 250, train_loss 0.693
epoch 33, batch 260, train_loss 0.694
epoch 33, batch 270, train_loss 0.700
epoch 33, batch 280, train_loss 0.700
epoch 33, batch 290, train_loss 0.701
epoch 33, batch 300, train_loss 0.695
epoch 33, batch 310, train_loss 0.701
epoch 33, batch 320, train_loss 0.698
epoch 33, batch 330, train_loss 0.691
epoch 33, batch 340, train_loss 0.693
epoch 33, batch 350, train_loss 0.684
epoch 33, batch 360, train_loss 0.693
epoch 33, batch 370, train_loss 0.692
epoch 33, batch 380, train_loss 0.689
epoch 33, batch 390, train_loss 0.694
epoch 33, batch 400, train_loss 0.695
epoch 33, batch 410, train_loss 0.693
epoch 33, batch 420, train_loss 0.692
epoch 33, batch 430, train_loss 0.700
epoch 33, batch 440, train_loss 0.697
epoch 33, batch 450, train_loss 0.686
epoch 33, batch 460, train_loss 0.693
epoch 33, batch 470, train_loss 0.694
epoch 33, batch 480, train_loss 0.696
epoch 33, batch 490, train_loss 0.693
epoch 33, batch 500, train_loss 0.695
epoch 33, batch 510, train_loss 0.691
epoch 33, batch 520, train_loss 0.691
epoch 33, batch 530, train_loss 0.701
epoch 33, batch 540, train_loss 0.691
epoch 33, batch 550, train_loss 0.694
epoch 33, batch 560, train_loss 0.689
epoch 33, batch 570, train_loss 0.691
epoch 33, batch 580, train_loss 0.698
epoch 33, batch 590, train_loss 0.696
epoch 33, batch 600, train_loss 0.704
epoch 33, batch 610, train_loss 0.698
epoch 33, batch 620, train_loss 0.689
epoch 33, batch 630, train_loss 0.693
epoch 33, batch 640, train_loss 0.688
epoch 33, batch 650, train_loss 0.701
epoch 33, batch 660, train_loss 0.698
epoch 33, batch 670, train_loss 0.692
epoch 33, batch 680, train_loss 0.697
epoch 33, batch 690, train_loss 0.685
epoch 33, batch 700, train_loss 0.688
epoch 33, batch 710, train_loss 0.695
epoch 33, batch 720, train_loss 0.687
epoch 33, batch 730, train_loss 0.694
epoch 33, batch 740, train_loss 0.699
epoch 33, batch 750, train_loss 0.694
epoch 33, batch 760, train_loss 0.690
epoch 33, batch 770, train_loss 0.688
epoch 33, batch 780, train_loss 0.690
epoch 33, batch 790, train_loss 0.694
epoch 33, batch 800, train_loss 0.693
epoch 33, batch 810, train_loss 0.694
epoch 33, batch 820, train_loss 0.704
epoch 33, batch 830, train_loss 0.700
epoch 33, batch 840, train_loss 0.689
epoch 33, batch 850, train_loss 0.694
epoch 33, batch 860, train_loss 0.703
epoch 33, batch 870, train_loss 0.693
epoch 33, batch 880, train_loss 0.695
epoch 33, batch 890, train_loss 0.693
epoch 33, batch 900, train_loss 0.695
epoch 33, batch 910, train_loss 0.704
epoch 33, batch 920, train_loss 0.684
epoch 33, batch 930, train_loss 0.702
epoch 33, batch 940, train_loss 0.692
epoch 33, batch 950, train_loss 0.697
epoch 33, batch 960, train_loss 0.693
epoch 33, batch 970, train_loss 0.695
epoch 33, batch 980, train_loss 0.689
epoch 33, batch 990, train_loss 0.689
epoch 33, batch 1000, train_loss 0.689
epoch 33, batch 1010, train_loss 0.686
epoch 33, batch 1020, train_loss 0.697
epoch 33, batch 1030, train_loss 0.701
epoch 33, batch 1040, train_loss 0.698
epoch 33, batch 1050, train_loss 0.704
epoch 33, batch 1060, train_loss 0.689
epoch 33, batch 1070, train_loss 0.693
epoch 33, batch 1080, train_loss 0.692
epoch 33, batch 1090, train_loss 0.688
epoch 33, batch 1100, train_loss 0.696
epoch 33, batch 1110, train_loss 0.698
epoch 33, batch 1120, train_loss 0.694
epoch 33, batch 1130, train_loss 0.705
epoch 33, batch 1140, train_loss 0.694
epoch 33, batch 1150, train_loss 0.694
epoch 33, batch 1160, train_loss 0.693
epoch 33, batch 1170, train_loss 0.702
epoch 33, batch 1180, train_loss 0.694
epoch 33, batch 1190, train_loss 0.700
epoch 33, train_loss 0.693, valid_loss 0.723, train_accuracy  70.23%, valid_accuracy  68.56%
epoch 34, batch 0, train_loss 0.693
epoch 34, batch 10, train_loss 0.689
epoch 34, batch 20, train_loss 0.694
epoch 34, batch 30, train_loss 0.698
epoch 34, batch 40, train_loss 0.697
epoch 34, batch 50, train_loss 0.697
epoch 34, batch 60, train_loss 0.692
epoch 34, batch 70, train_loss 0.690
epoch 34, batch 80, train_loss 0.692
epoch 34, batch 90, train_loss 0.696
epoch 34, batch 100, train_loss 0.700
epoch 34, batch 110, train_loss 0.699
epoch 34, batch 120, train_loss 0.690
epoch 34, batch 130, train_loss 0.680
epoch 34, batch 140, train_loss 0.685
epoch 34, batch 150, train_loss 0.686
epoch 34, batch 160, train_loss 0.687
epoch 34, batch 170, train_loss 0.686
epoch 34, batch 180, train_loss 0.697
epoch 34, batch 190, train_loss 0.700
epoch 34, batch 200, train_loss 0.688
epoch 34, batch 210, train_loss 0.694
epoch 34, batch 220, train_loss 0.688
epoch 34, batch 230, train_loss 0.689
epoch 34, batch 240, train_loss 0.689
epoch 34, batch 250, train_loss 0.690
epoch 34, batch 260, train_loss 0.691
epoch 34, batch 270, train_loss 0.689
epoch 34, batch 280, train_loss 0.689
epoch 34, batch 290, train_loss 0.690
epoch 34, batch 300, train_loss 0.688
epoch 34, batch 310, train_loss 0.687
epoch 34, batch 320, train_loss 0.699
epoch 34, batch 330, train_loss 0.688
epoch 34, batch 340, train_loss 0.690
epoch 34, batch 350, train_loss 0.697
epoch 34, batch 360, train_loss 0.699
epoch 34, batch 370, train_loss 0.697
epoch 34, batch 380, train_loss 0.695
epoch 34, batch 390, train_loss 0.685
epoch 34, batch 400, train_loss 0.700
epoch 34, batch 410, train_loss 0.693
epoch 34, batch 420, train_loss 0.705
epoch 34, batch 430, train_loss 0.685
epoch 34, batch 440, train_loss 0.698
epoch 34, batch 450, train_loss 0.696
epoch 34, batch 460, train_loss 0.694
epoch 34, batch 470, train_loss 0.683
epoch 34, batch 480, train_loss 0.700
epoch 34, batch 490, train_loss 0.693
epoch 34, batch 500, train_loss 0.691
epoch 34, batch 510, train_loss 0.700
epoch 34, batch 520, train_loss 0.691
epoch 34, batch 530, train_loss 0.705
epoch 34, batch 540, train_loss 0.694
epoch 34, batch 550, train_loss 0.697
epoch 34, batch 560, train_loss 0.688
epoch 34, batch 570, train_loss 0.700
epoch 34, batch 580, train_loss 0.683
epoch 34, batch 590, train_loss 0.685
epoch 34, batch 600, train_loss 0.706
epoch 34, batch 610, train_loss 0.699
epoch 34, batch 620, train_loss 0.697
epoch 34, batch 630, train_loss 0.697
epoch 34, batch 640, train_loss 0.694
epoch 34, batch 650, train_loss 0.692
epoch 34, batch 660, train_loss 0.697
epoch 34, batch 670, train_loss 0.700
epoch 34, batch 680, train_loss 0.692
epoch 34, batch 690, train_loss 0.699
epoch 34, batch 700, train_loss 0.692
epoch 34, batch 710, train_loss 0.688
epoch 34, batch 720, train_loss 0.691
epoch 34, batch 730, train_loss 0.694
epoch 34, batch 740, train_loss 0.694
epoch 34, batch 750, train_loss 0.688
epoch 34, batch 760, train_loss 0.687
epoch 34, batch 770, train_loss 0.700
epoch 34, batch 780, train_loss 0.693
epoch 34, batch 790, train_loss 0.688
epoch 34, batch 800, train_loss 0.697
epoch 34, batch 810, train_loss 0.683
epoch 34, batch 820, train_loss 0.696
epoch 34, batch 830, train_loss 0.690
epoch 34, batch 840, train_loss 0.686
epoch 34, batch 850, train_loss 0.688
epoch 34, batch 860, train_loss 0.686
epoch 34, batch 870, train_loss 0.694
epoch 34, batch 880, train_loss 0.694
epoch 34, batch 890, train_loss 0.689
epoch 34, batch 900, train_loss 0.689
epoch 34, batch 910, train_loss 0.688
epoch 34, batch 920, train_loss 0.698
epoch 34, batch 930, train_loss 0.687
epoch 34, batch 940, train_loss 0.687
epoch 34, batch 950, train_loss 0.690
epoch 34, batch 960, train_loss 0.690
epoch 34, batch 970, train_loss 0.696
epoch 34, batch 980, train_loss 0.693
epoch 34, batch 990, train_loss 0.703
epoch 34, batch 1000, train_loss 0.687
epoch 34, batch 1010, train_loss 0.710
epoch 34, batch 1020, train_loss 0.702
epoch 34, batch 1030, train_loss 0.691
epoch 34, batch 1040, train_loss 0.701
epoch 34, batch 1050, train_loss 0.686
epoch 34, batch 1060, train_loss 0.702
epoch 34, batch 1070, train_loss 0.698
epoch 34, batch 1080, train_loss 0.686
epoch 34, batch 1090, train_loss 0.691
epoch 34, batch 1100, train_loss 0.685
epoch 34, batch 1110, train_loss 0.693
epoch 34, batch 1120, train_loss 0.699
epoch 34, batch 1130, train_loss 0.699
epoch 34, batch 1140, train_loss 0.700
epoch 34, batch 1150, train_loss 0.699
epoch 34, batch 1160, train_loss 0.682
epoch 34, batch 1170, train_loss 0.699
epoch 34, batch 1180, train_loss 0.682
epoch 34, batch 1190, train_loss 0.698
epoch 34, train_loss 0.693, valid_loss 0.722, train_accuracy  70.24%, valid_accuracy  68.62%
epoch 35, batch 0, train_loss 0.698
epoch 35, batch 10, train_loss 0.697
epoch 35, batch 20, train_loss 0.682
epoch 35, batch 30, train_loss 0.705
epoch 35, batch 40, train_loss 0.697
epoch 35, batch 50, train_loss 0.695
epoch 35, batch 60, train_loss 0.680
epoch 35, batch 70, train_loss 0.696
epoch 35, batch 80, train_loss 0.697
epoch 35, batch 90, train_loss 0.692
epoch 35, batch 100, train_loss 0.688
epoch 35, batch 110, train_loss 0.695
epoch 35, batch 120, train_loss 0.698
epoch 35, batch 130, train_loss 0.696
epoch 35, batch 140, train_loss 0.699
epoch 35, batch 150, train_loss 0.689
epoch 35, batch 160, train_loss 0.696
epoch 35, batch 170, train_loss 0.686
epoch 35, batch 180, train_loss 0.694
epoch 35, batch 190, train_loss 0.693
epoch 35, batch 200, train_loss 0.694
epoch 35, batch 210, train_loss 0.693
epoch 35, batch 220, train_loss 0.692
epoch 35, batch 230, train_loss 0.692
epoch 35, batch 240, train_loss 0.697
epoch 35, batch 250, train_loss 0.692
epoch 35, batch 260, train_loss 0.694
epoch 35, batch 270, train_loss 0.689
epoch 35, batch 280, train_loss 0.697
epoch 35, batch 290, train_loss 0.693
epoch 35, batch 300, train_loss 0.702
epoch 35, batch 310, train_loss 0.691
epoch 35, batch 320, train_loss 0.695
epoch 35, batch 330, train_loss 0.689
epoch 35, batch 340, train_loss 0.690
epoch 35, batch 350, train_loss 0.699
epoch 35, batch 360, train_loss 0.694
epoch 35, batch 370, train_loss 0.703
epoch 35, batch 380, train_loss 0.686
epoch 35, batch 390, train_loss 0.689
epoch 35, batch 400, train_loss 0.688
epoch 35, batch 410, train_loss 0.704
epoch 35, batch 420, train_loss 0.688
epoch 35, batch 430, train_loss 0.690
epoch 35, batch 440, train_loss 0.700
epoch 35, batch 450, train_loss 0.700
epoch 35, batch 460, train_loss 0.696
epoch 35, batch 470, train_loss 0.687
epoch 35, batch 480, train_loss 0.692
epoch 35, batch 490, train_loss 0.695
epoch 35, batch 500, train_loss 0.696
epoch 35, batch 510, train_loss 0.692
epoch 35, batch 520, train_loss 0.690
epoch 35, batch 530, train_loss 0.700
epoch 35, batch 540, train_loss 0.688
epoch 35, batch 550, train_loss 0.687
epoch 35, batch 560, train_loss 0.687
epoch 35, batch 570, train_loss 0.697
epoch 35, batch 580, train_loss 0.698
epoch 35, batch 590, train_loss 0.693
epoch 35, batch 600, train_loss 0.692
epoch 35, batch 610, train_loss 0.701
epoch 35, batch 620, train_loss 0.679
epoch 35, batch 630, train_loss 0.690
epoch 35, batch 640, train_loss 0.690
epoch 35, batch 650, train_loss 0.683
epoch 35, batch 660, train_loss 0.689
epoch 35, batch 670, train_loss 0.701
epoch 35, batch 680, train_loss 0.696
epoch 35, batch 690, train_loss 0.687
epoch 35, batch 700, train_loss 0.691
epoch 35, batch 710, train_loss 0.685
epoch 35, batch 720, train_loss 0.688
epoch 35, batch 730, train_loss 0.697
epoch 35, batch 740, train_loss 0.694
epoch 35, batch 750, train_loss 0.691
epoch 35, batch 760, train_loss 0.687
epoch 35, batch 770, train_loss 0.695
epoch 35, batch 780, train_loss 0.684
epoch 35, batch 790, train_loss 0.707
epoch 35, batch 800, train_loss 0.707
epoch 35, batch 810, train_loss 0.695
epoch 35, batch 820, train_loss 0.703
epoch 35, batch 830, train_loss 0.695
epoch 35, batch 840, train_loss 0.696
epoch 35, batch 850, train_loss 0.693
epoch 35, batch 860, train_loss 0.692
epoch 35, batch 870, train_loss 0.697
epoch 35, batch 880, train_loss 0.697
epoch 35, batch 890, train_loss 0.686
epoch 35, batch 900, train_loss 0.690
epoch 35, batch 910, train_loss 0.689
epoch 35, batch 920, train_loss 0.702
epoch 35, batch 930, train_loss 0.698
epoch 35, batch 940, train_loss 0.687
epoch 35, batch 950, train_loss 0.693
epoch 35, batch 960, train_loss 0.686
epoch 35, batch 970, train_loss 0.687
epoch 35, batch 980, train_loss 0.694
epoch 35, batch 990, train_loss 0.696
epoch 35, batch 1000, train_loss 0.696
epoch 35, batch 1010, train_loss 0.696
epoch 35, batch 1020, train_loss 0.697
epoch 35, batch 1030, train_loss 0.693
epoch 35, batch 1040, train_loss 0.695
epoch 35, batch 1050, train_loss 0.693
epoch 35, batch 1060, train_loss 0.689
epoch 35, batch 1070, train_loss 0.687
epoch 35, batch 1080, train_loss 0.704
epoch 35, batch 1090, train_loss 0.685
epoch 35, batch 1100, train_loss 0.700
epoch 35, batch 1110, train_loss 0.686
epoch 35, batch 1120, train_loss 0.687
epoch 35, batch 1130, train_loss 0.693
epoch 35, batch 1140, train_loss 0.691
epoch 35, batch 1150, train_loss 0.689
epoch 35, batch 1160, train_loss 0.699
epoch 35, batch 1170, train_loss 0.705
epoch 35, batch 1180, train_loss 0.692
epoch 35, batch 1190, train_loss 0.681
epoch 35, train_loss 0.692, valid_loss 0.723, train_accuracy  70.25%, valid_accuracy  68.63%
model saved with highest valid accuracy:  68.63%
epoch 36, batch 0, train_loss 0.694
epoch 36, batch 10, train_loss 0.698
epoch 36, batch 20, train_loss 0.692
epoch 36, batch 30, train_loss 0.694
epoch 36, batch 40, train_loss 0.697
epoch 36, batch 50, train_loss 0.692
epoch 36, batch 60, train_loss 0.694
epoch 36, batch 70, train_loss 0.690
epoch 36, batch 80, train_loss 0.690
epoch 36, batch 90, train_loss 0.697
epoch 36, batch 100, train_loss 0.695
epoch 36, batch 110, train_loss 0.704
epoch 36, batch 120, train_loss 0.696
epoch 36, batch 130, train_loss 0.691
epoch 36, batch 140, train_loss 0.693
epoch 36, batch 150, train_loss 0.697
epoch 36, batch 160, train_loss 0.688
epoch 36, batch 170, train_loss 0.690
epoch 36, batch 180, train_loss 0.707
epoch 36, batch 190, train_loss 0.686
epoch 36, batch 200, train_loss 0.691
epoch 36, batch 210, train_loss 0.696
epoch 36, batch 220, train_loss 0.687
epoch 36, batch 230, train_loss 0.697
epoch 36, batch 240, train_loss 0.688
epoch 36, batch 250, train_loss 0.683
epoch 36, batch 260, train_loss 0.700
epoch 36, batch 270, train_loss 0.694
epoch 36, batch 280, train_loss 0.696
epoch 36, batch 290, train_loss 0.691
epoch 36, batch 300, train_loss 0.687
epoch 36, batch 310, train_loss 0.691
epoch 36, batch 320, train_loss 0.701
epoch 36, batch 330, train_loss 0.695
epoch 36, batch 340, train_loss 0.693
epoch 36, batch 350, train_loss 0.696
epoch 36, batch 360, train_loss 0.689
epoch 36, batch 370, train_loss 0.698
epoch 36, batch 380, train_loss 0.693
epoch 36, batch 390, train_loss 0.698
epoch 36, batch 400, train_loss 0.697
epoch 36, batch 410, train_loss 0.696
epoch 36, batch 420, train_loss 0.693
epoch 36, batch 430, train_loss 0.692
epoch 36, batch 440, train_loss 0.688
epoch 36, batch 450, train_loss 0.689
epoch 36, batch 460, train_loss 0.689
epoch 36, batch 470, train_loss 0.696
epoch 36, batch 480, train_loss 0.696
epoch 36, batch 490, train_loss 0.683
epoch 36, batch 500, train_loss 0.698
epoch 36, batch 510, train_loss 0.694
epoch 36, batch 520, train_loss 0.689
epoch 36, batch 530, train_loss 0.697
epoch 36, batch 540, train_loss 0.684
epoch 36, batch 550, train_loss 0.697
epoch 36, batch 560, train_loss 0.699
epoch 36, batch 570, train_loss 0.695
epoch 36, batch 580, train_loss 0.693
epoch 36, batch 590, train_loss 0.689
epoch 36, batch 600, train_loss 0.697
epoch 36, batch 610, train_loss 0.698
epoch 36, batch 620, train_loss 0.697
epoch 36, batch 630, train_loss 0.695
epoch 36, batch 640, train_loss 0.705
epoch 36, batch 650, train_loss 0.701
epoch 36, batch 660, train_loss 0.695
epoch 36, batch 670, train_loss 0.697
epoch 36, batch 680, train_loss 0.701
epoch 36, batch 690, train_loss 0.693
epoch 36, batch 700, train_loss 0.690
epoch 36, batch 710, train_loss 0.699
epoch 36, batch 720, train_loss 0.691
epoch 36, batch 730, train_loss 0.695
epoch 36, batch 740, train_loss 0.697
epoch 36, batch 750, train_loss 0.701
epoch 36, batch 760, train_loss 0.691
epoch 36, batch 770, train_loss 0.694
epoch 36, batch 780, train_loss 0.703
epoch 36, batch 790, train_loss 0.697
epoch 36, batch 800, train_loss 0.694
epoch 36, batch 810, train_loss 0.709
epoch 36, batch 820, train_loss 0.699
epoch 36, batch 830, train_loss 0.692
epoch 36, batch 840, train_loss 0.693
epoch 36, batch 850, train_loss 0.700
epoch 36, batch 860, train_loss 0.694
epoch 36, batch 870, train_loss 0.691
epoch 36, batch 880, train_loss 0.681
epoch 36, batch 890, train_loss 0.699
epoch 36, batch 900, train_loss 0.692
epoch 36, batch 910, train_loss 0.699
epoch 36, batch 920, train_loss 0.697
epoch 36, batch 930, train_loss 0.684
epoch 36, batch 940, train_loss 0.697
epoch 36, batch 950, train_loss 0.683
epoch 36, batch 960, train_loss 0.689
epoch 36, batch 970, train_loss 0.693
epoch 36, batch 980, train_loss 0.690
epoch 36, batch 990, train_loss 0.699
epoch 36, batch 1000, train_loss 0.695
epoch 36, batch 1010, train_loss 0.684
epoch 36, batch 1020, train_loss 0.690
epoch 36, batch 1030, train_loss 0.693
epoch 36, batch 1040, train_loss 0.695
epoch 36, batch 1050, train_loss 0.694
epoch 36, batch 1060, train_loss 0.696
epoch 36, batch 1070, train_loss 0.690
epoch 36, batch 1080, train_loss 0.691
epoch 36, batch 1090, train_loss 0.708
epoch 36, batch 1100, train_loss 0.701
epoch 36, batch 1110, train_loss 0.689
epoch 36, batch 1120, train_loss 0.691
epoch 36, batch 1130, train_loss 0.685
epoch 36, batch 1140, train_loss 0.700
epoch 36, batch 1150, train_loss 0.690
epoch 36, batch 1160, train_loss 0.688
epoch 36, batch 1170, train_loss 0.696
epoch 36, batch 1180, train_loss 0.694
epoch 36, batch 1190, train_loss 0.688
epoch 36, train_loss 0.692, valid_loss 0.723, train_accuracy  70.23%, valid_accuracy  68.57%
epoch 37, batch 0, train_loss 0.689
epoch 37, batch 10, train_loss 0.694
epoch 37, batch 20, train_loss 0.700
epoch 37, batch 30, train_loss 0.688
epoch 37, batch 40, train_loss 0.705
epoch 37, batch 50, train_loss 0.688
epoch 37, batch 60, train_loss 0.699
epoch 37, batch 70, train_loss 0.686
epoch 37, batch 80, train_loss 0.689
epoch 37, batch 90, train_loss 0.690
epoch 37, batch 100, train_loss 0.694
epoch 37, batch 110, train_loss 0.700
epoch 37, batch 120, train_loss 0.698
epoch 37, batch 130, train_loss 0.686
epoch 37, batch 140, train_loss 0.700
epoch 37, batch 150, train_loss 0.700
epoch 37, batch 160, train_loss 0.697
epoch 37, batch 170, train_loss 0.683
epoch 37, batch 180, train_loss 0.693
epoch 37, batch 190, train_loss 0.684
epoch 37, batch 200, train_loss 0.693
epoch 37, batch 210, train_loss 0.692
epoch 37, batch 220, train_loss 0.688
epoch 37, batch 230, train_loss 0.696
epoch 37, batch 240, train_loss 0.689
epoch 37, batch 250, train_loss 0.685
epoch 37, batch 260, train_loss 0.696
epoch 37, batch 270, train_loss 0.689
epoch 37, batch 280, train_loss 0.684
epoch 37, batch 290, train_loss 0.696
epoch 37, batch 300, train_loss 0.695
epoch 37, batch 310, train_loss 0.691
epoch 37, batch 320, train_loss 0.701
epoch 37, batch 330, train_loss 0.693
epoch 37, batch 340, train_loss 0.697
epoch 37, batch 350, train_loss 0.697
epoch 37, batch 360, train_loss 0.685
epoch 37, batch 370, train_loss 0.693
epoch 37, batch 380, train_loss 0.698
epoch 37, batch 390, train_loss 0.697
epoch 37, batch 400, train_loss 0.688
epoch 37, batch 410, train_loss 0.694
epoch 37, batch 420, train_loss 0.699
epoch 37, batch 430, train_loss 0.690
epoch 37, batch 440, train_loss 0.695
epoch 37, batch 450, train_loss 0.695
epoch 37, batch 460, train_loss 0.688
epoch 37, batch 470, train_loss 0.703
epoch 37, batch 480, train_loss 0.697
epoch 37, batch 490, train_loss 0.688
epoch 37, batch 500, train_loss 0.698
epoch 37, batch 510, train_loss 0.688
epoch 37, batch 520, train_loss 0.690
epoch 37, batch 530, train_loss 0.685
epoch 37, batch 540, train_loss 0.697
epoch 37, batch 550, train_loss 0.687
epoch 37, batch 560, train_loss 0.689
epoch 37, batch 570, train_loss 0.691
epoch 37, batch 580, train_loss 0.690
epoch 37, batch 590, train_loss 0.690
epoch 37, batch 600, train_loss 0.684
epoch 37, batch 610, train_loss 0.689
epoch 37, batch 620, train_loss 0.691
epoch 37, batch 630, train_loss 0.695
epoch 37, batch 640, train_loss 0.689
epoch 37, batch 650, train_loss 0.696
epoch 37, batch 660, train_loss 0.692
epoch 37, batch 670, train_loss 0.690
epoch 37, batch 680, train_loss 0.696
epoch 37, batch 690, train_loss 0.694
epoch 37, batch 700, train_loss 0.697
epoch 37, batch 710, train_loss 0.687
epoch 37, batch 720, train_loss 0.697
epoch 37, batch 730, train_loss 0.690
epoch 37, batch 740, train_loss 0.691
epoch 37, batch 750, train_loss 0.705
epoch 37, batch 760, train_loss 0.692
epoch 37, batch 770, train_loss 0.687
epoch 37, batch 780, train_loss 0.698
epoch 37, batch 790, train_loss 0.702
epoch 37, batch 800, train_loss 0.688
epoch 37, batch 810, train_loss 0.696
epoch 37, batch 820, train_loss 0.688
epoch 37, batch 830, train_loss 0.694
epoch 37, batch 840, train_loss 0.684
epoch 37, batch 850, train_loss 0.694
epoch 37, batch 860, train_loss 0.691
epoch 37, batch 870, train_loss 0.692
epoch 37, batch 880, train_loss 0.701
epoch 37, batch 890, train_loss 0.690
epoch 37, batch 900, train_loss 0.690
epoch 37, batch 910, train_loss 0.692
epoch 37, batch 920, train_loss 0.684
epoch 37, batch 930, train_loss 0.683
epoch 37, batch 940, train_loss 0.691
epoch 37, batch 950, train_loss 0.696
epoch 37, batch 960, train_loss 0.700
epoch 37, batch 970, train_loss 0.691
epoch 37, batch 980, train_loss 0.687
epoch 37, batch 990, train_loss 0.699
epoch 37, batch 1000, train_loss 0.700
epoch 37, batch 1010, train_loss 0.700
epoch 37, batch 1020, train_loss 0.710
epoch 37, batch 1030, train_loss 0.689
epoch 37, batch 1040, train_loss 0.694
epoch 37, batch 1050, train_loss 0.690
epoch 37, batch 1060, train_loss 0.696
epoch 37, batch 1070, train_loss 0.692
epoch 37, batch 1080, train_loss 0.692
epoch 37, batch 1090, train_loss 0.688
epoch 37, batch 1100, train_loss 0.696
epoch 37, batch 1110, train_loss 0.695
epoch 37, batch 1120, train_loss 0.694
epoch 37, batch 1130, train_loss 0.685
epoch 37, batch 1140, train_loss 0.696
epoch 37, batch 1150, train_loss 0.692
epoch 37, batch 1160, train_loss 0.692
epoch 37, batch 1170, train_loss 0.691
epoch 37, batch 1180, train_loss 0.691
epoch 37, batch 1190, train_loss 0.707
epoch 37, train_loss 0.692, valid_loss 0.722, train_accuracy  70.26%, valid_accuracy  68.60%
epoch 38, batch 0, train_loss 0.685
epoch 38, batch 10, train_loss 0.682
epoch 38, batch 20, train_loss 0.690
epoch 38, batch 30, train_loss 0.693
epoch 38, batch 40, train_loss 0.703
epoch 38, batch 50, train_loss 0.688
epoch 38, batch 60, train_loss 0.698
epoch 38, batch 70, train_loss 0.689
epoch 38, batch 80, train_loss 0.686
epoch 38, batch 90, train_loss 0.693
epoch 38, batch 100, train_loss 0.695
epoch 38, batch 110, train_loss 0.694
epoch 38, batch 120, train_loss 0.686
epoch 38, batch 130, train_loss 0.684
epoch 38, batch 140, train_loss 0.692
epoch 38, batch 150, train_loss 0.693
epoch 38, batch 160, train_loss 0.703
epoch 38, batch 170, train_loss 0.693
epoch 38, batch 180, train_loss 0.694
epoch 38, batch 190, train_loss 0.686
epoch 38, batch 200, train_loss 0.697
epoch 38, batch 210, train_loss 0.693
epoch 38, batch 220, train_loss 0.688
epoch 38, batch 230, train_loss 0.697
epoch 38, batch 240, train_loss 0.693
epoch 38, batch 250, train_loss 0.697
epoch 38, batch 260, train_loss 0.691
epoch 38, batch 270, train_loss 0.686
epoch 38, batch 280, train_loss 0.687
epoch 38, batch 290, train_loss 0.697
epoch 38, batch 300, train_loss 0.698
epoch 38, batch 310, train_loss 0.698
epoch 38, batch 320, train_loss 0.700
epoch 38, batch 330, train_loss 0.695
epoch 38, batch 340, train_loss 0.692
epoch 38, batch 350, train_loss 0.700
epoch 38, batch 360, train_loss 0.685
epoch 38, batch 370, train_loss 0.692
epoch 38, batch 380, train_loss 0.693
epoch 38, batch 390, train_loss 0.700
epoch 38, batch 400, train_loss 0.683
epoch 38, batch 410, train_loss 0.697
epoch 38, batch 420, train_loss 0.690
epoch 38, batch 430, train_loss 0.696
epoch 38, batch 440, train_loss 0.692
epoch 38, batch 450, train_loss 0.697
epoch 38, batch 460, train_loss 0.692
epoch 38, batch 470, train_loss 0.692
epoch 38, batch 480, train_loss 0.695
epoch 38, batch 490, train_loss 0.706
epoch 38, batch 500, train_loss 0.693
epoch 38, batch 510, train_loss 0.685
epoch 38, batch 520, train_loss 0.695
epoch 38, batch 530, train_loss 0.694
epoch 38, batch 540, train_loss 0.691
epoch 38, batch 550, train_loss 0.703
epoch 38, batch 560, train_loss 0.697
epoch 38, batch 570, train_loss 0.690
epoch 38, batch 580, train_loss 0.680
epoch 38, batch 590, train_loss 0.702
epoch 38, batch 600, train_loss 0.706
epoch 38, batch 610, train_loss 0.684
epoch 38, batch 620, train_loss 0.695
epoch 38, batch 630, train_loss 0.693
epoch 38, batch 640, train_loss 0.695
epoch 38, batch 650, train_loss 0.681
epoch 38, batch 660, train_loss 0.694
epoch 38, batch 670, train_loss 0.694
epoch 38, batch 680, train_loss 0.704
epoch 38, batch 690, train_loss 0.692
epoch 38, batch 700, train_loss 0.690
epoch 38, batch 710, train_loss 0.696
epoch 38, batch 720, train_loss 0.691
epoch 38, batch 730, train_loss 0.701
epoch 38, batch 740, train_loss 0.698
epoch 38, batch 750, train_loss 0.697
epoch 38, batch 760, train_loss 0.691
epoch 38, batch 770, train_loss 0.690
epoch 38, batch 780, train_loss 0.698
epoch 38, batch 790, train_loss 0.689
epoch 38, batch 800, train_loss 0.692
epoch 38, batch 810, train_loss 0.695
epoch 38, batch 820, train_loss 0.695
epoch 38, batch 830, train_loss 0.689
epoch 38, batch 840, train_loss 0.696
epoch 38, batch 850, train_loss 0.691
epoch 38, batch 860, train_loss 0.704
epoch 38, batch 870, train_loss 0.692
epoch 38, batch 880, train_loss 0.692
epoch 38, batch 890, train_loss 0.685
epoch 38, batch 900, train_loss 0.699
epoch 38, batch 910, train_loss 0.700
epoch 38, batch 920, train_loss 0.676
epoch 38, batch 930, train_loss 0.686
epoch 38, batch 940, train_loss 0.702
epoch 38, batch 950, train_loss 0.704
epoch 38, batch 960, train_loss 0.684
epoch 38, batch 970, train_loss 0.705
epoch 38, batch 980, train_loss 0.694
epoch 38, batch 990, train_loss 0.696
epoch 38, batch 1000, train_loss 0.694
epoch 38, batch 1010, train_loss 0.689
epoch 38, batch 1020, train_loss 0.702
epoch 38, batch 1030, train_loss 0.689
epoch 38, batch 1040, train_loss 0.699
epoch 38, batch 1050, train_loss 0.695
epoch 38, batch 1060, train_loss 0.691
epoch 38, batch 1070, train_loss 0.697
epoch 38, batch 1080, train_loss 0.694
epoch 38, batch 1090, train_loss 0.694
epoch 38, batch 1100, train_loss 0.689
epoch 38, batch 1110, train_loss 0.692
epoch 38, batch 1120, train_loss 0.697
epoch 38, batch 1130, train_loss 0.692
epoch 38, batch 1140, train_loss 0.688
epoch 38, batch 1150, train_loss 0.695
epoch 38, batch 1160, train_loss 0.700
epoch 38, batch 1170, train_loss 0.686
epoch 38, batch 1180, train_loss 0.689
epoch 38, batch 1190, train_loss 0.699
epoch 38, train_loss 0.692, valid_loss 0.723, train_accuracy  70.25%, valid_accuracy  68.59%
epoch 39, batch 0, train_loss 0.702
epoch 39, batch 10, train_loss 0.694
epoch 39, batch 20, train_loss 0.690
epoch 39, batch 30, train_loss 0.700
epoch 39, batch 40, train_loss 0.703
epoch 39, batch 50, train_loss 0.689
epoch 39, batch 60, train_loss 0.707
epoch 39, batch 70, train_loss 0.696
epoch 39, batch 80, train_loss 0.689
epoch 39, batch 90, train_loss 0.698
epoch 39, batch 100, train_loss 0.681
epoch 39, batch 110, train_loss 0.693
epoch 39, batch 120, train_loss 0.689
epoch 39, batch 130, train_loss 0.702
epoch 39, batch 140, train_loss 0.691
epoch 39, batch 150, train_loss 0.690
epoch 39, batch 160, train_loss 0.694
epoch 39, batch 170, train_loss 0.691
epoch 39, batch 180, train_loss 0.692
epoch 39, batch 190, train_loss 0.702
epoch 39, batch 200, train_loss 0.702
epoch 39, batch 210, train_loss 0.699
epoch 39, batch 220, train_loss 0.689
epoch 39, batch 230, train_loss 0.688
epoch 39, batch 240, train_loss 0.689
epoch 39, batch 250, train_loss 0.689
epoch 39, batch 260, train_loss 0.698
epoch 39, batch 270, train_loss 0.690
epoch 39, batch 280, train_loss 0.689
epoch 39, batch 290, train_loss 0.677
epoch 39, batch 300, train_loss 0.693
epoch 39, batch 310, train_loss 0.700
epoch 39, batch 320, train_loss 0.690
epoch 39, batch 330, train_loss 0.696
epoch 39, batch 340, train_loss 0.694
epoch 39, batch 350, train_loss 0.701
epoch 39, batch 360, train_loss 0.702
epoch 39, batch 370, train_loss 0.697
epoch 39, batch 380, train_loss 0.699
epoch 39, batch 390, train_loss 0.690
epoch 39, batch 400, train_loss 0.700
epoch 39, batch 410, train_loss 0.698
epoch 39, batch 420, train_loss 0.694
epoch 39, batch 430, train_loss 0.689
epoch 39, batch 440, train_loss 0.689
epoch 39, batch 450, train_loss 0.697
epoch 39, batch 460, train_loss 0.692
epoch 39, batch 470, train_loss 0.696
epoch 39, batch 480, train_loss 0.697
epoch 39, batch 490, train_loss 0.687
epoch 39, batch 500, train_loss 0.691
epoch 39, batch 510, train_loss 0.694
epoch 39, batch 520, train_loss 0.706
epoch 39, batch 530, train_loss 0.694
epoch 39, batch 540, train_loss 0.690
epoch 39, batch 550, train_loss 0.698
epoch 39, batch 560, train_loss 0.687
epoch 39, batch 570, train_loss 0.696
epoch 39, batch 580, train_loss 0.685
epoch 39, batch 590, train_loss 0.696
epoch 39, batch 600, train_loss 0.696
epoch 39, batch 610, train_loss 0.701
epoch 39, batch 620, train_loss 0.693
epoch 39, batch 630, train_loss 0.689
epoch 39, batch 640, train_loss 0.693
epoch 39, batch 650, train_loss 0.702
epoch 39, batch 660, train_loss 0.679
epoch 39, batch 670, train_loss 0.700
epoch 39, batch 680, train_loss 0.694
epoch 39, batch 690, train_loss 0.690
epoch 39, batch 700, train_loss 0.699
epoch 39, batch 710, train_loss 0.683
epoch 39, batch 720, train_loss 0.681
epoch 39, batch 730, train_loss 0.693
epoch 39, batch 740, train_loss 0.697
epoch 39, batch 750, train_loss 0.696
epoch 39, batch 760, train_loss 0.690
epoch 39, batch 770, train_loss 0.689
epoch 39, batch 780, train_loss 0.682
epoch 39, batch 790, train_loss 0.686
epoch 39, batch 800, train_loss 0.694
epoch 39, batch 810, train_loss 0.684
epoch 39, batch 820, train_loss 0.694
epoch 39, batch 830, train_loss 0.698
epoch 39, batch 840, train_loss 0.687
epoch 39, batch 850, train_loss 0.695
epoch 39, batch 860, train_loss 0.689
epoch 39, batch 870, train_loss 0.694
epoch 39, batch 880, train_loss 0.687
epoch 39, batch 890, train_loss 0.695
epoch 39, batch 900, train_loss 0.693
epoch 39, batch 910, train_loss 0.694
epoch 39, batch 920, train_loss 0.686
epoch 39, batch 930, train_loss 0.680
epoch 39, batch 940, train_loss 0.698
epoch 39, batch 950, train_loss 0.695
epoch 39, batch 960, train_loss 0.687
epoch 39, batch 970, train_loss 0.691
epoch 39, batch 980, train_loss 0.691
epoch 39, batch 990, train_loss 0.692
epoch 39, batch 1000, train_loss 0.690
epoch 39, batch 1010, train_loss 0.692
epoch 39, batch 1020, train_loss 0.695
epoch 39, batch 1030, train_loss 0.696
epoch 39, batch 1040, train_loss 0.699
epoch 39, batch 1050, train_loss 0.692
epoch 39, batch 1060, train_loss 0.691
epoch 39, batch 1070, train_loss 0.693
epoch 39, batch 1080, train_loss 0.703
epoch 39, batch 1090, train_loss 0.695
epoch 39, batch 1100, train_loss 0.683
epoch 39, batch 1110, train_loss 0.689
epoch 39, batch 1120, train_loss 0.685
epoch 39, batch 1130, train_loss 0.696
epoch 39, batch 1140, train_loss 0.699
epoch 39, batch 1150, train_loss 0.695
epoch 39, batch 1160, train_loss 0.688
epoch 39, batch 1170, train_loss 0.686
epoch 39, batch 1180, train_loss 0.687
epoch 39, batch 1190, train_loss 0.697
epoch 39, train_loss 0.693, valid_loss 0.724, train_accuracy  70.21%, valid_accuracy  68.58%
epoch 40, batch 0, train_loss 0.690
epoch 40, batch 10, train_loss 0.691
epoch 40, batch 20, train_loss 0.696
epoch 40, batch 30, train_loss 0.687
epoch 40, batch 40, train_loss 0.690
epoch 40, batch 50, train_loss 0.709
epoch 40, batch 60, train_loss 0.688
epoch 40, batch 70, train_loss 0.690
epoch 40, batch 80, train_loss 0.695
epoch 40, batch 90, train_loss 0.692
epoch 40, batch 100, train_loss 0.697
epoch 40, batch 110, train_loss 0.686
epoch 40, batch 120, train_loss 0.694
epoch 40, batch 130, train_loss 0.694
epoch 40, batch 140, train_loss 0.696
epoch 40, batch 150, train_loss 0.687
epoch 40, batch 160, train_loss 0.695
epoch 40, batch 170, train_loss 0.692
epoch 40, batch 180, train_loss 0.688
epoch 40, batch 190, train_loss 0.693
epoch 40, batch 200, train_loss 0.684
epoch 40, batch 210, train_loss 0.689
epoch 40, batch 220, train_loss 0.699
epoch 40, batch 230, train_loss 0.688
epoch 40, batch 240, train_loss 0.697
epoch 40, batch 250, train_loss 0.687
epoch 40, batch 260, train_loss 0.689
epoch 40, batch 270, train_loss 0.706
epoch 40, batch 280, train_loss 0.694
epoch 40, batch 290, train_loss 0.692
epoch 40, batch 300, train_loss 0.702
epoch 40, batch 310, train_loss 0.697
epoch 40, batch 320, train_loss 0.691
epoch 40, batch 330, train_loss 0.697
epoch 40, batch 340, train_loss 0.695
epoch 40, batch 350, train_loss 0.696
epoch 40, batch 360, train_loss 0.680
epoch 40, batch 370, train_loss 0.686
epoch 40, batch 380, train_loss 0.690
epoch 40, batch 390, train_loss 0.700
epoch 40, batch 400, train_loss 0.691
epoch 40, batch 410, train_loss 0.686
epoch 40, batch 420, train_loss 0.691
epoch 40, batch 430, train_loss 0.698
epoch 40, batch 440, train_loss 0.696
epoch 40, batch 450, train_loss 0.679
epoch 40, batch 460, train_loss 0.705
epoch 40, batch 470, train_loss 0.692
epoch 40, batch 480, train_loss 0.686
epoch 40, batch 490, train_loss 0.697
epoch 40, batch 500, train_loss 0.691
epoch 40, batch 510, train_loss 0.691
epoch 40, batch 520, train_loss 0.696
epoch 40, batch 530, train_loss 0.692
epoch 40, batch 540, train_loss 0.694
epoch 40, batch 550, train_loss 0.688
epoch 40, batch 560, train_loss 0.699
epoch 40, batch 570, train_loss 0.700
epoch 40, batch 580, train_loss 0.688
epoch 40, batch 590, train_loss 0.691
epoch 40, batch 600, train_loss 0.684
epoch 40, batch 610, train_loss 0.689
epoch 40, batch 620, train_loss 0.694
epoch 40, batch 630, train_loss 0.691
epoch 40, batch 640, train_loss 0.698
epoch 40, batch 650, train_loss 0.682
epoch 40, batch 660, train_loss 0.691
epoch 40, batch 670, train_loss 0.703
epoch 40, batch 680, train_loss 0.698
epoch 40, batch 690, train_loss 0.682
epoch 40, batch 700, train_loss 0.690
epoch 40, batch 710, train_loss 0.685
epoch 40, batch 720, train_loss 0.700
epoch 40, batch 730, train_loss 0.698
epoch 40, batch 740, train_loss 0.684
epoch 40, batch 750, train_loss 0.693
epoch 40, batch 760, train_loss 0.682
epoch 40, batch 770, train_loss 0.699
epoch 40, batch 780, train_loss 0.692
epoch 40, batch 790, train_loss 0.696
epoch 40, batch 800, train_loss 0.702
epoch 40, batch 810, train_loss 0.683
epoch 40, batch 820, train_loss 0.699
epoch 40, batch 830, train_loss 0.687
epoch 40, batch 840, train_loss 0.699
epoch 40, batch 850, train_loss 0.695
epoch 40, batch 860, train_loss 0.703
epoch 40, batch 870, train_loss 0.700
epoch 40, batch 880, train_loss 0.691
epoch 40, batch 890, train_loss 0.688
epoch 40, batch 900, train_loss 0.687
epoch 40, batch 910, train_loss 0.688
epoch 40, batch 920, train_loss 0.688
epoch 40, batch 930, train_loss 0.696
epoch 40, batch 940, train_loss 0.685
epoch 40, batch 950, train_loss 0.691
epoch 40, batch 960, train_loss 0.700
epoch 40, batch 970, train_loss 0.694
epoch 40, batch 980, train_loss 0.697
epoch 40, batch 990, train_loss 0.694
epoch 40, batch 1000, train_loss 0.681
epoch 40, batch 1010, train_loss 0.697
epoch 40, batch 1020, train_loss 0.697
epoch 40, batch 1030, train_loss 0.687
epoch 40, batch 1040, train_loss 0.699
epoch 40, batch 1050, train_loss 0.696
epoch 40, batch 1060, train_loss 0.691
epoch 40, batch 1070, train_loss 0.695
epoch 40, batch 1080, train_loss 0.700
epoch 40, batch 1090, train_loss 0.687
epoch 40, batch 1100, train_loss 0.690
epoch 40, batch 1110, train_loss 0.698
epoch 40, batch 1120, train_loss 0.692
epoch 40, batch 1130, train_loss 0.689
epoch 40, batch 1140, train_loss 0.687
epoch 40, batch 1150, train_loss 0.693
epoch 40, batch 1160, train_loss 0.697
epoch 40, batch 1170, train_loss 0.693
epoch 40, batch 1180, train_loss 0.698
epoch 40, batch 1190, train_loss 0.694
epoch 40, train_loss 0.691, valid_loss 0.723, train_accuracy  70.29%, valid_accuracy  68.62%
epoch 41, batch 0, train_loss 0.698
epoch 41, batch 10, train_loss 0.687
epoch 41, batch 20, train_loss 0.686
epoch 41, batch 30, train_loss 0.698
epoch 41, batch 40, train_loss 0.693
epoch 41, batch 50, train_loss 0.689
epoch 41, batch 60, train_loss 0.690
epoch 41, batch 70, train_loss 0.693
epoch 41, batch 80, train_loss 0.685
epoch 41, batch 90, train_loss 0.683
epoch 41, batch 100, train_loss 0.694
epoch 41, batch 110, train_loss 0.704
epoch 41, batch 120, train_loss 0.690
epoch 41, batch 130, train_loss 0.694
epoch 41, batch 140, train_loss 0.696
epoch 41, batch 150, train_loss 0.690
epoch 41, batch 160, train_loss 0.693
epoch 41, batch 170, train_loss 0.696
epoch 41, batch 180, train_loss 0.696
epoch 41, batch 190, train_loss 0.690
epoch 41, batch 200, train_loss 0.694
epoch 41, batch 210, train_loss 0.688
epoch 41, batch 220, train_loss 0.698
epoch 41, batch 230, train_loss 0.690
epoch 41, batch 240, train_loss 0.698
epoch 41, batch 250, train_loss 0.695
epoch 41, batch 260, train_loss 0.693
epoch 41, batch 270, train_loss 0.687
epoch 41, batch 280, train_loss 0.697
epoch 41, batch 290, train_loss 0.694
epoch 41, batch 300, train_loss 0.688
epoch 41, batch 310, train_loss 0.694
epoch 41, batch 320, train_loss 0.704
epoch 41, batch 330, train_loss 0.686
epoch 41, batch 340, train_loss 0.688
epoch 41, batch 350, train_loss 0.698
epoch 41, batch 360, train_loss 0.690
epoch 41, batch 370, train_loss 0.695
epoch 41, batch 380, train_loss 0.684
epoch 41, batch 390, train_loss 0.685
epoch 41, batch 400, train_loss 0.688
epoch 41, batch 410, train_loss 0.691
epoch 41, batch 420, train_loss 0.693
epoch 41, batch 430, train_loss 0.698
epoch 41, batch 440, train_loss 0.682
epoch 41, batch 450, train_loss 0.689
epoch 41, batch 460, train_loss 0.696
epoch 41, batch 470, train_loss 0.693
epoch 41, batch 480, train_loss 0.685
epoch 41, batch 490, train_loss 0.699
epoch 41, batch 500, train_loss 0.695
epoch 41, batch 510, train_loss 0.685
epoch 41, batch 520, train_loss 0.694
epoch 41, batch 530, train_loss 0.676
epoch 41, batch 540, train_loss 0.701
epoch 41, batch 550, train_loss 0.688
epoch 41, batch 560, train_loss 0.692
epoch 41, batch 570, train_loss 0.690
epoch 41, batch 580, train_loss 0.690
epoch 41, batch 590, train_loss 0.704
epoch 41, batch 600, train_loss 0.678
epoch 41, batch 610, train_loss 0.692
epoch 41, batch 620, train_loss 0.702
epoch 41, batch 630, train_loss 0.686
epoch 41, batch 640, train_loss 0.692
epoch 41, batch 650, train_loss 0.697
epoch 41, batch 660, train_loss 0.699
epoch 41, batch 670, train_loss 0.701
epoch 41, batch 680, train_loss 0.684
epoch 41, batch 690, train_loss 0.693
epoch 41, batch 700, train_loss 0.691
epoch 41, batch 710, train_loss 0.686
epoch 41, batch 720, train_loss 0.695
epoch 41, batch 730, train_loss 0.693
epoch 41, batch 740, train_loss 0.709
epoch 41, batch 750, train_loss 0.694
epoch 41, batch 760, train_loss 0.687
epoch 41, batch 770, train_loss 0.694
epoch 41, batch 780, train_loss 0.684
epoch 41, batch 790, train_loss 0.699
epoch 41, batch 800, train_loss 0.694
epoch 41, batch 810, train_loss 0.691
epoch 41, batch 820, train_loss 0.699
epoch 41, batch 830, train_loss 0.699
epoch 41, batch 840, train_loss 0.688
epoch 41, batch 850, train_loss 0.700
epoch 41, batch 860, train_loss 0.688
epoch 41, batch 870, train_loss 0.681
epoch 41, batch 880, train_loss 0.687
epoch 41, batch 890, train_loss 0.698
epoch 41, batch 900, train_loss 0.691
epoch 41, batch 910, train_loss 0.693
epoch 41, batch 920, train_loss 0.686
epoch 41, batch 930, train_loss 0.694
epoch 41, batch 940, train_loss 0.706
epoch 41, batch 950, train_loss 0.696
epoch 41, batch 960, train_loss 0.704
epoch 41, batch 970, train_loss 0.686
epoch 41, batch 980, train_loss 0.694
epoch 41, batch 990, train_loss 0.687
epoch 41, batch 1000, train_loss 0.690
epoch 41, batch 1010, train_loss 0.693
epoch 41, batch 1020, train_loss 0.684
epoch 41, batch 1030, train_loss 0.691
epoch 41, batch 1040, train_loss 0.691
epoch 41, batch 1050, train_loss 0.693
epoch 41, batch 1060, train_loss 0.695
epoch 41, batch 1070, train_loss 0.685
epoch 41, batch 1080, train_loss 0.685
epoch 41, batch 1090, train_loss 0.688
epoch 41, batch 1100, train_loss 0.693
epoch 41, batch 1110, train_loss 0.696
epoch 41, batch 1120, train_loss 0.687
epoch 41, batch 1130, train_loss 0.693
epoch 41, batch 1140, train_loss 0.686
epoch 41, batch 1150, train_loss 0.682
epoch 41, batch 1160, train_loss 0.688
epoch 41, batch 1170, train_loss 0.687
epoch 41, batch 1180, train_loss 0.691
epoch 41, batch 1190, train_loss 0.696
epoch 41, train_loss 0.692, valid_loss 0.723, train_accuracy  70.26%, valid_accuracy  68.58%
epoch 42, batch 0, train_loss 0.681
epoch 42, batch 10, train_loss 0.685
epoch 42, batch 20, train_loss 0.689
epoch 42, batch 30, train_loss 0.692
epoch 42, batch 40, train_loss 0.685
epoch 42, batch 50, train_loss 0.684
epoch 42, batch 60, train_loss 0.684
epoch 42, batch 70, train_loss 0.695
epoch 42, batch 80, train_loss 0.697
epoch 42, batch 90, train_loss 0.688
epoch 42, batch 100, train_loss 0.687
epoch 42, batch 110, train_loss 0.694
epoch 42, batch 120, train_loss 0.693
epoch 42, batch 130, train_loss 0.693
epoch 42, batch 140, train_loss 0.686
epoch 42, batch 150, train_loss 0.691
epoch 42, batch 160, train_loss 0.688
epoch 42, batch 170, train_loss 0.687
epoch 42, batch 180, train_loss 0.691
epoch 42, batch 190, train_loss 0.691
epoch 42, batch 200, train_loss 0.688
epoch 42, batch 210, train_loss 0.695
epoch 42, batch 220, train_loss 0.705
epoch 42, batch 230, train_loss 0.690
epoch 42, batch 240, train_loss 0.688
epoch 42, batch 250, train_loss 0.691
epoch 42, batch 260, train_loss 0.693
epoch 42, batch 270, train_loss 0.695
epoch 42, batch 280, train_loss 0.697
epoch 42, batch 290, train_loss 0.687
epoch 42, batch 300, train_loss 0.693
epoch 42, batch 310, train_loss 0.687
epoch 42, batch 320, train_loss 0.691
epoch 42, batch 330, train_loss 0.692
epoch 42, batch 340, train_loss 0.695
epoch 42, batch 350, train_loss 0.693
epoch 42, batch 360, train_loss 0.693
epoch 42, batch 370, train_loss 0.686
epoch 42, batch 380, train_loss 0.692
epoch 42, batch 390, train_loss 0.682
epoch 42, batch 400, train_loss 0.700
epoch 42, batch 410, train_loss 0.691
epoch 42, batch 420, train_loss 0.686
epoch 42, batch 430, train_loss 0.687
epoch 42, batch 440, train_loss 0.687
epoch 42, batch 450, train_loss 0.690
epoch 42, batch 460, train_loss 0.686
epoch 42, batch 470, train_loss 0.696
epoch 42, batch 480, train_loss 0.690
epoch 42, batch 490, train_loss 0.692
epoch 42, batch 500, train_loss 0.686
epoch 42, batch 510, train_loss 0.686
epoch 42, batch 520, train_loss 0.693
epoch 42, batch 530, train_loss 0.703
epoch 42, batch 540, train_loss 0.692
epoch 42, batch 550, train_loss 0.691
epoch 42, batch 560, train_loss 0.699
epoch 42, batch 570, train_loss 0.689
epoch 42, batch 580, train_loss 0.707
epoch 42, batch 590, train_loss 0.687
epoch 42, batch 600, train_loss 0.684
epoch 42, batch 610, train_loss 0.704
epoch 42, batch 620, train_loss 0.698
epoch 42, batch 630, train_loss 0.685
epoch 42, batch 640, train_loss 0.701
epoch 42, batch 650, train_loss 0.695
epoch 42, batch 660, train_loss 0.694
epoch 42, batch 670, train_loss 0.698
epoch 42, batch 680, train_loss 0.695
epoch 42, batch 690, train_loss 0.702
epoch 42, batch 700, train_loss 0.699
epoch 42, batch 710, train_loss 0.697
epoch 42, batch 720, train_loss 0.690
epoch 42, batch 730, train_loss 0.690
epoch 42, batch 740, train_loss 0.695
epoch 42, batch 750, train_loss 0.696
epoch 42, batch 760, train_loss 0.688
epoch 42, batch 770, train_loss 0.690
epoch 42, batch 780, train_loss 0.703
epoch 42, batch 790, train_loss 0.687
epoch 42, batch 800, train_loss 0.694
epoch 42, batch 810, train_loss 0.696
epoch 42, batch 820, train_loss 0.693
epoch 42, batch 830, train_loss 0.692
epoch 42, batch 840, train_loss 0.691
epoch 42, batch 850, train_loss 0.680
epoch 42, batch 860, train_loss 0.683
epoch 42, batch 870, train_loss 0.686
epoch 42, batch 880, train_loss 0.692
epoch 42, batch 890, train_loss 0.691
epoch 42, batch 900, train_loss 0.694
epoch 42, batch 910, train_loss 0.684
epoch 42, batch 920, train_loss 0.702
epoch 42, batch 930, train_loss 0.687
epoch 42, batch 940, train_loss 0.692
epoch 42, batch 950, train_loss 0.693
epoch 42, batch 960, train_loss 0.696
epoch 42, batch 970, train_loss 0.699
epoch 42, batch 980, train_loss 0.696
epoch 42, batch 990, train_loss 0.703
epoch 42, batch 1000, train_loss 0.695
epoch 42, batch 1010, train_loss 0.699
epoch 42, batch 1020, train_loss 0.691
epoch 42, batch 1030, train_loss 0.690
epoch 42, batch 1040, train_loss 0.693
epoch 42, batch 1050, train_loss 0.696
epoch 42, batch 1060, train_loss 0.693
epoch 42, batch 1070, train_loss 0.686
epoch 42, batch 1080, train_loss 0.689
epoch 42, batch 1090, train_loss 0.685
epoch 42, batch 1100, train_loss 0.701
epoch 42, batch 1110, train_loss 0.684
epoch 42, batch 1120, train_loss 0.691
epoch 42, batch 1130, train_loss 0.688
epoch 42, batch 1140, train_loss 0.696
epoch 42, batch 1150, train_loss 0.685
epoch 42, batch 1160, train_loss 0.704
epoch 42, batch 1170, train_loss 0.698
epoch 42, batch 1180, train_loss 0.695
epoch 42, batch 1190, train_loss 0.682
epoch 42, train_loss 0.691, valid_loss 0.723, train_accuracy  70.30%, valid_accuracy  68.55%
epoch 43, batch 0, train_loss 0.700
epoch 43, batch 10, train_loss 0.686
epoch 43, batch 20, train_loss 0.691
epoch 43, batch 30, train_loss 0.688
epoch 43, batch 40, train_loss 0.695
epoch 43, batch 50, train_loss 0.695
epoch 43, batch 60, train_loss 0.692
epoch 43, batch 70, train_loss 0.690
epoch 43, batch 80, train_loss 0.693
epoch 43, batch 90, train_loss 0.685
epoch 43, batch 100, train_loss 0.689
epoch 43, batch 110, train_loss 0.693
epoch 43, batch 120, train_loss 0.689
epoch 43, batch 130, train_loss 0.694
epoch 43, batch 140, train_loss 0.690
epoch 43, batch 150, train_loss 0.696
epoch 43, batch 160, train_loss 0.697
epoch 43, batch 170, train_loss 0.701
epoch 43, batch 180, train_loss 0.700
epoch 43, batch 190, train_loss 0.691
epoch 43, batch 200, train_loss 0.683
epoch 43, batch 210, train_loss 0.695
epoch 43, batch 220, train_loss 0.690
epoch 43, batch 230, train_loss 0.700
epoch 43, batch 240, train_loss 0.700
epoch 43, batch 250, train_loss 0.692
epoch 43, batch 260, train_loss 0.687
epoch 43, batch 270, train_loss 0.683
epoch 43, batch 280, train_loss 0.696
epoch 43, batch 290, train_loss 0.692
epoch 43, batch 300, train_loss 0.692
epoch 43, batch 310, train_loss 0.689
epoch 43, batch 320, train_loss 0.703
epoch 43, batch 330, train_loss 0.690
epoch 43, batch 340, train_loss 0.690
epoch 43, batch 350, train_loss 0.689
epoch 43, batch 360, train_loss 0.692
epoch 43, batch 370, train_loss 0.688
epoch 43, batch 380, train_loss 0.690
epoch 43, batch 390, train_loss 0.697
epoch 43, batch 400, train_loss 0.686
epoch 43, batch 410, train_loss 0.699
epoch 43, batch 420, train_loss 0.689
epoch 43, batch 430, train_loss 0.696
epoch 43, batch 440, train_loss 0.694
epoch 43, batch 450, train_loss 0.682
epoch 43, batch 460, train_loss 0.687
epoch 43, batch 470, train_loss 0.697
epoch 43, batch 480, train_loss 0.695
epoch 43, batch 490, train_loss 0.692
epoch 43, batch 500, train_loss 0.689
epoch 43, batch 510, train_loss 0.690
epoch 43, batch 520, train_loss 0.684
epoch 43, batch 530, train_loss 0.692
epoch 43, batch 540, train_loss 0.693
epoch 43, batch 550, train_loss 0.701
epoch 43, batch 560, train_loss 0.698
epoch 43, batch 570, train_loss 0.691
epoch 43, batch 580, train_loss 0.689
epoch 43, batch 590, train_loss 0.702
epoch 43, batch 600, train_loss 0.688
epoch 43, batch 610, train_loss 0.694
epoch 43, batch 620, train_loss 0.693
epoch 43, batch 630, train_loss 0.696
epoch 43, batch 640, train_loss 0.686
epoch 43, batch 650, train_loss 0.683
epoch 43, batch 660, train_loss 0.691
epoch 43, batch 670, train_loss 0.694
epoch 43, batch 680, train_loss 0.694
epoch 43, batch 690, train_loss 0.697
epoch 43, batch 700, train_loss 0.687
epoch 43, batch 710, train_loss 0.697
epoch 43, batch 720, train_loss 0.687
epoch 43, batch 730, train_loss 0.681
epoch 43, batch 740, train_loss 0.691
epoch 43, batch 750, train_loss 0.693
epoch 43, batch 760, train_loss 0.688
epoch 43, batch 770, train_loss 0.688
epoch 43, batch 780, train_loss 0.696
epoch 43, batch 790, train_loss 0.690
epoch 43, batch 800, train_loss 0.681
epoch 43, batch 810, train_loss 0.694
epoch 43, batch 820, train_loss 0.701
epoch 43, batch 830, train_loss 0.699
epoch 43, batch 840, train_loss 0.696
epoch 43, batch 850, train_loss 0.697
epoch 43, batch 860, train_loss 0.688
epoch 43, batch 870, train_loss 0.687
epoch 43, batch 880, train_loss 0.703
epoch 43, batch 890, train_loss 0.696
epoch 43, batch 900, train_loss 0.698
epoch 43, batch 910, train_loss 0.691
epoch 43, batch 920, train_loss 0.690
epoch 43, batch 930, train_loss 0.682
epoch 43, batch 940, train_loss 0.687
epoch 43, batch 950, train_loss 0.696
epoch 43, batch 960, train_loss 0.692
epoch 43, batch 970, train_loss 0.680
epoch 43, batch 980, train_loss 0.692
epoch 43, batch 990, train_loss 0.698
epoch 43, batch 1000, train_loss 0.695
epoch 43, batch 1010, train_loss 0.692
epoch 43, batch 1020, train_loss 0.692
epoch 43, batch 1030, train_loss 0.693
epoch 43, batch 1040, train_loss 0.695
epoch 43, batch 1050, train_loss 0.682
epoch 43, batch 1060, train_loss 0.691
epoch 43, batch 1070, train_loss 0.690
epoch 43, batch 1080, train_loss 0.689
epoch 43, batch 1090, train_loss 0.705
epoch 43, batch 1100, train_loss 0.690
epoch 43, batch 1110, train_loss 0.698
epoch 43, batch 1120, train_loss 0.688
epoch 43, batch 1130, train_loss 0.690
epoch 43, batch 1140, train_loss 0.686
epoch 43, batch 1150, train_loss 0.689
epoch 43, batch 1160, train_loss 0.690
epoch 43, batch 1170, train_loss 0.698
epoch 43, batch 1180, train_loss 0.686
epoch 43, batch 1190, train_loss 0.695
epoch 43, train_loss 0.691, valid_loss 0.723, train_accuracy  70.29%, valid_accuracy  68.56%
epoch 44, batch 0, train_loss 0.688
epoch 44, batch 10, train_loss 0.686
epoch 44, batch 20, train_loss 0.685
epoch 44, batch 30, train_loss 0.677
epoch 44, batch 40, train_loss 0.698
epoch 44, batch 50, train_loss 0.697
epoch 44, batch 60, train_loss 0.694
epoch 44, batch 70, train_loss 0.698
epoch 44, batch 80, train_loss 0.690
epoch 44, batch 90, train_loss 0.693
epoch 44, batch 100, train_loss 0.694
epoch 44, batch 110, train_loss 0.696
epoch 44, batch 120, train_loss 0.693
epoch 44, batch 130, train_loss 0.692
epoch 44, batch 140, train_loss 0.692
epoch 44, batch 150, train_loss 0.685
epoch 44, batch 160, train_loss 0.690
epoch 44, batch 170, train_loss 0.692
epoch 44, batch 180, train_loss 0.691
epoch 44, batch 190, train_loss 0.690
epoch 44, batch 200, train_loss 0.681
epoch 44, batch 210, train_loss 0.693
epoch 44, batch 220, train_loss 0.696
epoch 44, batch 230, train_loss 0.694
epoch 44, batch 240, train_loss 0.700
epoch 44, batch 250, train_loss 0.689
epoch 44, batch 260, train_loss 0.699
epoch 44, batch 270, train_loss 0.691
epoch 44, batch 280, train_loss 0.683
epoch 44, batch 290, train_loss 0.698
epoch 44, batch 300, train_loss 0.688
epoch 44, batch 310, train_loss 0.695
epoch 44, batch 320, train_loss 0.703
epoch 44, batch 330, train_loss 0.689
epoch 44, batch 340, train_loss 0.691
epoch 44, batch 350, train_loss 0.695
epoch 44, batch 360, train_loss 0.693
epoch 44, batch 370, train_loss 0.706
epoch 44, batch 380, train_loss 0.689
epoch 44, batch 390, train_loss 0.701
epoch 44, batch 400, train_loss 0.694
epoch 44, batch 410, train_loss 0.697
epoch 44, batch 420, train_loss 0.694
epoch 44, batch 430, train_loss 0.686
epoch 44, batch 440, train_loss 0.685
epoch 44, batch 450, train_loss 0.694
epoch 44, batch 460, train_loss 0.693
epoch 44, batch 470, train_loss 0.697
epoch 44, batch 480, train_loss 0.699
epoch 44, batch 490, train_loss 0.693
epoch 44, batch 500, train_loss 0.678
epoch 44, batch 510, train_loss 0.683
epoch 44, batch 520, train_loss 0.692
epoch 44, batch 530, train_loss 0.692
epoch 44, batch 540, train_loss 0.688
epoch 44, batch 550, train_loss 0.686
epoch 44, batch 560, train_loss 0.685
epoch 44, batch 570, train_loss 0.692
epoch 44, batch 580, train_loss 0.690
epoch 44, batch 590, train_loss 0.692
epoch 44, batch 600, train_loss 0.689
epoch 44, batch 610, train_loss 0.693
epoch 44, batch 620, train_loss 0.690
epoch 44, batch 630, train_loss 0.690
epoch 44, batch 640, train_loss 0.694
epoch 44, batch 650, train_loss 0.694
epoch 44, batch 660, train_loss 0.691
epoch 44, batch 670, train_loss 0.701
epoch 44, batch 680, train_loss 0.692
epoch 44, batch 690, train_loss 0.698
epoch 44, batch 700, train_loss 0.692
epoch 44, batch 710, train_loss 0.698
epoch 44, batch 720, train_loss 0.687
epoch 44, batch 730, train_loss 0.693
epoch 44, batch 740, train_loss 0.695
epoch 44, batch 750, train_loss 0.688
epoch 44, batch 760, train_loss 0.698
epoch 44, batch 770, train_loss 0.690
epoch 44, batch 780, train_loss 0.695
epoch 44, batch 790, train_loss 0.691
epoch 44, batch 800, train_loss 0.687
epoch 44, batch 810, train_loss 0.688
epoch 44, batch 820, train_loss 0.697
epoch 44, batch 830, train_loss 0.688
epoch 44, batch 840, train_loss 0.693
epoch 44, batch 850, train_loss 0.690
epoch 44, batch 860, train_loss 0.689
epoch 44, batch 870, train_loss 0.699
epoch 44, batch 880, train_loss 0.696
epoch 44, batch 890, train_loss 0.690
epoch 44, batch 900, train_loss 0.700
epoch 44, batch 910, train_loss 0.695
epoch 44, batch 920, train_loss 0.688
epoch 44, batch 930, train_loss 0.695
epoch 44, batch 940, train_loss 0.696
epoch 44, batch 950, train_loss 0.693
epoch 44, batch 960, train_loss 0.688
epoch 44, batch 970, train_loss 0.691
epoch 44, batch 980, train_loss 0.692
epoch 44, batch 990, train_loss 0.698
epoch 44, batch 1000, train_loss 0.686
epoch 44, batch 1010, train_loss 0.694
epoch 44, batch 1020, train_loss 0.701
epoch 44, batch 1030, train_loss 0.691
epoch 44, batch 1040, train_loss 0.683
epoch 44, batch 1050, train_loss 0.692
epoch 44, batch 1060, train_loss 0.682
epoch 44, batch 1070, train_loss 0.703
epoch 44, batch 1080, train_loss 0.694
epoch 44, batch 1090, train_loss 0.690
epoch 44, batch 1100, train_loss 0.689
epoch 44, batch 1110, train_loss 0.693
epoch 44, batch 1120, train_loss 0.694
epoch 44, batch 1130, train_loss 0.685
epoch 44, batch 1140, train_loss 0.702
epoch 44, batch 1150, train_loss 0.690
epoch 44, batch 1160, train_loss 0.694
epoch 44, batch 1170, train_loss 0.696
epoch 44, batch 1180, train_loss 0.687
epoch 44, batch 1190, train_loss 0.702
epoch 44, train_loss 0.691, valid_loss 0.723, train_accuracy  70.30%, valid_accuracy  68.60%
epoch 45, batch 0, train_loss 0.700
epoch 45, batch 10, train_loss 0.694
epoch 45, batch 20, train_loss 0.694
epoch 45, batch 30, train_loss 0.690
epoch 45, batch 40, train_loss 0.693
epoch 45, batch 50, train_loss 0.676
epoch 45, batch 60, train_loss 0.696
epoch 45, batch 70, train_loss 0.686
epoch 45, batch 80, train_loss 0.686
epoch 45, batch 90, train_loss 0.694
epoch 45, batch 100, train_loss 0.687
epoch 45, batch 110, train_loss 0.687
epoch 45, batch 120, train_loss 0.688
epoch 45, batch 130, train_loss 0.698
epoch 45, batch 140, train_loss 0.698
epoch 45, batch 150, train_loss 0.694
epoch 45, batch 160, train_loss 0.689
epoch 45, batch 170, train_loss 0.692
epoch 45, batch 180, train_loss 0.706
epoch 45, batch 190, train_loss 0.695
epoch 45, batch 200, train_loss 0.685
epoch 45, batch 210, train_loss 0.692
epoch 45, batch 220, train_loss 0.696
epoch 45, batch 230, train_loss 0.690
epoch 45, batch 240, train_loss 0.698
epoch 45, batch 250, train_loss 0.690
epoch 45, batch 260, train_loss 0.693
epoch 45, batch 270, train_loss 0.683
epoch 45, batch 280, train_loss 0.694
epoch 45, batch 290, train_loss 0.678
epoch 45, batch 300, train_loss 0.680
epoch 45, batch 310, train_loss 0.691
epoch 45, batch 320, train_loss 0.691
epoch 45, batch 330, train_loss 0.690
epoch 45, batch 340, train_loss 0.685
epoch 45, batch 350, train_loss 0.692
epoch 45, batch 360, train_loss 0.689
epoch 45, batch 370, train_loss 0.690
epoch 45, batch 380, train_loss 0.696
epoch 45, batch 390, train_loss 0.699
epoch 45, batch 400, train_loss 0.697
epoch 45, batch 410, train_loss 0.694
epoch 45, batch 420, train_loss 0.690
epoch 45, batch 430, train_loss 0.683
epoch 45, batch 440, train_loss 0.694
epoch 45, batch 450, train_loss 0.691
epoch 45, batch 460, train_loss 0.685
epoch 45, batch 470, train_loss 0.695
epoch 45, batch 480, train_loss 0.692
epoch 45, batch 490, train_loss 0.699
epoch 45, batch 500, train_loss 0.700
epoch 45, batch 510, train_loss 0.693
epoch 45, batch 520, train_loss 0.687
epoch 45, batch 530, train_loss 0.689
epoch 45, batch 540, train_loss 0.693
epoch 45, batch 550, train_loss 0.682
epoch 45, batch 560, train_loss 0.685
epoch 45, batch 570, train_loss 0.702
epoch 45, batch 580, train_loss 0.684
epoch 45, batch 590, train_loss 0.681
epoch 45, batch 600, train_loss 0.687
epoch 45, batch 610, train_loss 0.692
epoch 45, batch 620, train_loss 0.686
epoch 45, batch 630, train_loss 0.690
epoch 45, batch 640, train_loss 0.700
epoch 45, batch 650, train_loss 0.703
epoch 45, batch 660, train_loss 0.698
epoch 45, batch 670, train_loss 0.683
epoch 45, batch 680, train_loss 0.691
epoch 45, batch 690, train_loss 0.694
epoch 45, batch 700, train_loss 0.695
epoch 45, batch 710, train_loss 0.695
epoch 45, batch 720, train_loss 0.699
epoch 45, batch 730, train_loss 0.698
epoch 45, batch 740, train_loss 0.693
epoch 45, batch 750, train_loss 0.697
epoch 45, batch 760, train_loss 0.698
epoch 45, batch 770, train_loss 0.689
epoch 45, batch 780, train_loss 0.695
epoch 45, batch 790, train_loss 0.693
epoch 45, batch 800, train_loss 0.697
epoch 45, batch 810, train_loss 0.686
epoch 45, batch 820, train_loss 0.697
epoch 45, batch 830, train_loss 0.696
epoch 45, batch 840, train_loss 0.693
epoch 45, batch 850, train_loss 0.689
epoch 45, batch 860, train_loss 0.695
epoch 45, batch 870, train_loss 0.679
epoch 45, batch 880, train_loss 0.683
epoch 45, batch 890, train_loss 0.679
epoch 45, batch 900, train_loss 0.709
epoch 45, batch 910, train_loss 0.698
epoch 45, batch 920, train_loss 0.685
epoch 45, batch 930, train_loss 0.690
epoch 45, batch 940, train_loss 0.682
epoch 45, batch 950, train_loss 0.692
epoch 45, batch 960, train_loss 0.682
epoch 45, batch 970, train_loss 0.691
epoch 45, batch 980, train_loss 0.693
epoch 45, batch 990, train_loss 0.688
epoch 45, batch 1000, train_loss 0.689
epoch 45, batch 1010, train_loss 0.695
epoch 45, batch 1020, train_loss 0.697
epoch 45, batch 1030, train_loss 0.698
epoch 45, batch 1040, train_loss 0.693
epoch 45, batch 1050, train_loss 0.692
epoch 45, batch 1060, train_loss 0.689
epoch 45, batch 1070, train_loss 0.687
epoch 45, batch 1080, train_loss 0.688
epoch 45, batch 1090, train_loss 0.682
epoch 45, batch 1100, train_loss 0.691
epoch 45, batch 1110, train_loss 0.694
epoch 45, batch 1120, train_loss 0.703
epoch 45, batch 1130, train_loss 0.688
epoch 45, batch 1140, train_loss 0.690
epoch 45, batch 1150, train_loss 0.684
epoch 45, batch 1160, train_loss 0.693
epoch 45, batch 1170, train_loss 0.682
epoch 45, batch 1180, train_loss 0.693
epoch 45, batch 1190, train_loss 0.692
epoch 45, train_loss 0.691, valid_loss 0.723, train_accuracy  70.31%, valid_accuracy  68.58%
epoch 46, batch 0, train_loss 0.688
epoch 46, batch 10, train_loss 0.685
epoch 46, batch 20, train_loss 0.685
epoch 46, batch 30, train_loss 0.692
epoch 46, batch 40, train_loss 0.687
epoch 46, batch 50, train_loss 0.695
epoch 46, batch 60, train_loss 0.694
epoch 46, batch 70, train_loss 0.701
epoch 46, batch 80, train_loss 0.693
epoch 46, batch 90, train_loss 0.682
epoch 46, batch 100, train_loss 0.694
epoch 46, batch 110, train_loss 0.684
epoch 46, batch 120, train_loss 0.696
epoch 46, batch 130, train_loss 0.697
epoch 46, batch 140, train_loss 0.706
epoch 46, batch 150, train_loss 0.697
epoch 46, batch 160, train_loss 0.691
epoch 46, batch 170, train_loss 0.688
epoch 46, batch 180, train_loss 0.692
epoch 46, batch 190, train_loss 0.694
epoch 46, batch 200, train_loss 0.692
epoch 46, batch 210, train_loss 0.694
epoch 46, batch 220, train_loss 0.697
epoch 46, batch 230, train_loss 0.695
epoch 46, batch 240, train_loss 0.691
epoch 46, batch 250, train_loss 0.683
epoch 46, batch 260, train_loss 0.691
epoch 46, batch 270, train_loss 0.689
epoch 46, batch 280, train_loss 0.694
epoch 46, batch 290, train_loss 0.690
epoch 46, batch 300, train_loss 0.698
epoch 46, batch 310, train_loss 0.695
epoch 46, batch 320, train_loss 0.696
epoch 46, batch 330, train_loss 0.698
epoch 46, batch 340, train_loss 0.696
epoch 46, batch 350, train_loss 0.694
epoch 46, batch 360, train_loss 0.698
epoch 46, batch 370, train_loss 0.689
epoch 46, batch 380, train_loss 0.693
epoch 46, batch 390, train_loss 0.693
epoch 46, batch 400, train_loss 0.692
epoch 46, batch 410, train_loss 0.685
epoch 46, batch 420, train_loss 0.687
epoch 46, batch 430, train_loss 0.702
epoch 46, batch 440, train_loss 0.694
epoch 46, batch 450, train_loss 0.683
epoch 46, batch 460, train_loss 0.691
epoch 46, batch 470, train_loss 0.686
epoch 46, batch 480, train_loss 0.699
epoch 46, batch 490, train_loss 0.691
epoch 46, batch 500, train_loss 0.696
epoch 46, batch 510, train_loss 0.705
epoch 46, batch 520, train_loss 0.693
epoch 46, batch 530, train_loss 0.686
epoch 46, batch 540, train_loss 0.694
epoch 46, batch 550, train_loss 0.688
epoch 46, batch 560, train_loss 0.697
epoch 46, batch 570, train_loss 0.700
epoch 46, batch 580, train_loss 0.692
epoch 46, batch 590, train_loss 0.696
epoch 46, batch 600, train_loss 0.697
epoch 46, batch 610, train_loss 0.694
epoch 46, batch 620, train_loss 0.685
epoch 46, batch 630, train_loss 0.693
epoch 46, batch 640, train_loss 0.690
epoch 46, batch 650, train_loss 0.694
epoch 46, batch 660, train_loss 0.689
epoch 46, batch 670, train_loss 0.693
epoch 46, batch 680, train_loss 0.695
epoch 46, batch 690, train_loss 0.692
epoch 46, batch 700, train_loss 0.700
epoch 46, batch 710, train_loss 0.691
epoch 46, batch 720, train_loss 0.692
epoch 46, batch 730, train_loss 0.687
epoch 46, batch 740, train_loss 0.688
epoch 46, batch 750, train_loss 0.681
epoch 46, batch 760, train_loss 0.692
epoch 46, batch 770, train_loss 0.689
epoch 46, batch 780, train_loss 0.694
epoch 46, batch 790, train_loss 0.687
epoch 46, batch 800, train_loss 0.685
epoch 46, batch 810, train_loss 0.684
epoch 46, batch 820, train_loss 0.691
epoch 46, batch 830, train_loss 0.693
epoch 46, batch 840, train_loss 0.694
epoch 46, batch 850, train_loss 0.695
epoch 46, batch 860, train_loss 0.690
epoch 46, batch 870, train_loss 0.695
epoch 46, batch 880, train_loss 0.694
epoch 46, batch 890, train_loss 0.680
epoch 46, batch 900, train_loss 0.696
epoch 46, batch 910, train_loss 0.687
epoch 46, batch 920, train_loss 0.687
epoch 46, batch 930, train_loss 0.697
epoch 46, batch 940, train_loss 0.685
epoch 46, batch 950, train_loss 0.701
epoch 46, batch 960, train_loss 0.692
epoch 46, batch 970, train_loss 0.693
epoch 46, batch 980, train_loss 0.696
epoch 46, batch 990, train_loss 0.691
epoch 46, batch 1000, train_loss 0.697
epoch 46, batch 1010, train_loss 0.693
epoch 46, batch 1020, train_loss 0.702
epoch 46, batch 1030, train_loss 0.683
epoch 46, batch 1040, train_loss 0.697
epoch 46, batch 1050, train_loss 0.695
epoch 46, batch 1060, train_loss 0.691
epoch 46, batch 1070, train_loss 0.687
epoch 46, batch 1080, train_loss 0.702
epoch 46, batch 1090, train_loss 0.700
epoch 46, batch 1100, train_loss 0.695
epoch 46, batch 1110, train_loss 0.692
epoch 46, batch 1120, train_loss 0.686
epoch 46, batch 1130, train_loss 0.697
epoch 46, batch 1140, train_loss 0.696
epoch 46, batch 1150, train_loss 0.692
epoch 46, batch 1160, train_loss 0.692
epoch 46, batch 1170, train_loss 0.693
epoch 46, batch 1180, train_loss 0.692
epoch 46, batch 1190, train_loss 0.699
epoch 46, train_loss 0.692, valid_loss 0.723, train_accuracy  70.28%, valid_accuracy  68.56%
epoch 47, batch 0, train_loss 0.684
epoch 47, batch 10, train_loss 0.694
epoch 47, batch 20, train_loss 0.692
epoch 47, batch 30, train_loss 0.692
epoch 47, batch 40, train_loss 0.691
epoch 47, batch 50, train_loss 0.693
epoch 47, batch 60, train_loss 0.696
epoch 47, batch 70, train_loss 0.673
epoch 47, batch 80, train_loss 0.702
epoch 47, batch 90, train_loss 0.693
epoch 47, batch 100, train_loss 0.693
epoch 47, batch 110, train_loss 0.697
epoch 47, batch 120, train_loss 0.687
epoch 47, batch 130, train_loss 0.698
epoch 47, batch 140, train_loss 0.685
epoch 47, batch 150, train_loss 0.696
epoch 47, batch 160, train_loss 0.691
epoch 47, batch 170, train_loss 0.689
epoch 47, batch 180, train_loss 0.691
epoch 47, batch 190, train_loss 0.692
epoch 47, batch 200, train_loss 0.695
epoch 47, batch 210, train_loss 0.696
epoch 47, batch 220, train_loss 0.688
epoch 47, batch 230, train_loss 0.697
epoch 47, batch 240, train_loss 0.696
epoch 47, batch 250, train_loss 0.682
epoch 47, batch 260, train_loss 0.688
epoch 47, batch 270, train_loss 0.685
epoch 47, batch 280, train_loss 0.690
epoch 47, batch 290, train_loss 0.688
epoch 47, batch 300, train_loss 0.700
epoch 47, batch 310, train_loss 0.691
epoch 47, batch 320, train_loss 0.688
epoch 47, batch 330, train_loss 0.690
epoch 47, batch 340, train_loss 0.689
epoch 47, batch 350, train_loss 0.694
epoch 47, batch 360, train_loss 0.699
epoch 47, batch 370, train_loss 0.698
epoch 47, batch 380, train_loss 0.690
epoch 47, batch 390, train_loss 0.692
epoch 47, batch 400, train_loss 0.697
epoch 47, batch 410, train_loss 0.696
epoch 47, batch 420, train_loss 0.701
epoch 47, batch 430, train_loss 0.683
epoch 47, batch 440, train_loss 0.692
epoch 47, batch 450, train_loss 0.700
epoch 47, batch 460, train_loss 0.685
epoch 47, batch 470, train_loss 0.688
epoch 47, batch 480, train_loss 0.694
epoch 47, batch 490, train_loss 0.686
epoch 47, batch 500, train_loss 0.686
epoch 47, batch 510, train_loss 0.696
epoch 47, batch 520, train_loss 0.696
epoch 47, batch 530, train_loss 0.690
epoch 47, batch 540, train_loss 0.682
epoch 47, batch 550, train_loss 0.688
epoch 47, batch 560, train_loss 0.692
epoch 47, batch 570, train_loss 0.684
epoch 47, batch 580, train_loss 0.690
epoch 47, batch 590, train_loss 0.700
epoch 47, batch 600, train_loss 0.689
epoch 47, batch 610, train_loss 0.692
epoch 47, batch 620, train_loss 0.700
epoch 47, batch 630, train_loss 0.695
epoch 47, batch 640, train_loss 0.693
epoch 47, batch 650, train_loss 0.704
epoch 47, batch 660, train_loss 0.690
epoch 47, batch 670, train_loss 0.695
epoch 47, batch 680, train_loss 0.694
epoch 47, batch 690, train_loss 0.696
epoch 47, batch 700, train_loss 0.690
epoch 47, batch 710, train_loss 0.690
epoch 47, batch 720, train_loss 0.688
epoch 47, batch 730, train_loss 0.702
epoch 47, batch 740, train_loss 0.693
epoch 47, batch 750, train_loss 0.689
epoch 47, batch 760, train_loss 0.693
epoch 47, batch 770, train_loss 0.696
epoch 47, batch 780, train_loss 0.702
epoch 47, batch 790, train_loss 0.689
epoch 47, batch 800, train_loss 0.691
epoch 47, batch 810, train_loss 0.690
epoch 47, batch 820, train_loss 0.688
epoch 47, batch 830, train_loss 0.702
epoch 47, batch 840, train_loss 0.685
epoch 47, batch 850, train_loss 0.695
epoch 47, batch 860, train_loss 0.690
epoch 47, batch 870, train_loss 0.689
epoch 47, batch 880, train_loss 0.700
epoch 47, batch 890, train_loss 0.697
epoch 47, batch 900, train_loss 0.695
epoch 47, batch 910, train_loss 0.688
epoch 47, batch 920, train_loss 0.688
epoch 47, batch 930, train_loss 0.694
epoch 47, batch 940, train_loss 0.681
epoch 47, batch 950, train_loss 0.706
epoch 47, batch 960, train_loss 0.691
epoch 47, batch 970, train_loss 0.690
epoch 47, batch 980, train_loss 0.691
epoch 47, batch 990, train_loss 0.687
epoch 47, batch 1000, train_loss 0.697
epoch 47, batch 1010, train_loss 0.699
epoch 47, batch 1020, train_loss 0.699
epoch 47, batch 1030, train_loss 0.694
epoch 47, batch 1040, train_loss 0.695
epoch 47, batch 1050, train_loss 0.698
epoch 47, batch 1060, train_loss 0.697
epoch 47, batch 1070, train_loss 0.697
epoch 47, batch 1080, train_loss 0.697
epoch 47, batch 1090, train_loss 0.690
epoch 47, batch 1100, train_loss 0.698
epoch 47, batch 1110, train_loss 0.685
epoch 47, batch 1120, train_loss 0.700
epoch 47, batch 1130, train_loss 0.702
epoch 47, batch 1140, train_loss 0.698
epoch 47, batch 1150, train_loss 0.696
epoch 47, batch 1160, train_loss 0.701
epoch 47, batch 1170, train_loss 0.693
epoch 47, batch 1180, train_loss 0.693
epoch 47, batch 1190, train_loss 0.692
epoch 47, train_loss 0.692, valid_loss 0.724, train_accuracy  70.28%, valid_accuracy  68.55%
epoch 48, batch 0, train_loss 0.675
epoch 48, batch 10, train_loss 0.702
epoch 48, batch 20, train_loss 0.690
epoch 48, batch 30, train_loss 0.692
epoch 48, batch 40, train_loss 0.686
epoch 48, batch 50, train_loss 0.683
epoch 48, batch 60, train_loss 0.690
epoch 48, batch 70, train_loss 0.689
epoch 48, batch 80, train_loss 0.696
epoch 48, batch 90, train_loss 0.685
epoch 48, batch 100, train_loss 0.690
epoch 48, batch 110, train_loss 0.695
epoch 48, batch 120, train_loss 0.690
epoch 48, batch 130, train_loss 0.697
epoch 48, batch 140, train_loss 0.695
epoch 48, batch 150, train_loss 0.683
epoch 48, batch 160, train_loss 0.696
epoch 48, batch 170, train_loss 0.704
epoch 48, batch 180, train_loss 0.673
epoch 48, batch 190, train_loss 0.697
epoch 48, batch 200, train_loss 0.684
epoch 48, batch 210, train_loss 0.685
epoch 48, batch 220, train_loss 0.689
epoch 48, batch 230, train_loss 0.687
epoch 48, batch 240, train_loss 0.699
epoch 48, batch 250, train_loss 0.693
epoch 48, batch 260, train_loss 0.689
epoch 48, batch 270, train_loss 0.692
epoch 48, batch 280, train_loss 0.681
epoch 48, batch 290, train_loss 0.692
epoch 48, batch 300, train_loss 0.693
epoch 48, batch 310, train_loss 0.690
epoch 48, batch 320, train_loss 0.690
epoch 48, batch 330, train_loss 0.694
epoch 48, batch 340, train_loss 0.694
epoch 48, batch 350, train_loss 0.686
epoch 48, batch 360, train_loss 0.696
epoch 48, batch 370, train_loss 0.693
epoch 48, batch 380, train_loss 0.695
epoch 48, batch 390, train_loss 0.692
epoch 48, batch 400, train_loss 0.695
epoch 48, batch 410, train_loss 0.697
epoch 48, batch 420, train_loss 0.689
epoch 48, batch 430, train_loss 0.695
epoch 48, batch 440, train_loss 0.690
epoch 48, batch 450, train_loss 0.686
epoch 48, batch 460, train_loss 0.692
epoch 48, batch 470, train_loss 0.698
epoch 48, batch 480, train_loss 0.698
epoch 48, batch 490, train_loss 0.690
epoch 48, batch 500, train_loss 0.697
epoch 48, batch 510, train_loss 0.697
epoch 48, batch 520, train_loss 0.689
epoch 48, batch 530, train_loss 0.686
epoch 48, batch 540, train_loss 0.692
epoch 48, batch 550, train_loss 0.681
epoch 48, batch 560, train_loss 0.691
epoch 48, batch 570, train_loss 0.693
epoch 48, batch 580, train_loss 0.696
epoch 48, batch 590, train_loss 0.680
epoch 48, batch 600, train_loss 0.697
epoch 48, batch 610, train_loss 0.688
epoch 48, batch 620, train_loss 0.702
epoch 48, batch 630, train_loss 0.692
epoch 48, batch 640, train_loss 0.692
epoch 48, batch 650, train_loss 0.693
epoch 48, batch 660, train_loss 0.691
epoch 48, batch 670, train_loss 0.688
epoch 48, batch 680, train_loss 0.696
epoch 48, batch 690, train_loss 0.690
epoch 48, batch 700, train_loss 0.687
epoch 48, batch 710, train_loss 0.693
epoch 48, batch 720, train_loss 0.695
epoch 48, batch 730, train_loss 0.686
epoch 48, batch 740, train_loss 0.687
epoch 48, batch 750, train_loss 0.692
epoch 48, batch 760, train_loss 0.695
epoch 48, batch 770, train_loss 0.687
epoch 48, batch 780, train_loss 0.693
epoch 48, batch 790, train_loss 0.699
epoch 48, batch 800, train_loss 0.703
epoch 48, batch 810, train_loss 0.698
epoch 48, batch 820, train_loss 0.696
epoch 48, batch 830, train_loss 0.695
epoch 48, batch 840, train_loss 0.698
epoch 48, batch 850, train_loss 0.689
epoch 48, batch 860, train_loss 0.692
epoch 48, batch 870, train_loss 0.687
epoch 48, batch 880, train_loss 0.692
epoch 48, batch 890, train_loss 0.694
epoch 48, batch 900, train_loss 0.691
epoch 48, batch 910, train_loss 0.696
epoch 48, batch 920, train_loss 0.689
epoch 48, batch 930, train_loss 0.698
epoch 48, batch 940, train_loss 0.696
epoch 48, batch 950, train_loss 0.691
epoch 48, batch 960, train_loss 0.692
epoch 48, batch 970, train_loss 0.696
epoch 48, batch 980, train_loss 0.701
epoch 48, batch 990, train_loss 0.696
epoch 48, batch 1000, train_loss 0.688
epoch 48, batch 1010, train_loss 0.689
epoch 48, batch 1020, train_loss 0.681
epoch 48, batch 1030, train_loss 0.697
epoch 48, batch 1040, train_loss 0.688
epoch 48, batch 1050, train_loss 0.687
epoch 48, batch 1060, train_loss 0.691
epoch 48, batch 1070, train_loss 0.695
epoch 48, batch 1080, train_loss 0.698
epoch 48, batch 1090, train_loss 0.692
epoch 48, batch 1100, train_loss 0.690
epoch 48, batch 1110, train_loss 0.688
epoch 48, batch 1120, train_loss 0.696
epoch 48, batch 1130, train_loss 0.688
epoch 48, batch 1140, train_loss 0.690
epoch 48, batch 1150, train_loss 0.693
epoch 48, batch 1160, train_loss 0.686
epoch 48, batch 1170, train_loss 0.687
epoch 48, batch 1180, train_loss 0.693
epoch 48, batch 1190, train_loss 0.685
epoch 48, train_loss 0.691, valid_loss 0.723, train_accuracy  70.29%, valid_accuracy  68.59%
epoch 49, batch 0, train_loss 0.690
epoch 49, batch 10, train_loss 0.694
epoch 49, batch 20, train_loss 0.690
epoch 49, batch 30, train_loss 0.685
epoch 49, batch 40, train_loss 0.690
epoch 49, batch 50, train_loss 0.681
epoch 49, batch 60, train_loss 0.696
epoch 49, batch 70, train_loss 0.702
epoch 49, batch 80, train_loss 0.685
epoch 49, batch 90, train_loss 0.686
epoch 49, batch 100, train_loss 0.686
epoch 49, batch 110, train_loss 0.693
epoch 49, batch 120, train_loss 0.688
epoch 49, batch 130, train_loss 0.692
epoch 49, batch 140, train_loss 0.691
epoch 49, batch 150, train_loss 0.691
epoch 49, batch 160, train_loss 0.696
epoch 49, batch 170, train_loss 0.692
epoch 49, batch 180, train_loss 0.688
epoch 49, batch 190, train_loss 0.690
epoch 49, batch 200, train_loss 0.686
epoch 49, batch 210, train_loss 0.691
epoch 49, batch 220, train_loss 0.702
epoch 49, batch 230, train_loss 0.694
epoch 49, batch 240, train_loss 0.695
epoch 49, batch 250, train_loss 0.700
epoch 49, batch 260, train_loss 0.691
epoch 49, batch 270, train_loss 0.690
epoch 49, batch 280, train_loss 0.699
epoch 49, batch 290, train_loss 0.698
epoch 49, batch 300, train_loss 0.693
epoch 49, batch 310, train_loss 0.686
epoch 49, batch 320, train_loss 0.689
epoch 49, batch 330, train_loss 0.690
epoch 49, batch 340, train_loss 0.698
epoch 49, batch 350, train_loss 0.692
epoch 49, batch 360, train_loss 0.685
epoch 49, batch 370, train_loss 0.684
epoch 49, batch 380, train_loss 0.683
epoch 49, batch 390, train_loss 0.684
epoch 49, batch 400, train_loss 0.696
epoch 49, batch 410, train_loss 0.696
epoch 49, batch 420, train_loss 0.688
epoch 49, batch 430, train_loss 0.692
epoch 49, batch 440, train_loss 0.691
epoch 49, batch 450, train_loss 0.693
epoch 49, batch 460, train_loss 0.696
epoch 49, batch 470, train_loss 0.690
epoch 49, batch 480, train_loss 0.691
epoch 49, batch 490, train_loss 0.700
epoch 49, batch 500, train_loss 0.691
epoch 49, batch 510, train_loss 0.693
epoch 49, batch 520, train_loss 0.696
epoch 49, batch 530, train_loss 0.701
epoch 49, batch 540, train_loss 0.694
epoch 49, batch 550, train_loss 0.687
epoch 49, batch 560, train_loss 0.687
epoch 49, batch 570, train_loss 0.693
epoch 49, batch 580, train_loss 0.693
epoch 49, batch 590, train_loss 0.701
epoch 49, batch 600, train_loss 0.685
epoch 49, batch 610, train_loss 0.687
epoch 49, batch 620, train_loss 0.689
epoch 49, batch 630, train_loss 0.696
epoch 49, batch 640, train_loss 0.690
epoch 49, batch 650, train_loss 0.689
epoch 49, batch 660, train_loss 0.692
epoch 49, batch 670, train_loss 0.692
epoch 49, batch 680, train_loss 0.699
epoch 49, batch 690, train_loss 0.695
epoch 49, batch 700, train_loss 0.694
epoch 49, batch 710, train_loss 0.688
epoch 49, batch 720, train_loss 0.684
epoch 49, batch 730, train_loss 0.691
epoch 49, batch 740, train_loss 0.696
epoch 49, batch 750, train_loss 0.695
epoch 49, batch 760, train_loss 0.678
epoch 49, batch 770, train_loss 0.698
epoch 49, batch 780, train_loss 0.692
epoch 49, batch 790, train_loss 0.685
epoch 49, batch 800, train_loss 0.689
epoch 49, batch 810, train_loss 0.692
epoch 49, batch 820, train_loss 0.681
epoch 49, batch 830, train_loss 0.700
epoch 49, batch 840, train_loss 0.693
epoch 49, batch 850, train_loss 0.689
epoch 49, batch 860, train_loss 0.696
epoch 49, batch 870, train_loss 0.688
epoch 49, batch 880, train_loss 0.693
epoch 49, batch 890, train_loss 0.681
epoch 49, batch 900, train_loss 0.690
epoch 49, batch 910, train_loss 0.693
epoch 49, batch 920, train_loss 0.697
epoch 49, batch 930, train_loss 0.691
epoch 49, batch 940, train_loss 0.698
epoch 49, batch 950, train_loss 0.696
epoch 49, batch 960, train_loss 0.706
epoch 49, batch 970, train_loss 0.692
epoch 49, batch 980, train_loss 0.690
epoch 49, batch 990, train_loss 0.684
epoch 49, batch 1000, train_loss 0.686
epoch 49, batch 1010, train_loss 0.682
epoch 49, batch 1020, train_loss 0.692
epoch 49, batch 1030, train_loss 0.691
epoch 49, batch 1040, train_loss 0.690
epoch 49, batch 1050, train_loss 0.696
epoch 49, batch 1060, train_loss 0.693
epoch 49, batch 1070, train_loss 0.683
epoch 49, batch 1080, train_loss 0.681
epoch 49, batch 1090, train_loss 0.692
epoch 49, batch 1100, train_loss 0.692
epoch 49, batch 1110, train_loss 0.686
epoch 49, batch 1120, train_loss 0.691
epoch 49, batch 1130, train_loss 0.695
epoch 49, batch 1140, train_loss 0.690
epoch 49, batch 1150, train_loss 0.694
epoch 49, batch 1160, train_loss 0.697
epoch 49, batch 1170, train_loss 0.692
epoch 49, batch 1180, train_loss 0.690
epoch 49, batch 1190, train_loss 0.689
epoch 49, train_loss 0.691, valid_loss 0.723, train_accuracy  70.30%, valid_accuracy  68.60%
</pre></div></div>
</div>
</section>
</section>
<section id="Make-predictions-on-the-test-data">
<h2>Make predictions on the test data<a class="headerlink" href="#Make-predictions-on-the-test-data" title="Link to this heading">#</a></h2>
<p>After the model is trained, you make predictions on the test sequences using saved model that has the highest validation accuracy. The test sequences are provided in the file <code class="docutils literal notranslate"><span class="pre">test.txt</span></code>. You need to use the trained model to predict the secondary structure of all residues in the test sequences. The predictions should be written to a text file named <code class="docutils literal notranslate"><span class="pre">predictions.txt</span></code> and its format should be the same as the file <code class="docutils literal notranslate"><span class="pre">train.txt</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[40]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## load the model with the highest validation accuracy</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNetwork</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">eqx</span><span class="o">.</span><span class="n">tree_deserialise_leaves</span><span class="p">(</span><span class="s2">&quot;../output/model-with-highest-valid-accuracy.eqx&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="c1">###########################################################################</span>
<span class="c1">#### write your code here for the task described above (10 points) ########</span>
<span class="c1">###########################################################################</span>
<br/><br/><br/></pre></div>
</div>
</div>
</section>
<section id="Submission-instructions">
<h2>Submission instructions<a class="headerlink" href="#Submission-instructions" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>You need to create a folder named <code class="docutils literal notranslate"><span class="pre">assignment-3-protein-secondary-structure-nn</span></code> under the OneDrive folder that has been shared with you.</p></li>
<li><p>Complete the code and answer the questions as described above in this Jupyter notebook. Make sure to save your work and name your Jupyter notebook as <code class="docutils literal notranslate"><span class="pre">main.ipynb</span></code>.</p></li>
<li><p>Upload the <code class="docutils literal notranslate"><span class="pre">main.ipynb</span></code>, <code class="docutils literal notranslate"><span class="pre">pyproject.toml</span></code>, and <code class="docutils literal notranslate"><span class="pre">test_prediction.txt</span></code> files to the <code class="docutils literal notranslate"><span class="pre">assignment-3-protein-secondary-structure-nn</span></code> folder that you created in step 1.</p></li>
</ol>
<p><strong>Note:</strong> Please make sure the names of the folder and files are exactly as instructed.</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Input-and-output-of-the-neural-network-model">Input and output of the neural network model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Process-the-training-data">Process the training data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#The-neural-network-model">The neural network model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Training-the-model">Training the model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Train-the-model-using-stochastic-gradient-descent-(SGD)-with-the-Adam-optimizer">Train the model using stochastic gradient descent (SGD) with the Adam optimizer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Plot-the-loss-and-accuracy-curves-during-training">Plot the loss and accuracy curves during training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Save-the-model-with-the-highest-validation-accuracy">Save the model with the highest validation accuracy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Make-predictions-on-the-test-data">Make predictions on the test data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Submission-instructions">Submission instructions</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Xinqiang Ding
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, Xinqiang Ding.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>