
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Linear Regression &#8212; Chem 193</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=e645c8fa"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorial/linear-regression';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="High Performance Computing" href="hpc.html" />
    <link rel="prev" title="Numpy &amp; JAX" href="numpy-jax.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Chem 193</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../schedule.html">Schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../syllabus.html">Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lecture.html">Lecture Slides</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Tutorials</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="python-basics.html">Python Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="numpy-jax.html">Numpy &amp; JAX</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax-nn.html">Neural networks with JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="sample-from-probability-distributions.html">Sample from probability distributions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../homework/index.html">Homeworks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../homework/0-linear-algebra.html">Linear Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/1-python-basics/main.html">Processing protein MSA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/2-protein-secondary-structure/script/main.html">Predicting protein secondary structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/3-protein-secondary-structure-nn/script/main.html">Predicting protein secondary structure with neural networks</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/DingGroup/Chem-193" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/tutorial/linear-regression.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Linear Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#1.-Generate-synthetic-data">1. Generate synthetic data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#2.-Fit-the-linear-model">2. Fit the linear model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Gradient-descent">Gradient descent</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Linear-Regression">
<h1>Linear Regression<a class="headerlink" href="#Linear-Regression" title="Link to this heading">#</a></h1>
<p>In this tutorial, we will show how to perform a simple linear regression. We will use synthetic data for which we know the true parameters. We will then fit a linear model to this data and see if we can recover the true parameters.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.random</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jr</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;presentation&quot;</span><span class="p">)</span>
<span class="n">jax</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;jax_enable_x64&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="1.-Generate-synthetic-data">
<h2>1. Generate synthetic data<a class="headerlink" href="#1.-Generate-synthetic-data" title="Link to this heading">#</a></h2>
<p>The data contain pairs of <span class="math notranslate nohighlight">\((x, y)\)</span> values, where <span class="math notranslate nohighlight">\(x\)</span> is the 1-d feature and <span class="math notranslate nohighlight">\(y\)</span> is the target. The underlying model is <span class="math notranslate nohighlight">\(y = \theta_0 + \theta_1 x + \epsilon\)</span>, where <span class="math notranslate nohighlight">\(\epsilon\)</span> is Gaussian noise. We set <span class="math notranslate nohighlight">\(\theta_0 = 5.7\)</span>, <span class="math notranslate nohighlight">\(\theta_1 = 2.5\)</span>, and the standard deviation of <span class="math notranslate nohighlight">\(\epsilon\)</span> to 2.0. We generate 100 synthetic data points based on this model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## true parameters</span>
<span class="n">theta_1</span> <span class="o">=</span> <span class="mf">2.5</span>
<span class="n">theta_0</span> <span class="o">=</span> <span class="mf">5.7</span>

<span class="c1">## x is the feature</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">subkey</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,),</span> <span class="n">minval</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1">## y is the response</span>
<span class="n">subkey</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">theta_0</span> <span class="o">+</span> <span class="n">theta_1</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">jr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="mf">2.0</span>

<span class="c1">## plot the data</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">theta_0</span> <span class="o">+</span> <span class="n">theta_1</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_linear-regression_3_0.png" src="../_images/tutorial_linear-regression_3_0.png" />
</div>
</div>
<p>Turn data and parameters into matrix/vector form</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">theta</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">theta_0</span><span class="p">,</span> <span class="n">theta_1</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;shape of theta: &quot;</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;shape of x: &quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
shape of theta:  (2,)
shape of x:  (100, 2)
</pre></div></div>
</div>
</section>
<section id="2.-Fit-the-linear-model">
<h2>2. Fit the linear model<a class="headerlink" href="#2.-Fit-the-linear-model" title="Link to this heading">#</a></h2>
<p>We will fit the linear model using both the analytical solution and the gradient descent algorithm. We will then compare the estimated parameters with the true parameters. ### Analytical solution Although it is attempting to directly use the formula: <span class="math notranslate nohighlight">\(\theta = (X^T X)^{-1} X^T y\)</span> to compute the analytical solution, it is not recommended because it requires inverting a matrix, which could be numerically unstable. Instead, we can compute the solution using the QR decomposition of <span class="math notranslate nohighlight">\(X\)</span>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## use the formula directly</span>
<span class="n">theta_naive</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">x</span><span class="p">)</span> <span class="o">@</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>

<span class="c1">## use the QR decomposition</span>
<span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">theta_qr</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span>

<span class="c1">## although the two methods provide the same result here, the method using QR decomposition is numerically more stable and should be preferred</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta_true:&quot;</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta_naive:&quot;</span><span class="p">,</span> <span class="n">theta_naive</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta_qr:&quot;</span><span class="p">,</span> <span class="n">theta_qr</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
theta_true: [5.7 2.5]
theta_naive: [5.76809547 2.51084153]
theta_qr: [5.76809547 2.51084153]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## make predictions using the estimated parameters</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">theta_qr</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">theta_0</span> <span class="o">+</span> <span class="n">theta_1</span> <span class="o">*</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;prediction&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_linear-regression_8_0.png" src="../_images/tutorial_linear-regression_8_0.png" />
</div>
</div>
<section id="Gradient-descent">
<h3>Gradient descent<a class="headerlink" href="#Gradient-descent" title="Link to this heading">#</a></h3>
<p>First, we provide a simple implementation of the gradient descent algorithm for fitting the linear model. In the implementation, we use a fixed learning rate.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## define the loss function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">loss_fn</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">jnp</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1">## function to compute the gradient of the loss function</span>
<span class="n">grad_fn</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">## train the model</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="c1">## stopping criteria</span>
<span class="n">max_iter</span> <span class="o">=</span> <span class="mi">10_000</span>
<span class="n">g_tol</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="n">f_tol</span> <span class="o">=</span> <span class="mf">1e-8</span>

<span class="n">theta_gd</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">theta_gd</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx_iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="n">grad_fn</span><span class="p">(</span><span class="n">theta_gd</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">jnp</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">gradient</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">g_tol</span><span class="p">):</span>
        <span class="k">break</span>

    <span class="n">theta_gd</span> <span class="o">-=</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">gradient</span>
    <span class="n">loss_new</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">theta_gd</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">loss</span> <span class="o">-</span> <span class="n">loss_new</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">loss</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">loss_new</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">f_tol</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_new</span>

    <span class="k">if</span> <span class="n">idx_iter</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Loss at step </span><span class="si">{</span><span class="n">idx_iter</span><span class="si">:</span><span class="s2">&gt;3</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">&gt;6.2f</span><span class="si">}</span><span class="s2">, theta:&quot;</span><span class="p">,</span> <span class="n">theta_gd</span><span class="p">,</span> <span class="s2">&quot;gradident:&quot;</span><span class="p">,</span> <span class="n">gradient</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Loss at step   0:  85.97, theta: [0.18974219 1.20315769] gradident: [ -18.97421894 -120.31576877]
Loss at step 100:   3.43, theta: [1.55316878 3.13334832] gradident: [-0.94286931  0.13925332]
Loss at step 200:   2.70, theta: [2.39718003 3.00869544] gradident: [-0.75406595  0.11136876]
Loss at step 300:   2.24, theta: [3.0721836  2.90900348] gradident: [-0.60306922  0.0890679 ]
Loss at step 400:   1.94, theta: [3.61202215 2.82927418] gradident: [-0.48230859  0.07123264]
Loss at step 500:   1.75, theta: [4.0437616  2.76551014] gradident: [-0.38572948  0.05696878]
Loss at step 600:   1.62, theta: [4.38904808 2.71451443] gradident: [-0.3084897   0.04556116]
Loss at step 700:   1.55, theta: [4.66519321 2.67373028] gradident: [-0.24671667  0.03643784]
Loss at step 800:   1.50, theta: [4.88604211 2.64111288] gradident: [-0.19731329  0.0291414 ]
Loss at step 900:   1.46, theta: [5.06266747 2.6150269 ] gradident: [-0.1578026   0.02330603]
Loss at step 1000:   1.44, theta: [5.20392477 2.59416447] gradident: [-0.12620367  0.01863915]
Loss at step 1100:   1.43, theta: [5.31689623 2.5774796 ] gradident: [-0.10093222  0.01490678]
Loss at step 1200:   1.42, theta: [5.4072459  2.56413577] gradident: [-0.08072121  0.0119218 ]
Loss at step 1300:   1.42, theta: [5.47950364 2.55346395] gradident: [-0.06455732  0.00953454]
Loss at step 1400:   1.41, theta: [5.53729225 2.54492909] gradident: [-0.05163014  0.00762531]
Loss at step 1500:   1.41, theta: [5.58350907 2.53810328] gradident: [-0.04129155  0.00609839]
Loss at step 1600:   1.41, theta: [5.62047128 2.53264429] gradident: [-0.03302319  0.00487723]
Loss at step 1700:   1.41, theta: [5.65003205 2.52827843] gradident: [-0.02641051  0.0039006 ]
Loss at step 1800:   1.41, theta: [5.67367347 2.52478681] gradident: [-0.02112198  0.00311953]
Loss at step 1900:   1.41, theta: [5.69258085 2.52199436] gradident: [-0.01689244  0.00249486]
Loss at step 2000:   1.41, theta: [5.70770216 2.51976108] gradident: [-0.01350984  0.00199528]
Loss at step 2100:   1.41, theta: [5.71979552 2.517975  ] gradident: [-0.01080459  0.00159574]
Loss at step 2200:   1.41, theta: [5.72946726 2.51654657] gradident: [-0.00864104  0.0012762 ]
Loss at step 2300:   1.41, theta: [5.73720231 2.51540417] gradident: [-0.00691073  0.00102065]
Loss at step 2400:   1.41, theta: [5.74338846 2.51449053] gradident: [-0.0055269   0.00081627]
Loss at step 2500:   1.41, theta: [5.74833587 2.51375984] gradident: [-0.00442018  0.00065282]
Loss at step 2600:   1.41, theta: [5.7522926  2.51317547] gradident: [-0.00353506  0.0005221 ]
Loss at step 2700:   1.41, theta: [5.75545702 2.51270811] gradident: [-0.00282719  0.00041755]
Loss at step 2800:   1.41, theta: [5.75798779 2.51233434] gradident: [-0.00226106  0.00033394]
Loss at step 2900:   1.41, theta: [5.76001178 2.51203541] gradident: [-0.0018083   0.00026707]
Loss at step 3000:   1.41, theta: [5.76163049 2.51179635] gradident: [-0.0014462   0.00021359]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta_true:&quot;</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta_gd:&quot;</span><span class="p">,</span> <span class="n">theta_gd</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
theta_true: [5.7 2.5]
theta_gd: [5.76285527 2.51161546]
</pre></div></div>
</div>
<p>In practice, we rarely write our own optimization algorithm. Instead, we use more advanced implementations offered by various libraries. In this tutorial, we will use the <code class="docutils literal notranslate"><span class="pre">LBFGS</span></code> algorithm provided by the <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code> library. It is more efficient and does not require specifying a learning rate. All we need to do is to provide a function that computes the loss and its gradient.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">optimize</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">options</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;disp&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;gtol&quot;</span><span class="p">:</span> <span class="mf">1e-8</span><span class="p">}</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">func</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">f</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)]</span>

<span class="n">theta_init</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
    <span class="n">func</span><span class="p">,</span>
    <span class="n">theta_init</span><span class="p">,</span>
    <span class="n">jac</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;L-BFGS-B&quot;</span><span class="p">,</span>
    <span class="n">tol</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
  message: CONVERGENCE: NORM OF PROJECTED GRADIENT &lt;= PGTOL
  success: True
   status: 0
      fun: 1.4068179203820095
        x: [ 5.768e+00  2.511e+00]
      nit: 6
      jac: [ 3.079e-09  4.877e-09]
     nfev: 9
     njev: 9
 hess_inv: &lt;2x2 LbfgsInvHessProduct with dtype=float64&gt;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">theta_bfgs</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta_true:&quot;</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;theta_bfgs:&quot;</span><span class="p">,</span> <span class="n">theta_bfgs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
theta_true: [5.7 2.5]
theta_bfgs: [5.76809548 2.51084153]
</pre></div></div>
</div>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="numpy-jax.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Numpy &amp; JAX</p>
      </div>
    </a>
    <a class="right-next"
       href="hpc.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">High Performance Computing</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#1.-Generate-synthetic-data">1. Generate synthetic data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#2.-Fit-the-linear-model">2. Fit the linear model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Gradient-descent">Gradient descent</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Xinqiang Ding
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, Xinqiang Ding.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>